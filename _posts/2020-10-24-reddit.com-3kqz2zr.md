---

layout: post
category: threads
title: "[D] Apply Transformer-style post-norm to ResNet"
date: 2020-10-24 08:47:27
link: https://vrhk.co/3kqz2zr
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Here I mean using the normalization layer outside the residual block. Did anyone try it? Will it result in divergence in training? It's said..."

---

### [D] Apply Transformer-style post-norm to ResNet

Here I mean using the normalization layer outside the residual block. Did anyone try it? Will it result in divergence in training? It's said...