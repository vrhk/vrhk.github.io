---

layout: post
category: product
title: "Import AI 170: Hearing herring via AI; think NLP progress has been dramatic"
date: 2019-10-28 20:56:29
link: https://vrhk.co/31QimHD
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Want to protect our civilization from the truth-melting capabilities of contemporary AI techniques? Enter the deepfake detection challenge!&hellip; Competition challenges people to build tools that can spot visual deepfakes&hellip;Deepfakes, the slang term of art for images and videos that have been synthesized via AI systems, are everyone&rsquo;s problem. That&rsquo;s because deepfakes are a threat to our ability to trust the things we see online. Therefore, finding ways to help people spot deepfakes is key to creating a society where people can maintain trust in their digital lives. One route to doing that is having a better ability to automatically detect deepfakes. Now, Facebook, Microsoft, Amazon Web Services, and the Partnership on AI have created the Deepfake Detection Challenge to encourage research into deepfake detection.
Dataset release: Facebook&rsquo;s &ldquo;AI Red Team&rdquo; has released a &ldquo;preview dataset&rdquo; for the challenge that consists of around 5000 videos, both original and manipulated. To build the dataset, the researchers crowdsourced videos from people while &ldquo;ensuring a variability in gender, skin tone and age&rdquo;. In a rare turn for an AI project, Facebook seems to have acted ethically here &ndash; &ldquo;one key differentiating factor from other existing datasets is that the actors have agreed to participate in the creation of the dataset which uses and modifies their likeness&rdquo;, the researchers write.&nbsp;
Ethical dataset policies: A deepfakes detection dataset could also be useful to bad actors who want to create deepfakes that can evade detection. For this reason, Facebook has made is so researchers will need to register to access the dataset. Adding slight hurdles like this to data access can have a big effect on minimizing bad behavior.&nbsp;
Why this matters: Competitions are a fantastic way to focus the attention of the AI community on a problem. Even better are competitions which include large dataset releases, as these can catalyze research on a tricky problem, while also providing new tools that researchers can use to develop their thinking in an area. I hope we see many more competitions like this, and I hope we see way more AI red teams to facilitate such competitions.&nbsp;&nbsp;&nbsp;Read more: The Deepfake Detection Challenge (DFDC) Preview Dataset (Arxiv).&nbsp;&nbsp;&nbsp;Read more: Deepfake Detection Challenge (official website).
####################################################
Can deep learning systems spot changes in cities via satellites? Kind of, but we need to do more research:&hellip;DL + data makes automatic analysis of satellite imagery possible, with big implications for the diffusion of strategic surveillance capabilities&hellip;Researchers with the National Technical University of Athens, the Universite Paras-Saclay and INRIA Saclay, and startup Granular AI, have tried to train a system to identify changes in urban scenes via the automated analysis of satellite footage. The resulting system is an intriguing proof-of-concept, but not yet good enough for production.&nbsp;
How it works and how well it works: They design a relatively simple system which combines a &lsquo;U-Net&rsquo; architecture with LSTM memory cells, letting them learn to model changes between images over time. The best-performing system is a U-Net + LSTM architecture using all five images for each city over time, obtaining a precision of 63.59, recall of 52.93, OA of 96 and F1 of 57.78.&nbsp;
Dataset: They use the Bi-temporal Onera Satellite Change Detection (OSCD) Sentinel-2 dataset, which consists of images of 24 different cities around the world taken on two distinct dates. They also splice in additional images from Sentinel satellites to give them three additional datapoints, helping them model changes over time. They also augment the dataset programmatically, flipping and rotating images to create more data to train the system on.&nbsp;
Why this matters: &ldquo;As far as human intervention on earth is concerned, change detection techniques offer valuable information on a variety of topics such as urban sprawl, water and air contamination levels, illegal constructions&rdquo;. Papers like this show how AI is upending the balance of strategic power, taking capabilities that used to be the province solely of intelligent agencies and hedge funds (automatically analyzing satellite imagery), and diffusing them to a broader range of actors. Ultimately, this means we&rsquo;ll see more organizations using AI tools to analyze satellite images, and I&rsquo;m particularly excited about such technologies being used for providing analytical capabilities following natural disasters.&nbsp;&nbsp;&nbsp;Read more: Detecting Urban Changes with Recurrent Neural Networks from Multitemporal Sentinel-2 Data (Arxiv).&nbsp;
####################################################
Can you herring me know? Researchers train AI to listen for schools of fish:&hellip;Deep learning + echograms = autonomous fish classifier&hellip;Can we use deep learning to listen to the ocean and learn about it? Researchers with the University of Victoria, ASL Environmental Sciences, and the Victoria branch of Fisheries and Oceans Canada think so, have built a system that hunts for herring in echograms.
How it works: The primary technical aspect of this work is a region-of-interest extractor, which the researchers develop to look at echograms and pull out sections for further analysis and classification; this system obtains a recall of 0.93 in the best case. They then train a classifier that looks at echograms extracted by the region-of-interest module; the top performing system is a DenseNet which obtains a recall scall of 0.85 and an F1 score of 0.82 &ndash; significantly higher than a support vector machine baseline of 0.78 and 0.62.&nbsp;&nbsp;&nbsp;The scores the researchers obtain are encouraging but not sufficiently robust for the real world &ndash; yet. But though the accuracy is sub-par, it could become a useful tool: &ldquo;the ability to measure the abundance of such subjects [fish] over extended periods of time constitutes a strong tool for the study of the effects of water temperature shifts caused by climate change-related phenomena,&rdquo; they write.&nbsp;
Why this matters: I look forward to a day when planet earth is covered in systems automatically listening for and cataloguing wildlife &ndash; I think such systems could give us a richer understanding of our own ecosystems and will likely be a prerequisite for the effective rebuilding of ecosystems as we get our collective act together with regard to catastrophic climate change.&nbsp;
It&rsquo;s a shame that&hellip; the researchers didn&rsquo;t call this software DeepFish, or something similar. HerringVision? FishFinder? The possibilities are as boundless as the ocean itself!&nbsp;&nbsp;&nbsp;Read more: A Deep Learning-based Framework for the Detection of Schools of Herring in Echograms (Arxiv).&nbsp;
####################################################
Want better OCR? Try messing up your data:&hellip;DeepErase promises to take your words, make them dirty, clean them for you, and get smarter in the process&hellip;Researchers with Ernest and Young have created DeepErase, weakly supervized software that &ldquo;inputs a document text image with ink artifacts and outputs the same image with artifacts erased&rdquo;. DeepErase is essentially a pipeline for processing images destined for optical character recognition (OCR) systems; it takes in images, automatically augments them with visual clutter, then trains a classifier to distinguish good images from bad ones. The idea is that, if the software gets good enough, you can use it to automatically identify and clean images before they go to custom in-house OCR software.&nbsp;
How it works: DeepErase takes in some datasets of images of handwritten text, then programmatically generate artifacts for these images, deliberately messing up…"

---

### Import AI 170: Hearing herring via AI; think NLP progress has been dramatic – so does Google!; and Facebook’s “AI red team” hunts deepfakes

Want to protect our civilization from the truth-melting capabilities of contemporary AI techniques? Enter the deepfake detection challenge!&hellip; Competition challenges people to build tools that can spot visual deepfakes&hellip;Deepfakes, the slang term of art for images and videos that have been synthesized via AI systems, are everyone&rsquo;s problem. That&rsquo;s because deepfakes are a threat to our ability to trust the things we see online. Therefore, finding ways to help people spot deepfakes is key to creating a society where people can maintain trust in their digital lives. One route to doing that is having a better ability to automatically detect deepfakes. Now, Facebook, Microsoft, Amazon Web Services, and the Partnership on AI have created the Deepfake Detection Challenge to encourage research into deepfake detection.
Dataset release: Facebook&rsquo;s &ldquo;AI Red Team&rdquo; has released a &ldquo;preview dataset&rdquo; for the challenge that consists of around 5000 videos, both original and manipulated. To build the dataset, the researchers crowdsourced videos from people while &ldquo;ensuring a variability in gender, skin tone and age&rdquo;. In a rare turn for an AI project, Facebook seems to have acted ethically here &ndash; &ldquo;one key differentiating factor from other existing datasets is that the actors have agreed to participate in the creation of the dataset which uses and modifies their likeness&rdquo;, the researchers write.&nbsp;
Ethical dataset policies: A deepfakes detection dataset could also be useful to bad actors who want to create deepfakes that can evade detection. For this reason, Facebook has made is so researchers will need to register to access the dataset. Adding slight hurdles like this to data access can have a big effect on minimizing bad behavior.&nbsp;
Why this matters: Competitions are a fantastic way to focus the attention of the AI community on a problem. Even better are competitions which include large dataset releases, as these can catalyze research on a tricky problem, while also providing new tools that researchers can use to develop their thinking in an area. I hope we see many more competitions like this, and I hope we see way more AI red teams to facilitate such competitions.&nbsp;&nbsp;&nbsp;Read more: The Deepfake Detection Challenge (DFDC) Preview Dataset (Arxiv).&nbsp;&nbsp;&nbsp;Read more: Deepfake Detection Challenge (official website).
####################################################
Can deep learning systems spot changes in cities via satellites? Kind of, but we need to do more research:&hellip;DL + data makes automatic analysis of satellite imagery possible, with big implications for the diffusion of strategic surveillance capabilities&hellip;Researchers with the National Technical University of Athens, the Universite Paras-Saclay and INRIA Saclay, and startup Granular AI, have tried to train a system to identify changes in urban scenes via the automated analysis of satellite footage. The resulting system is an intriguing proof-of-concept, but not yet good enough for production.&nbsp;
How it works and how well it works: They design a relatively simple system which combines a &lsquo;U-Net&rsquo; architecture with LSTM memory cells, letting them learn to model changes between images over time. The best-performing system is a U-Net + LSTM architecture using all five images for each city over time, obtaining a precision of 63.59, recall of 52.93, OA of 96 and F1 of 57.78.&nbsp;
Dataset: They use the Bi-temporal Onera Satellite Change Detection (OSCD) Sentinel-2 dataset, which consists of images of 24 different cities around the world taken on two distinct dates. They also splice in additional images from Sentinel satellites to give them three additional datapoints, helping them model changes over time. They also augment the dataset programmatically, flipping and rotating images to create more data to train the system on.&nbsp;
Why this matters: &ldquo;As far as human intervention on earth is concerned, change detection techniques offer valuable information on a variety of topics such as urban sprawl, water and air contamination levels, illegal constructions&rdquo;. Papers like this show how AI is upending the balance of strategic power, taking capabilities that used to be the province solely of intelligent agencies and hedge funds (automatically analyzing satellite imagery), and diffusing them to a broader range of actors. Ultimately, this means we&rsquo;ll see more organizations using AI tools to analyze satellite images, and I&rsquo;m particularly excited about such technologies being used for providing analytical capabilities following natural disasters.&nbsp;&nbsp;&nbsp;Read more: Detecting Urban Changes with Recurrent Neural Networks from Multitemporal Sentinel-2 Data (Arxiv).&nbsp;
####################################################
Can you herring me know? Researchers train AI to listen for schools of fish:&hellip;Deep learning + echograms = autonomous fish classifier&hellip;Can we use deep learning to listen to the ocean and learn about it? Researchers with the University of Victoria, ASL Environmental Sciences, and the Victoria branch of Fisheries and Oceans Canada think so, have built a system that hunts for herring in echograms.
How it works: The primary technical aspect of this work is a region-of-interest extractor, which the researchers develop to look at echograms and pull out sections for further analysis and classification; this system obtains a recall of 0.93 in the best case. They then train a classifier that looks at echograms extracted by the region-of-interest module; the top performing system is a DenseNet which obtains a recall scall of 0.85 and an F1 score of 0.82 &ndash; significantly higher than a support vector machine baseline of 0.78 and 0.62.&nbsp;&nbsp;&nbsp;The scores the researchers obtain are encouraging but not sufficiently robust for the real world &ndash; yet. But though the accuracy is sub-par, it could become a useful tool: &ldquo;the ability to measure the abundance of such subjects [fish] over extended periods of time constitutes a strong tool for the study of the effects of water temperature shifts caused by climate change-related phenomena,&rdquo; they write.&nbsp;
Why this matters: I look forward to a day when planet earth is covered in systems automatically listening for and cataloguing wildlife &ndash; I think such systems could give us a richer understanding of our own ecosystems and will likely be a prerequisite for the effective rebuilding of ecosystems as we get our collective act together with regard to catastrophic climate change.&nbsp;
It&rsquo;s a shame that&hellip; the researchers didn&rsquo;t call this software DeepFish, or something similar. HerringVision? FishFinder? The possibilities are as boundless as the ocean itself!&nbsp;&nbsp;&nbsp;Read more: A Deep Learning-based Framework for the Detection of Schools of Herring in Echograms (Arxiv).&nbsp;
####################################################
Want better OCR? Try messing up your data:&hellip;DeepErase promises to take your words, make them dirty, clean them for you, and get smarter in the process&hellip;Researchers with Ernest and Young have created DeepErase, weakly supervized software that &ldquo;inputs a document text image with ink artifacts and outputs the same image with artifacts erased&rdquo;. DeepErase is essentially a pipeline for processing images destined for optical character recognition (OCR) systems; it takes in images, automatically augments them with visual clutter, then trains a classifier to distinguish good images from bad ones. The idea is that, if the software gets good enough, you can use it to automatically identify and clean images before they go to custom in-house OCR software.&nbsp;
How it works: DeepErase takes in some datasets of images of handwritten text, then programmatically generate artifacts for these images, deliberately messing up…