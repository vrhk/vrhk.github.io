---

layout: post
category: product
title: "Import AI 185: Dawn of the planetary search engine; GPT-2 poems; and the UK government’s seven rules for AI providers"
date: 2020-02-17 17:56:36
link: https://vrhk.co/2vJBJYM
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s0.wp.com/i/webclip.png
excerpt: "Dawn of the planetary satellite-imagery search engine:&hellip;Find more images like this, but for satellite imagery&hellip;AI startup Descartes Labs has created a planet-scale search engine that lets people use the equivalent of &lsquo;find more images like this&rsquo;, but instead of uploading an image into a search engine and getting a response back, they upload a picture of somewhere on Earth and get a set of visually similar locations. How they did it: To build this, the authors used four datasets &ndash; for the USA, they used aerial imagery from the National Agriculture Imagery Program (NAIP), as well as the Texas Orthoimagery Program. For the rest of the world, they used data from Landsat 8. They then took a stock 50-layer ResNet pre-trained on ImageNet and made a couple of tweaks &ndash; injecting noise during training to make it easier for the network to learn to make binary classification decisions, they also did light customization for extracting features from networks trained against different datasets. Through this, they gained a set of 512-bit feature vectors, which make it possible to search for complex things like visual similarity. How well does it work: In tests, they get scores of reasonable but not stellar performance, obtaining top-30 accuracies of around 80% when dealing with things they&rsquo;ve fine-tuned the network against. However, in qualitative tests it feels like its performance may be higher than this for most use cases &ndash; I&rsquo;ve played around with the Descartes Labs website where you can test out the system; it does reasonably well when you click around, identifying things like intersections and football stadiums well. I think a lot of the places where it gets confused come from the relatively low resolution of the satellite imagery, making fine-grained judgements more difficult. Why this matters: Systems like this give us a sense of how AI lets us do intuitive things easily that would otherwise be ferociously difficult &ndash; just twenty years ago, asking for a system that could show you similar satellite images would be a vast undertaking with significant amounts of hand-written features and bespoke datasets. Now, it&rsquo;s possible to create this system with a generic pre-trained model, a couple of tweaks, and some generally available unclassified datasets. I think AI systems are going to unlock lots of applications like this, letting us query the world with the sort of intuitive commands (e.g., similar to), that we use our own memories for today.  &nbsp; Read more: Visual search over billions of aerial and satellite images (arXiv). &nbsp; Try the AI-infused search for yourself here (Descartes Labs website).####################################################Generating emotional, dreamlike poems with GPT-2:&hellip;If a poem makes you feel joy or sadness, then is it good?&hellip;Researchers with Drury University and UC-Colorado Springs have created&nbsp; a suite of fine-tuned GPT-2 models for generating poetry with different emotional or stylistic characteristics. Specifically, they create five separate data corpuses of poems that, in their view, represent emotions like anger, anticipation, joy, sadness, and trust. They then fine-tune the medium GPT-2 model against these datasets.  &nbsp; Fine-tuned dream poetry: They also train their model to generate what they call &ldquo;dream poems&rdquo; &ndash; poems that have a dreamlike element. To do this, they take the GPT-2 model and train it on a corpus of first-person dream descriptions, then train it again on a large poetry dataset. Do humans care? The researchers generated a batch of 1,000 poems, then presented four poems from each emotional category to a set of ten human reviewers. &ldquo;Poems presented were randomly selected from the top 20 EmoLex scored poems out of a pool of 1,000 generated poems,&rdquo; they write. The humans were asked to write the poems according to the emotions they felt after reading them &ndash; in tests, they classified the poems based on the joy and sad corpuses as reflecting those emotions 85% and 87.5% of the time, respectively. That&rsquo;s likely because these are relatively easy emotions to categorize with relatively broad categories. By comparison, they correctly categorized things like Anticipation and Trust 40% and 32.5% of the time, respectively. Why this matters: I think language models are increasingly being used like custom funhouse mirrors &ndash; take something you&rsquo;re interested in, like poetry, and tune a language model against it, giving you an artefact that can generate warped reflections of what it was exposed to. I think language models are going to change how we explore and interact with large bodies of literature.  &nbsp; Get the &lsquo;Dreambank&rsquo; dataset used to generate the dream-like poems here.  &nbsp; Read more: Introducing Aspects of Creativity in Automatic Poetry Generation (arXiv). ####################################################Want a responsible AI economy? Do these things, says UK committee:&hellip;Eight tips for governments, seven tips for AI developers..The UK&rsquo;s Committee on Standards in Public Life thinks the government needs to work harder to ensure it uses AI responsibly, and that the providers of AI systems operate in responsible, trustworthy ways. The government has a lot of work to do, according to a new report from the committee: &ldquo;Government is failing on openness,&rdquo; the report says. &ldquo;Public sector organizations are not sufficiently transparent about their use of AI and it is too difficult to find out where machine learning is currently being used in government&rdquo;.What to do about AI if you&rsquo;re a government, national body, or regulator: The committee has eight recommendations designed for potential AI regulators:
Adopt and enforce ethical principles: Figure out which ethical principles to use to guide the use of AI in the public sector (there are currently three sets of principles for the public sector &ndash; the FAST SUM Principles, the OECD AI Principles, and the Data Ethics Framework.
Articulate a clear legal basis for AI usage: Public sector organizations should publish a statement on how their use of AI complies with relevant laws and regulations before they are deployed in public service delivery.&nbsp;
Data bias and anti-discrimination law: Ensure public bodies comply with the Equality Act 2010.&nbsp;
Regulatory assurance body: Create a regulatory assurance body that identifies gaps in the regulatory landscape and provides advice to individual regulators and government on the issues associated with AI.&nbsp;
Procurement rules and processes: Use government procurement procedures to mandate compliance with ethical principles (when selling to public organizations).
The Crown Commercial Service&rsquo;s Digital Marketplace: Create a one-stop shop for finding AI products and services that satisfy ethical requirements.
Impact assessment: Integrate an AI impact assessment into existing processes to evaluate the potential effects of AI on public standards, for a given use case.
What to do if you&rsquo;re an AI provider: The committee also has some specific recommendations for providers of AI services (both public and private-sector). These include:
Evaluate risks to public standards: Assess systems for their potential impact on standards and seek to mitigate standard risks identified.&nbsp;
Diversity: Tackle issues of bias and discrimination by ensuring they take into account &ldquo;the full range of diversity of the population and provide a fair and effective service&rdquo;.
Upholding responsibility: Ensure that responsibility for AI systems is clearly allocated and documented.
Monitoring and evaluation: Moniter and evaluate AI systems to ensure they always operate as intended.
Establishing oversight: Implement oversight systems that allow for their AI systems to be properly scrutinised.
Appeal and redress: AI providers should always tell …"

---

### Import AI 185: Dawn of the planetary search engine; GPT-2 poems; and the UK government’s seven rules for AI providers

Dawn of the planetary satellite-imagery search engine:&hellip;Find more images like this, but for satellite imagery&hellip;AI startup Descartes Labs has created a planet-scale search engine that lets people use the equivalent of &lsquo;find more images like this&rsquo;, but instead of uploading an image into a search engine and getting a response back, they upload a picture of somewhere on Earth and get a set of visually similar locations. How they did it: To build this, the authors used four datasets &ndash; for the USA, they used aerial imagery from the National Agriculture Imagery Program (NAIP), as well as the Texas Orthoimagery Program. For the rest of the world, they used data from Landsat 8. They then took a stock 50-layer ResNet pre-trained on ImageNet and made a couple of tweaks &ndash; injecting noise during training to make it easier for the network to learn to make binary classification decisions, they also did light customization for extracting features from networks trained against different datasets. Through this, they gained a set of 512-bit feature vectors, which make it possible to search for complex things like visual similarity. How well does it work: In tests, they get scores of reasonable but not stellar performance, obtaining top-30 accuracies of around 80% when dealing with things they&rsquo;ve fine-tuned the network against. However, in qualitative tests it feels like its performance may be higher than this for most use cases &ndash; I&rsquo;ve played around with the Descartes Labs website where you can test out the system; it does reasonably well when you click around, identifying things like intersections and football stadiums well. I think a lot of the places where it gets confused come from the relatively low resolution of the satellite imagery, making fine-grained judgements more difficult. Why this matters: Systems like this give us a sense of how AI lets us do intuitive things easily that would otherwise be ferociously difficult &ndash; just twenty years ago, asking for a system that could show you similar satellite images would be a vast undertaking with significant amounts of hand-written features and bespoke datasets. Now, it&rsquo;s possible to create this system with a generic pre-trained model, a couple of tweaks, and some generally available unclassified datasets. I think AI systems are going to unlock lots of applications like this, letting us query the world with the sort of intuitive commands (e.g., similar to), that we use our own memories for today.  &nbsp; Read more: Visual search over billions of aerial and satellite images (arXiv). &nbsp; Try the AI-infused search for yourself here (Descartes Labs website).####################################################Generating emotional, dreamlike poems with GPT-2:&hellip;If a poem makes you feel joy or sadness, then is it good?&hellip;Researchers with Drury University and UC-Colorado Springs have created&nbsp; a suite of fine-tuned GPT-2 models for generating poetry with different emotional or stylistic characteristics. Specifically, they create five separate data corpuses of poems that, in their view, represent emotions like anger, anticipation, joy, sadness, and trust. They then fine-tune the medium GPT-2 model against these datasets.  &nbsp; Fine-tuned dream poetry: They also train their model to generate what they call &ldquo;dream poems&rdquo; &ndash; poems that have a dreamlike element. To do this, they take the GPT-2 model and train it on a corpus of first-person dream descriptions, then train it again on a large poetry dataset. Do humans care? The researchers generated a batch of 1,000 poems, then presented four poems from each emotional category to a set of ten human reviewers. &ldquo;Poems presented were randomly selected from the top 20 EmoLex scored poems out of a pool of 1,000 generated poems,&rdquo; they write. The humans were asked to write the poems according to the emotions they felt after reading them &ndash; in tests, they classified the poems based on the joy and sad corpuses as reflecting those emotions 85% and 87.5% of the time, respectively. That&rsquo;s likely because these are relatively easy emotions to categorize with relatively broad categories. By comparison, they correctly categorized things like Anticipation and Trust 40% and 32.5% of the time, respectively. Why this matters: I think language models are increasingly being used like custom funhouse mirrors &ndash; take something you&rsquo;re interested in, like poetry, and tune a language model against it, giving you an artefact that can generate warped reflections of what it was exposed to. I think language models are going to change how we explore and interact with large bodies of literature.  &nbsp; Get the &lsquo;Dreambank&rsquo; dataset used to generate the dream-like poems here.  &nbsp; Read more: Introducing Aspects of Creativity in Automatic Poetry Generation (arXiv). ####################################################Want a responsible AI economy? Do these things, says UK committee:&hellip;Eight tips for governments, seven tips for AI developers..The UK&rsquo;s Committee on Standards in Public Life thinks the government needs to work harder to ensure it uses AI responsibly, and that the providers of AI systems operate in responsible, trustworthy ways. The government has a lot of work to do, according to a new report from the committee: &ldquo;Government is failing on openness,&rdquo; the report says. &ldquo;Public sector organizations are not sufficiently transparent about their use of AI and it is too difficult to find out where machine learning is currently being used in government&rdquo;.What to do about AI if you&rsquo;re a government, national body, or regulator: The committee has eight recommendations designed for potential AI regulators:
Adopt and enforce ethical principles: Figure out which ethical principles to use to guide the use of AI in the public sector (there are currently three sets of principles for the public sector &ndash; the FAST SUM Principles, the OECD AI Principles, and the Data Ethics Framework.
Articulate a clear legal basis for AI usage: Public sector organizations should publish a statement on how their use of AI complies with relevant laws and regulations before they are deployed in public service delivery.&nbsp;
Data bias and anti-discrimination law: Ensure public bodies comply with the Equality Act 2010.&nbsp;
Regulatory assurance body: Create a regulatory assurance body that identifies gaps in the regulatory landscape and provides advice to individual regulators and government on the issues associated with AI.&nbsp;
Procurement rules and processes: Use government procurement procedures to mandate compliance with ethical principles (when selling to public organizations).
The Crown Commercial Service&rsquo;s Digital Marketplace: Create a one-stop shop for finding AI products and services that satisfy ethical requirements.
Impact assessment: Integrate an AI impact assessment into existing processes to evaluate the potential effects of AI on public standards, for a given use case.
What to do if you&rsquo;re an AI provider: The committee also has some specific recommendations for providers of AI services (both public and private-sector). These include:
Evaluate risks to public standards: Assess systems for their potential impact on standards and seek to mitigate standard risks identified.&nbsp;
Diversity: Tackle issues of bias and discrimination by ensuring they take into account &ldquo;the full range of diversity of the population and provide a fair and effective service&rdquo;.
Upholding responsibility: Ensure that responsibility for AI systems is clearly allocated and documented.
Monitoring and evaluation: Moniter and evaluate AI systems to ensure they always operate as intended.
Establishing oversight: Implement oversight systems that allow for their AI systems to be properly scrutinised.
Appeal and redress: AI providers should always tell …