---

layout: post
category: threads
title: "[R] BERTology Meets Biology: Interpreting Attention in Protein Language Models. Trained solely on unsupervised language modeling, the Transformer's attention mechanism recovers high-level structural (folding) and functional properties of proteins."
date: 2020-07-02 15:57:34
link: https://vrhk.co/3in6aaQ
image: https://external-preview.redd.it/0mXe9R9a5kqvlpvhptoCFeP7IOGPZtB_fgx_1G9lglo.jpg?width=1168&height=611.518324607&auto=webp&crop=1168:611.518324607,smart&s=08a9fff18c043621bf52130bc3ed9c65be340a21
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "**BERTology Meets Biology: Interpreting Attention in Protein Language Models** *Abstract* Transformer architectures have proven to learn useful..."

---

### [R] BERTology Meets Biology: Interpreting Attention in Protein Language Models. Trained solely on unsupervised language modeling, the Transformer's attention mechanism recovers high-level structural (folding) and functional properties of proteins.

**BERTology Meets Biology: Interpreting Attention in Protein Language Models** *Abstract* Transformer architectures have proven to learn useful...