---

layout: post
category: threads
title: "[R] When talking about robustness/regularisation, our community tend to connnect it merely to better test performance. I advocate caring training performance as well"
date: 2020-07-18 16:17:28
link: https://vrhk.co/3hd8EHl
image: https://external-preview.redd.it/iHrYEG8qwA7cfn_fdLYlZ_OHM7FkpobsVdLdG4fjPhI.jpg?width=192&height=100.523560209&auto=webp&crop=192:100.523560209,smart&s=6b5bfa58ebc19f50c0fb4c6fbfd7044d05bc21c0
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "[**Why**](<https://xinshaoamoswang.github.io/blogs/2020-06-14-Robust-Deep-LearningviaDerivativeManipulationIMAE/#when-talking-about-robustnessregula>..."

---

### [R] When talking about robustness/regularisation, our community tend to connnect it merely to better test performance. I advocate caring training performance as well

[**Why**](<https://xinshaoamoswang.github.io/blogs/2020-06-14-Robust-Deep-LearningviaDerivativeManipulationIMAE/#when-talking-about-robustnessregula>...