---

layout: post
category: product
title: "Import AI 188: Get ready for thermal drone vision; Microsoft puts $300,000 up for better AI security; plus, does AI require different publication norms?"
date: 2020-03-09 17:06:38
link: https://vrhk.co/3cIYFbw
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "How Skydio made its NEURAL DRONE:&hellip;Why Skydio built a &lsquo;deep neural pilot&rsquo;, and what this tells us about the maturity of deep RL research&hellip;Drone startup Skydio has become quite notorious in recent years, publishing videos of its incredible flying machines that can follow, chase, film, and track athletes as they carry out performative workouts. Now, in a post on Medium, the company says it has recently been exploring using deep reinforcement learning techniques to teach its drones to move around the world, a symptom of how mature this part of AI research has become.How can you make a neural pilot? Skydio has built some fairly complicated motion planning software for its drones, and initially the company tried to train a neural system off of this, via imitation learning. However, when they tried to do this they failed: &ldquo;Especially within our domain of flying through the air, the exact choice of flight path is a weak signal because there can be many obstacle-free paths that lead to cinematic video,&rdquo; they write. &ldquo;The average scenario overwhelms the training signal&rdquo;. Computational Expert Imitation Learning: They develop an approach they call Computational Expert Imitation Learning (CEILing), where their drone learns not only from expert trajectories generated by the simulator, but also gets reward penalization according to the severity of errors made, which helps the drone efficiently learn how to avoid doing ruinous things like crashing into trees. However, they don&rsquo;t publish enough information about the system to understand the specifics of the technical milestone &ndash; the more interesting thing is that they&rsquo;re experimenting with a deep learning-based RL approach at all.  &nbsp; &ldquo;Although there is still much work to be done before the learned system will outperform our production system, we believe in pursuing leapfrog technologies,&rdquo; they write. &ldquo;Deep reinforcement learning techniques promise to let us improve our entire system in a data-driven way, which will lead to an even smarter autonomous flying camera&rdquo;. Why this matters: At some point, learning-based methods are going to exceed the performance of systems designed by hand. Once that happens, we&rsquo;ll see a rapid proliferation of capabilities in consumer drones, like those made by Skydio. The fact companies like Skydio are already experimenting with these techniques in real world tests suggests the field of RL-based control is maturing rapidly, and may soon break out of the bounds of research into the real, physical world.  &nbsp; Read more: Deep Neural Pilot on Skydio 2 (Medium). &nbsp; Watch a video about the Deep Neural Pilot on Skydio 2 (Hayk Martiros, YouTube). ####################################################Turning Drones into vehicle surveillance tools, with the DroneVehicle dataset:&hellip;All watched over by flying machines of loving grace&hellip;Researchers with Tianjin University, China, have released a dataset of drone-collected overhead imagery. The DroneVehicle dataset is designed to help researchers develop AI systems that can autonomously analyze the world from the sorts of top-down footage taken via drones. The dataset: DroneVehicle consists of 15,532 pairs of RGB and infrared images, captured by drone-mounted dual cameras in a variety of locations in Tianjin, China. The dataset includes annotations for 441,642 object instances across five categories: car, bus, truck, van, and freight car. The inclusion of infrared imagery is interesting &ndash; it&rsquo;s rare to see this modality in datasets, and it could let researchers develop thermal-identifiers alongside visual identifiers.&nbsp; The DroneVehicle challenge: The challenge consists of two tasks: object detection, and object counting and is self-explanatory: try and identify any of the five categories of object in different images and, as a stretch goal, count the number of them. Why this matters: One of the craziest aspects of recent AI advances is how they build on the past two decades of development and miniaturization of consumer electronics systems for sensing (think, the tech that underpins digital cameras and phone cameras) and motion (think, quadcopters). Now that deep learning approaches have matured, we can build software to utilize these sensors, letting us autonomously map and analyze the world around us &ndash; an omni-use capability, that yields new applications in surveillance (scary!) as well as more socially beneficial things (automated traffic and environment analysis, for instance).  &nbsp; Read more: Drone Based RGBT Vehicle Detection and Counting: A Challenge (arXiv). ####################################################Better language AI research via Jiant:&hellip;Giant progress in NLP research requires a Jiant system to test the progress&hellip;Jiant is a software wrapper that makes it trivial to implement various different experimental pipelines into the development of language models. The software depends on Facebook&rsquo;s PyTorch deep learning software, as well as the AllenNLP and HuggingFace&rsquo;s Transformers software libraries (which provide access to language models). Why jiant is useful: jiant handles a couple of fiddly parts of a language model evaluation loop: first, users can define a given experiment via a simple config file (e.g., config = { input_module = &ldquo;roberta-large-cased&rdquo;, pretrain_tasks = &ldquo;record,mnli&rdquo;, target_tasks = &ldquo;boolq, mnli&rdquo;,), and also handles task and sentence encoding in the background. You can run jiant from the command line, so developers can integrate it into their usual workflow. What jiant ships with: jiant supports more than 50 tasks today, ranging from natural language understanding tasks like CommonsenseQA, to SQuAD, to the Schema Challenge. It also ships with support for various modern sentence encoder models, like BERT, GPT-2, ALBERT, and so on. Why this matters: In the past two years, research in natural language processing has been moved forward by the arrival of new, Transformer-based models that have yielded systems capable of generating human-grade synthetic text (for certain short lengths), as well as natural language understanding systems that are capable of performing more sophisticated feats of reasoning. Tools like jiant will make it easier to make this research reproducible by providing a common environment in which to run and replicate experiments. As with most software packages, the utility of jiant will ultimately come down to how many people use it &ndash; so give it a whirl!. Read more: jiant: A Software Toolkit for Research on General-Purpose Text Understanding Models (arXiv). &nbsp; Find out more about jiant at the official website. &nbsp; Get the code for jiant here (jiant GitHub).&nbsp; ####################################################
Microsoft thinks AI will change security, so it wants to pay researchers to help it figure out how:&hellip;$300,000 in funding for better AIsecurity research&hellip;Microsoft is providing funding of up to $150,000 for projects that &ldquo;spark new AI research that will expand our understanding of the enterprise, the threat landscape, and how to secure our customer&rsquo;s assets in the face of increasingly sophisticated attacks,&rdquo; Microsoft wrote. Microsoft has $300,000 in total funding available for the program, and &ldquo;will also consider an additional award of Azure cloud computing credits if warranted by the research&rdquo;. What is Microsoft interested in? Microsoft is keen to look at research proposals in the following areas (non-exhaustive list):&ndash; How can automatic modeling help enterprises autonomously understand their own security?&ndash; How can we identify the risk to the confidentiality, integrity, and availability of ML models?&ndash; How do we meaningfully interrogate ML systems under attack to ascertain the root cause of failure?&ndash; Can we build AI-…"

---

### Import AI 188: Get ready for thermal drone vision; Microsoft puts $300,000 up for better AI security; plus, does AI require different publication norms?

How Skydio made its NEURAL DRONE:&hellip;Why Skydio built a &lsquo;deep neural pilot&rsquo;, and what this tells us about the maturity of deep RL research&hellip;Drone startup Skydio has become quite notorious in recent years, publishing videos of its incredible flying machines that can follow, chase, film, and track athletes as they carry out performative workouts. Now, in a post on Medium, the company says it has recently been exploring using deep reinforcement learning techniques to teach its drones to move around the world, a symptom of how mature this part of AI research has become.How can you make a neural pilot? Skydio has built some fairly complicated motion planning software for its drones, and initially the company tried to train a neural system off of this, via imitation learning. However, when they tried to do this they failed: &ldquo;Especially within our domain of flying through the air, the exact choice of flight path is a weak signal because there can be many obstacle-free paths that lead to cinematic video,&rdquo; they write. &ldquo;The average scenario overwhelms the training signal&rdquo;. Computational Expert Imitation Learning: They develop an approach they call Computational Expert Imitation Learning (CEILing), where their drone learns not only from expert trajectories generated by the simulator, but also gets reward penalization according to the severity of errors made, which helps the drone efficiently learn how to avoid doing ruinous things like crashing into trees. However, they don&rsquo;t publish enough information about the system to understand the specifics of the technical milestone &ndash; the more interesting thing is that they&rsquo;re experimenting with a deep learning-based RL approach at all.  &nbsp; &ldquo;Although there is still much work to be done before the learned system will outperform our production system, we believe in pursuing leapfrog technologies,&rdquo; they write. &ldquo;Deep reinforcement learning techniques promise to let us improve our entire system in a data-driven way, which will lead to an even smarter autonomous flying camera&rdquo;. Why this matters: At some point, learning-based methods are going to exceed the performance of systems designed by hand. Once that happens, we&rsquo;ll see a rapid proliferation of capabilities in consumer drones, like those made by Skydio. The fact companies like Skydio are already experimenting with these techniques in real world tests suggests the field of RL-based control is maturing rapidly, and may soon break out of the bounds of research into the real, physical world.  &nbsp; Read more: Deep Neural Pilot on Skydio 2 (Medium). &nbsp; Watch a video about the Deep Neural Pilot on Skydio 2 (Hayk Martiros, YouTube). ####################################################Turning Drones into vehicle surveillance tools, with the DroneVehicle dataset:&hellip;All watched over by flying machines of loving grace&hellip;Researchers with Tianjin University, China, have released a dataset of drone-collected overhead imagery. The DroneVehicle dataset is designed to help researchers develop AI systems that can autonomously analyze the world from the sorts of top-down footage taken via drones. The dataset: DroneVehicle consists of 15,532 pairs of RGB and infrared images, captured by drone-mounted dual cameras in a variety of locations in Tianjin, China. The dataset includes annotations for 441,642 object instances across five categories: car, bus, truck, van, and freight car. The inclusion of infrared imagery is interesting &ndash; it&rsquo;s rare to see this modality in datasets, and it could let researchers develop thermal-identifiers alongside visual identifiers.&nbsp; The DroneVehicle challenge: The challenge consists of two tasks: object detection, and object counting and is self-explanatory: try and identify any of the five categories of object in different images and, as a stretch goal, count the number of them. Why this matters: One of the craziest aspects of recent AI advances is how they build on the past two decades of development and miniaturization of consumer electronics systems for sensing (think, the tech that underpins digital cameras and phone cameras) and motion (think, quadcopters). Now that deep learning approaches have matured, we can build software to utilize these sensors, letting us autonomously map and analyze the world around us &ndash; an omni-use capability, that yields new applications in surveillance (scary!) as well as more socially beneficial things (automated traffic and environment analysis, for instance).  &nbsp; Read more: Drone Based RGBT Vehicle Detection and Counting: A Challenge (arXiv). ####################################################Better language AI research via Jiant:&hellip;Giant progress in NLP research requires a Jiant system to test the progress&hellip;Jiant is a software wrapper that makes it trivial to implement various different experimental pipelines into the development of language models. The software depends on Facebook&rsquo;s PyTorch deep learning software, as well as the AllenNLP and HuggingFace&rsquo;s Transformers software libraries (which provide access to language models). Why jiant is useful: jiant handles a couple of fiddly parts of a language model evaluation loop: first, users can define a given experiment via a simple config file (e.g., config = { input_module = &ldquo;roberta-large-cased&rdquo;, pretrain_tasks = &ldquo;record,mnli&rdquo;, target_tasks = &ldquo;boolq, mnli&rdquo;,), and also handles task and sentence encoding in the background. You can run jiant from the command line, so developers can integrate it into their usual workflow. What jiant ships with: jiant supports more than 50 tasks today, ranging from natural language understanding tasks like CommonsenseQA, to SQuAD, to the Schema Challenge. It also ships with support for various modern sentence encoder models, like BERT, GPT-2, ALBERT, and so on. Why this matters: In the past two years, research in natural language processing has been moved forward by the arrival of new, Transformer-based models that have yielded systems capable of generating human-grade synthetic text (for certain short lengths), as well as natural language understanding systems that are capable of performing more sophisticated feats of reasoning. Tools like jiant will make it easier to make this research reproducible by providing a common environment in which to run and replicate experiments. As with most software packages, the utility of jiant will ultimately come down to how many people use it &ndash; so give it a whirl!. Read more: jiant: A Software Toolkit for Research on General-Purpose Text Understanding Models (arXiv). &nbsp; Find out more about jiant at the official website. &nbsp; Get the code for jiant here (jiant GitHub).&nbsp; ####################################################
Microsoft thinks AI will change security, so it wants to pay researchers to help it figure out how:&hellip;$300,000 in funding for better AIsecurity research&hellip;Microsoft is providing funding of up to $150,000 for projects that &ldquo;spark new AI research that will expand our understanding of the enterprise, the threat landscape, and how to secure our customer&rsquo;s assets in the face of increasingly sophisticated attacks,&rdquo; Microsoft wrote. Microsoft has $300,000 in total funding available for the program, and &ldquo;will also consider an additional award of Azure cloud computing credits if warranted by the research&rdquo;. What is Microsoft interested in? Microsoft is keen to look at research proposals in the following areas (non-exhaustive list):&ndash; How can automatic modeling help enterprises autonomously understand their own security?&ndash; How can we identify the risk to the confidentiality, integrity, and availability of ML models?&ndash; How do we meaningfully interrogate ML systems under attack to ascertain the root cause of failure?&ndash; Can we build AI-…