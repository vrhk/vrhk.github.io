---

layout: post
category: product
title: "Import AI 167: An aerial crowd hunting dataset; surveying people with the WiderPerson dataset; and testing out space robots for bomb disposal on earth "
date: 2019-10-07 19:46:28
link: https://vrhk.co/2LVgdWA
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Spotting people in crowds with the DLR Aerial Crowd Dataset:&hellip;Aerial photography + AI algorithms = airborne crowd scanners&hellip;One of the main ways we can use modern AI techniques to do helpful things in the world is through counting &ndash; whether counting goods on a production line, or the number of ships in a port, or the re-occurrence of the same face over a certain time period from a certain CCTV camera. A new dataset from the remote sensing technology institute at the German Aerospace Center in Wessling, Germany wants to use a new dataset to make it much easier for us to teach machines to accurately count large numbers of people via overhead imagery.
The DLR Aerial Crowd Dataset: This dataset consists of 33 images captured via DSLR cameras installed on a helicopter. The images come from 16 flights over a variety of events and locations, including sport events, city center views, trade fairs, concerts, and more. Each of these images is absolutely huge, weighing in at around 3600 * 5200 pixels each. There are 226,291 person annotations spread across the dataset. DLR-ACD is the first dataset of its kind, the researchers write, and they hope to use it &ldquo;to promote research on aerial crowd analysis&rdquo;. The majority of the images in ACD contain many thousands of people viewed from overhead, whereas most other aerial datasets involves crowds of less than 1,000 in size, according to analysis by the researchers.&nbsp;
MRCNet: The researchers also develop the Multi-Resolution Crowd Network (MRCNet) which uses an encoder-decoder structure to extract image features and then generate crowd density maps. The system uses two losses at different resolutions to help it count the number of people in the map, as well as providing a coarser map density estimate.
Why this matters: As AI research yields increasingly effective surveillance capabilities, people are going to likely start asking about what it means for these capabilities to diffuse widely across society. Papers like this give us a sense of activity in this domain and hint at future applied advances.&nbsp;&nbsp;&nbsp;Read more: MRCNet: Crowd Counting and Density Map Estimation in Aerial and Ground Imagery (Arxiv).&nbsp;&nbsp;&nbsp;Get the dataset from here (official DLR website).
####################################################
Once Federated Learning works, what happens to big model training?&hellip;How might AI change when distributed model training gets efficient?&hellip;How can technology companies train increasingly large AI systems on increasingly large datasets, without making individual people feel uneasy about their data being used in this way? That&rsquo;s a problem that has catalyzed research by large companies into a range of privacy-preserving techniques for large-scale AI training. One of the most common techniques is federated learning &ndash; the principle of breaking up a big model training run so that you train lots of the model on personal data on end-user devices, then aggregate the insights into a central big blob of compute that you control. The problem with federated learning, though, is that it&rsquo;s expensive, as you need to shuttle data back and forth between end-user devices and your giant central model. New research from the University of Michigan and Facebook outlines a technique that can reduce the training requirements of such federated learning approaches by 20-70%.&nbsp;
Active Federated Learning: UMichigan/Facebook&rsquo;s approach works like this: During each round of model training, Facebook&rsquo;s Active Federated Learning (AFL) algorithm tries to figure out how useful the data of each user is to model training, then uses that to automatically select which users it will sample from next. Another way to think about this is that if the algorithm didn&rsquo;t do any of this, it could end up mostly trying to learn from data held by users who were irrelevant to the thing being optimized, potentially because they don&rsquo;t fit the use case being optimized for. In tests, the researchers said that AFL could let them &ldquo;train models with 20%-70% fewer iterations for the same performance&rdquo; when compared to a random sampling baseline.&nbsp;
Why this matters: Federated learning will happen eventually: it&rsquo;s inevitable, given how much computation is stored on personal phones and computers, that large technology developers eventually figure out a way to harness it. I think that one interesting side-effect of the steady maturing of federated learning technology could be the increasing viability of technical approaches for large-scale, distributed model training for pro-social uses. What might the AI-equivalent of the do-it-yourself protein folding &lsquo;FoldIt @ Home&rsquo; or alien-hunting &lsquo;SETI @ Home&rsquo; systems look like?&nbsp;&nbsp;&nbsp;Read more: Active Federated Learning (Arxiv).&nbsp;
####################################################
Put your smart machine through its paces with DISCOMAN:&hellip;Room navigation dataset adds more types of data to make machines that can navigate the world&hellip;Researchers with Samsung&rsquo;s AI research lab have developed DISCOMAN, a dataset to help people train and benchmarking AI systems for simultaneous location and mapping (SLAM).&nbsp;
The dataset: DISCOMAN contains a bunch of realistic indoor scenes with ground truth labels for odometry, mapping, and semantic segmentation. The entire dataset consists of 200 sequences of a small simulated robot navigating a variety of simulated houses. Each sequence lasts between 3000 and 5000 frames.&nbsp;&nbsp;&nbsp;One of the main things that differentiates DISCOMAN from other datasets is the length of its generated sequences, as well as the fact that agent can get a bunch of different types of data, including depth, stereo, and IMU sensors.&nbsp;&nbsp;&nbsp;Read more: DISCOMAN: Dataset of Indoor SCenes for Odometry, Mapping and Navigation (Arxiv).&nbsp;
####################################################
Surveying people in unprecedented detail with &lsquo;WiderPerson&rsquo;:&hellip;Pedestrian recognition dataset aims to make it easier to train high-performance pedestrian recognition systems&hellip;Researchers with the Chinese Academy of Sciences, the University of Southern California, the Nanjing University of Aeronautics and Astronautics, and Baidu have created the &ldquo;WiderPerson&rdquo; pedestrian detection dataset.&nbsp;
The dataset details: WiderPerson consists of 13,382 images with 399,786 annotations (that&rsquo;s almost 30 annotations per image) and detailed bounding boxes. The researchers gathered the dataset by crawling images from search engines including Google, Bing, and Baidu. They then annotate entities in these images with one of five categories: pedestrians, riders, partially-visible person, crowd, and ignore. On average, each image in WiderPersons contains almost 30 people.&nbsp;
Generalization: Big datasets like WiderPerson are good candidates for pre-training experiments, where you run a model over this dtaa before pointing it to a test task. Here, the researchers test this by pre-training models on WiderPerson then testing them on another dataset, called Caltech-USA: Pre-training on WiderPerson can yield a reasonably good score when evaluated on CalTech, and they show that systems which train on WiderPerson and finetune on Caltech-USA data can beat systems trained purely on Caltech alone. They show the same phenomenon with the &lsquo;CityPersons&rsquo; dataset, suggesting that WiderPerson could be a generally useful dataset for generic pre-training.&nbsp;
Why this matters: The future of surveillance and the future of AI research are closely related. Datasets like WiderPerson illustrate just how close that relationship can be.&nbsp;&nbsp;&nbsp;Read more: WiderPerson: A Diverse Dataset for Dense Pedestrian Detection in the Wild (Arxiv).&nbsp;&nbsp;&nbsp;Get the dataset from here (official WiderPerson website).
########…"

---

### Import AI 167: An aerial crowd hunting dataset; surveying people with the WiderPerson dataset; and testing out space robots for bomb disposal on earth 

Spotting people in crowds with the DLR Aerial Crowd Dataset:&hellip;Aerial photography + AI algorithms = airborne crowd scanners&hellip;One of the main ways we can use modern AI techniques to do helpful things in the world is through counting &ndash; whether counting goods on a production line, or the number of ships in a port, or the re-occurrence of the same face over a certain time period from a certain CCTV camera. A new dataset from the remote sensing technology institute at the German Aerospace Center in Wessling, Germany wants to use a new dataset to make it much easier for us to teach machines to accurately count large numbers of people via overhead imagery.
The DLR Aerial Crowd Dataset: This dataset consists of 33 images captured via DSLR cameras installed on a helicopter. The images come from 16 flights over a variety of events and locations, including sport events, city center views, trade fairs, concerts, and more. Each of these images is absolutely huge, weighing in at around 3600 * 5200 pixels each. There are 226,291 person annotations spread across the dataset. DLR-ACD is the first dataset of its kind, the researchers write, and they hope to use it &ldquo;to promote research on aerial crowd analysis&rdquo;. The majority of the images in ACD contain many thousands of people viewed from overhead, whereas most other aerial datasets involves crowds of less than 1,000 in size, according to analysis by the researchers.&nbsp;
MRCNet: The researchers also develop the Multi-Resolution Crowd Network (MRCNet) which uses an encoder-decoder structure to extract image features and then generate crowd density maps. The system uses two losses at different resolutions to help it count the number of people in the map, as well as providing a coarser map density estimate.
Why this matters: As AI research yields increasingly effective surveillance capabilities, people are going to likely start asking about what it means for these capabilities to diffuse widely across society. Papers like this give us a sense of activity in this domain and hint at future applied advances.&nbsp;&nbsp;&nbsp;Read more: MRCNet: Crowd Counting and Density Map Estimation in Aerial and Ground Imagery (Arxiv).&nbsp;&nbsp;&nbsp;Get the dataset from here (official DLR website).
####################################################
Once Federated Learning works, what happens to big model training?&hellip;How might AI change when distributed model training gets efficient?&hellip;How can technology companies train increasingly large AI systems on increasingly large datasets, without making individual people feel uneasy about their data being used in this way? That&rsquo;s a problem that has catalyzed research by large companies into a range of privacy-preserving techniques for large-scale AI training. One of the most common techniques is federated learning &ndash; the principle of breaking up a big model training run so that you train lots of the model on personal data on end-user devices, then aggregate the insights into a central big blob of compute that you control. The problem with federated learning, though, is that it&rsquo;s expensive, as you need to shuttle data back and forth between end-user devices and your giant central model. New research from the University of Michigan and Facebook outlines a technique that can reduce the training requirements of such federated learning approaches by 20-70%.&nbsp;
Active Federated Learning: UMichigan/Facebook&rsquo;s approach works like this: During each round of model training, Facebook&rsquo;s Active Federated Learning (AFL) algorithm tries to figure out how useful the data of each user is to model training, then uses that to automatically select which users it will sample from next. Another way to think about this is that if the algorithm didn&rsquo;t do any of this, it could end up mostly trying to learn from data held by users who were irrelevant to the thing being optimized, potentially because they don&rsquo;t fit the use case being optimized for. In tests, the researchers said that AFL could let them &ldquo;train models with 20%-70% fewer iterations for the same performance&rdquo; when compared to a random sampling baseline.&nbsp;
Why this matters: Federated learning will happen eventually: it&rsquo;s inevitable, given how much computation is stored on personal phones and computers, that large technology developers eventually figure out a way to harness it. I think that one interesting side-effect of the steady maturing of federated learning technology could be the increasing viability of technical approaches for large-scale, distributed model training for pro-social uses. What might the AI-equivalent of the do-it-yourself protein folding &lsquo;FoldIt @ Home&rsquo; or alien-hunting &lsquo;SETI @ Home&rsquo; systems look like?&nbsp;&nbsp;&nbsp;Read more: Active Federated Learning (Arxiv).&nbsp;
####################################################
Put your smart machine through its paces with DISCOMAN:&hellip;Room navigation dataset adds more types of data to make machines that can navigate the world&hellip;Researchers with Samsung&rsquo;s AI research lab have developed DISCOMAN, a dataset to help people train and benchmarking AI systems for simultaneous location and mapping (SLAM).&nbsp;
The dataset: DISCOMAN contains a bunch of realistic indoor scenes with ground truth labels for odometry, mapping, and semantic segmentation. The entire dataset consists of 200 sequences of a small simulated robot navigating a variety of simulated houses. Each sequence lasts between 3000 and 5000 frames.&nbsp;&nbsp;&nbsp;One of the main things that differentiates DISCOMAN from other datasets is the length of its generated sequences, as well as the fact that agent can get a bunch of different types of data, including depth, stereo, and IMU sensors.&nbsp;&nbsp;&nbsp;Read more: DISCOMAN: Dataset of Indoor SCenes for Odometry, Mapping and Navigation (Arxiv).&nbsp;
####################################################
Surveying people in unprecedented detail with &lsquo;WiderPerson&rsquo;:&hellip;Pedestrian recognition dataset aims to make it easier to train high-performance pedestrian recognition systems&hellip;Researchers with the Chinese Academy of Sciences, the University of Southern California, the Nanjing University of Aeronautics and Astronautics, and Baidu have created the &ldquo;WiderPerson&rdquo; pedestrian detection dataset.&nbsp;
The dataset details: WiderPerson consists of 13,382 images with 399,786 annotations (that&rsquo;s almost 30 annotations per image) and detailed bounding boxes. The researchers gathered the dataset by crawling images from search engines including Google, Bing, and Baidu. They then annotate entities in these images with one of five categories: pedestrians, riders, partially-visible person, crowd, and ignore. On average, each image in WiderPersons contains almost 30 people.&nbsp;
Generalization: Big datasets like WiderPerson are good candidates for pre-training experiments, where you run a model over this dtaa before pointing it to a test task. Here, the researchers test this by pre-training models on WiderPerson then testing them on another dataset, called Caltech-USA: Pre-training on WiderPerson can yield a reasonably good score when evaluated on CalTech, and they show that systems which train on WiderPerson and finetune on Caltech-USA data can beat systems trained purely on Caltech alone. They show the same phenomenon with the &lsquo;CityPersons&rsquo; dataset, suggesting that WiderPerson could be a generally useful dataset for generic pre-training.&nbsp;
Why this matters: The future of surveillance and the future of AI research are closely related. Datasets like WiderPerson illustrate just how close that relationship can be.&nbsp;&nbsp;&nbsp;Read more: WiderPerson: A Diverse Dataset for Dense Pedestrian Detection in the Wild (Arxiv).&nbsp;&nbsp;&nbsp;Get the dataset from here (official WiderPerson website).
########…