---

layout: post
category: engineering
title: "NVIDIA Clocks World’s Fastest BERT Training Time and Largest Transformer Based Model, Paving Path For Advanced Conversational AI"
date: 2019-08-13 13:15:43
link: https://vrhk.co/31ASdNc
image: https://devblogs.nvidia.com/wp-content/uploads/2019/08/Figure-3-Training.jpg
domain: devblogs.nvidia.com
author: "NVIDIA Developer Blog"
icon: https://devblogs.nvidia.com/favicon.ico
excerpt: "NVIDIA DGX SuperPOD trains BERT-Large in just 53 minutes, and trains GPT-2 8B, the largest Transformer Network Ever with 8.3Bn parameters  Conversational AI is an essential building block of human interactions with intelligent machines and applications – from robots and cars, to home assistants and mobile apps. Getting computers to understand human languages, with all their …"

---

### NVIDIA Clocks World’s Fastest BERT Training Time and Largest Transformer Based Model, Paving Path For Advanced Conversational AI | NVIDIA Developer Blog

NVIDIA DGX SuperPOD trains BERT-Large in just 53 minutes, and trains GPT-2 8B, the largest Transformer Network Ever with 8.3Bn parameters  Conversational AI is an essential building block of human interactions with intelligent machines and applications – from robots and cars, to home assistants and mobile apps. Getting computers to understand human languages, with all their …