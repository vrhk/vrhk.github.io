---

layout: post
category: threads
title: "[Research] Plugging backdoor vulnerabilities in neural networks"
date: 2020-07-23 18:37:35
link: https://vrhk.co/3fQi4s6
image: https://external-preview.redd.it/2A8X3CkwJLvyR1hFJyiy63lNjCKahRjnWYSYqELbLLY.jpg?width=1200&height=628.272251309&auto=webp&crop=1200:628.272251309,smart&s=6e999c980160721f173482c0788cfe9728b486b2
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Research shows malicious actors can poison deep learning models by inserting carefully crafted patches in the training data. While detecting these..."

---

### [Research] Plugging backdoor vulnerabilities in neural networks

Research shows malicious actors can poison deep learning models by inserting carefully crafted patches in the training data. While detecting these...