---

layout: post
category: engineering
title: "Minimizing Deep Learning Inference Latency with NVIDIA Multi-Instance GPU"
date: 2020-12-18 18:55:48
link: https://vrhk.co/37wLFFb
image: https://developer-blogs.nvidia.com/wp-content/uploads/2020/12/Flowers_Demo.jpg
domain: developer.nvidia.com
author: "NVIDIA Developer Blog"
icon: 
excerpt: "Recently, NVIDIA unveiled the A100 GPU model, based on the NVIDIA Ampere architecture. Ampere introduced many features, including Multi-Instance GPU (MIG), that play a special role for deep learning…"

---

### Minimizing Deep Learning Inference Latency with NVIDIA Multi-Instance GPU | NVIDIA Developer Blog

Recently, NVIDIA unveiled the A100 GPU model, based on the NVIDIA Ampere architecture. Ampere introduced many features, including Multi-Instance GPU (MIG), that play a special role for deep learning…