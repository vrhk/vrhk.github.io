---

layout: post
category: threads
title: "[N] Test a Distilled GPT-2's generative capabilities"
date: 2019-10-08 20:17:29
link: https://vrhk.co/30Yp1z8
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "At Hugging Face, we recently started distilling models starting with [DistilBERT - a distilled version of BERT](<https://arxiv.org/abs/1910.01108>)...."

---

### [N] Test a Distilled GPT-2's generative capabilities

At Hugging Face, we recently started distilling models starting with [DistilBERT - a distilled version of BERT](<https://arxiv.org/abs/1910.01108>)....