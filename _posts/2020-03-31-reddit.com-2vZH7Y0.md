---

layout: post
category: threads
title: "[D] What is the best system design for sharing GPU(s) across multiple deep learning models? (Trying to optimize inference time, not training time)"
date: 2020-03-31 03:17:38
link: https://vrhk.co/2vZH7Y0
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "I do NOT mean sharding a deep learning model over multiple GPUs. Let's say I have a 12 GB GPU and each of my deep learning models is 1 GB each. I..."

---

### [D] What is the best system design for sharing GPU(s) across multiple deep learning models? (Trying to optimize inference time, not training time)

I do NOT mean sharding a deep learning model over multiple GPUs. Let's say I have a 12 GB GPU and each of my deep learning models is 1 GB each. I...