---

layout: post
category: engineering
title: "BERT inference on G4 instances using Apache MXNet and GluonNLP: 1 million requests for 20 cents"
date: 2020-09-28 17:26:30
link: https://amzn.to/3cKFZIL
image: https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2020/09/23/1-Graph-1.jpg
domain: aws.amazon.com
author: "Amazon Web Services"
icon: http://a0.awsstatic.com/main/images/site/touch-icon-iphone-114-smile.png
excerpt: "Bidirectional Encoder Representations from Transformers (BERT) [1] has become one of the most popular models for natural language processing (NLP) applications. BERT can outperform other models in several NLP tasks, including question answering and sentence classification. Training the BERT model on large datasets is expensive and time consuming, and achieving low latency when performing inference […]"

---

### BERT inference on G4 instances using Apache MXNet and GluonNLP: 1 million requests for 20 cents | Amazon Web Services

Bidirectional Encoder Representations from Transformers (BERT) [1] has become one of the most popular models for natural language processing (NLP) applications. BERT can outperform other models in several NLP tasks, including question answering and sentence classification. Training the BERT model on large datasets is expensive and time consuming, and achieving low latency when performing inference […]