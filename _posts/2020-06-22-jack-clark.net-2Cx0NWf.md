---

layout: post
category: product
title: "Import AI 202: Baidu leaves PAI; ImageNet can live forever with better labels; and what a badly upscaled Obama photo tells us about data bias"
date: 2020-06-22 17:06:38
link: https://vrhk.co/2Cx0NWf
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Making ImageNet live forever with better labels:&hellip;Industry-defining dataset gets new labels for a longer lifespan&hellip;ImageNet is why the recent decade was a boom year for AI &ndash; after all, it was in 2012 that a team of researchers at the University of Toronto used deep learning techniques to make significant progress on the annual ImageNet image recognition competition; their success ultimately led to the mass pivoting of the computer vision research community towards neural methods. The rest, as they say, is history. But is ImageNet still useful, almost a decade later? That&rsquo;s a question contemplated by researchers with Google Brain and DeepMind in a new research paper. Their conclusion is some form of &ldquo;yes, but&rdquo; &ndash; yes, ImageNet is still a useful large-scale training dataset for image systems, but its labels aren&rsquo;t as good as they could be. To remedy this, the researchers develop a set of &ldquo;ReaL&rdquo; reassessed labels for ImageNet, which tries to fix some of the labeling problems inherent to ImageNet, creating a richer dataset of labels for researchers to work with. What&rsquo;s wrong with old ImageNet labels? An old picture of a tool chest might have the label &lsquo;hammer&rsquo;, whereas the new &lsquo;ReaL&rsquo; labels could be any of &lsquo;screwdriver; hammer; power drill; carpenters&rsquo; kit&rsquo; (all of which are in the image). The new labels also fix some of the weird parts of ImageNet &ndash; like a picture of a bus and a passenger car, where the bus is in the foreground but the old correct label is &lsquo;passenger car&rsquo; (whereas the new label is &lsquo;school bus&rsquo;). Why this matters: &ldquo;While ReaL labels seem to be of comparable quality to ImageNet ones for fine-grained clases, they have significantly reduced the noise in the rest, enabling further meaningful progress on this benchmark,&rdquo; the authors write. Specifically, the ReaL ID labels make it more useful to train systems against the ImageNet dataset, because it leads to the development of vision systems with a more robust, broad set of labels. &ldquo;These findings suggest that although the original set of labels may be nearing the end of their useful life, ImageNet and its ReaL labels can readily benchmark progress in visual recognition for the foreseeable future&rdquo;, they write.  &nbsp; Read more: Are we done with ImageNet? (arXiv). &nbsp; Get the new labels: Reassessed labels for the ILSVRC-2012 (&ldquo;ImageNet&rdquo;) validation set (Google Research, GitHub).####################################################Want to count Zebrafish? This dataset might help!&hellip;The smart fishtank cometh&hellip;Researchers with Aalborg University, Denmark, have built a dataset of videos tracking Zebrafish as they move around in a tank. They&rsquo;re releasing the dataset and some baseline models to help people build systems that can automatically track and analyze ZebraFish. The dataset: The dataset consists of eight sequences with a duration between 15 and 120 seconds and 1-10 free moving zebrafish. It has been hand-annotated with 86,400 points and bounding boxes. It also includes tags relating to the occlusion of fish at different points in time, which can help provide data for training systems that are able to analyze schools of fish, rather than individual ones. Why Zebrafish? So, why bother making this? The researchers say it is because &ldquo;Zebrafish is an increasingly popular animal model and behavioural analysis plays a major role in neuroscientific and biological research&rdquo;, but tracking Zebrafish is a complex, tedious process. With this dataset, the researchers hope to spur the construct of robust zebrafish tracking systems which &ldquo;are critically needed to conduct accurate experiments on a grand scale&rdquo;.  &nbsp; Read more: 3D-ZeF: A 3D Zebrafish Tracking Benchmark Dataset (arXiv). &nbsp; Get the dataset here (Multiple Object Tracking Benchmark official site).####################################################Facebook gets its own StreetView with Mapillary acquisition:&hellip;Acquisition gives Facebook lots of data and lots of maps&hellip; Facebook has acquired Mapillary, a startup that had been developing a crowdsourced database of street-level imagery. Mapillary suggests in a blog post that it&rsquo;ll work with Facebook to develop better maps; &ldquo;by merging our efforts, we will further improve the ways that people and machines can work with both aerial and street-level imagery to produce map data,&rdquo; the company writes. Data moats and data maps: Mapping the world is a challenge, because once you&rsquo;ve mapped it, the world keeps changing. That&rsquo;s why companies like Apple and Google have made tremendous investments in infrastructure to regularly map and analyze the world around them (e.g, StreetView). Mapillary may give Facebook access to more data to help it develop sophisticated, current maps. For instance, a few months ago Mapillary announced it had created a dataset of more than 1.6 million images of streets from 30 major cities across six continents (Import AI 196).. &nbsp; &nbsp;  &nbsp; Read more: Mapillary Joins Facebook on the Journey of Improving Maps Everywhere (Mapillary blog). ####################################################Photo upscaling tech highlights bias concerns:&hellip;When photo enhancement magnifies societal biases&hellip;Last week, some researchers with Duke University published information about PULSE, a new photo upscaling technique. This system uses a neural network to upscale low-resolution pixelated picture into high-fidelity counterparts. Unfortunately, how good the neural net is at upscaling stuff depends on a combination of the underlying dataset it was trained on and how well tuned its loss function(s) is. Perhaps because PULSE is so good at upscaling in domains where there&rsquo;s a lot of data (e.g, pictures of white people), then its failures in other domains feel far worse. Broken data means you get Broken Barack Obama: Shortly after publishing the research, some Twitter users started probing the model for biases. And they found some unfortunate stuff:&ndash; Here is the model upscaling Barack Obama into a person with more typically caucasian features.&ndash; Here is a Twitter thread with more examples, where the model tends to skew towards generating caucasian outputs regardless of inputs. &ndash; Here is a more detailed exploration of the Barack Obama example from AI Artist Mario Klingemann, which shows more diversity in the generations (and some fun bugs) &ndash; note this isn&rsquo;t using exactly the same components as PULSE, so treat with a grain of salt. Blame the data or blame the algorithm? In a statement published on GitHub, the PULSE creators say &ldquo;this bias is likely inherited from the dataset StyleGAN was trained on, though there could be other factors that we are unaware of&rdquo;. They say they&rsquo;re going to talk to NVIDIA, which originally developed StyleGAN. However, AI artist Klingemann says &ldquo;StyleGAN is perfectly capable of producing diverse faces, it is their algorithm that fails to capture that diversity&rdquo;. Meanwhile, Yann Lecun, Facebook&rsquo;s head of AI research, says the issue is solely down to data &ndash; &ldquo;train the *exact* same system on a dataset from Senegal, and everyone will look African&rdquo; (this tweet doesn&rsquo;t discuss the issue of dataset creation &ndash; there aren&rsquo;t nearly as many datasets that portray people from Senegal, as those that portray people from other parts of the world).Why this matters: Bias and how it relates to AI is a broad, hard problem in the AI research and deployment space &ndash; that&rsquo;s because bias can creep in at every level, ranging from initial dataset selection, to the techniques used to train models, to the people that develop the systems. Bias is also hard because it relates to machine-readable data, which either means d…"

---

### Import AI 202: Baidu leaves PAI; ImageNet can live forever with better labels; and what a badly upscaled Obama photo tells us about data bias

Making ImageNet live forever with better labels:&hellip;Industry-defining dataset gets new labels for a longer lifespan&hellip;ImageNet is why the recent decade was a boom year for AI &ndash; after all, it was in 2012 that a team of researchers at the University of Toronto used deep learning techniques to make significant progress on the annual ImageNet image recognition competition; their success ultimately led to the mass pivoting of the computer vision research community towards neural methods. The rest, as they say, is history. But is ImageNet still useful, almost a decade later? That&rsquo;s a question contemplated by researchers with Google Brain and DeepMind in a new research paper. Their conclusion is some form of &ldquo;yes, but&rdquo; &ndash; yes, ImageNet is still a useful large-scale training dataset for image systems, but its labels aren&rsquo;t as good as they could be. To remedy this, the researchers develop a set of &ldquo;ReaL&rdquo; reassessed labels for ImageNet, which tries to fix some of the labeling problems inherent to ImageNet, creating a richer dataset of labels for researchers to work with. What&rsquo;s wrong with old ImageNet labels? An old picture of a tool chest might have the label &lsquo;hammer&rsquo;, whereas the new &lsquo;ReaL&rsquo; labels could be any of &lsquo;screwdriver; hammer; power drill; carpenters&rsquo; kit&rsquo; (all of which are in the image). The new labels also fix some of the weird parts of ImageNet &ndash; like a picture of a bus and a passenger car, where the bus is in the foreground but the old correct label is &lsquo;passenger car&rsquo; (whereas the new label is &lsquo;school bus&rsquo;). Why this matters: &ldquo;While ReaL labels seem to be of comparable quality to ImageNet ones for fine-grained clases, they have significantly reduced the noise in the rest, enabling further meaningful progress on this benchmark,&rdquo; the authors write. Specifically, the ReaL ID labels make it more useful to train systems against the ImageNet dataset, because it leads to the development of vision systems with a more robust, broad set of labels. &ldquo;These findings suggest that although the original set of labels may be nearing the end of their useful life, ImageNet and its ReaL labels can readily benchmark progress in visual recognition for the foreseeable future&rdquo;, they write.  &nbsp; Read more: Are we done with ImageNet? (arXiv). &nbsp; Get the new labels: Reassessed labels for the ILSVRC-2012 (&ldquo;ImageNet&rdquo;) validation set (Google Research, GitHub).####################################################Want to count Zebrafish? This dataset might help!&hellip;The smart fishtank cometh&hellip;Researchers with Aalborg University, Denmark, have built a dataset of videos tracking Zebrafish as they move around in a tank. They&rsquo;re releasing the dataset and some baseline models to help people build systems that can automatically track and analyze ZebraFish. The dataset: The dataset consists of eight sequences with a duration between 15 and 120 seconds and 1-10 free moving zebrafish. It has been hand-annotated with 86,400 points and bounding boxes. It also includes tags relating to the occlusion of fish at different points in time, which can help provide data for training systems that are able to analyze schools of fish, rather than individual ones. Why Zebrafish? So, why bother making this? The researchers say it is because &ldquo;Zebrafish is an increasingly popular animal model and behavioural analysis plays a major role in neuroscientific and biological research&rdquo;, but tracking Zebrafish is a complex, tedious process. With this dataset, the researchers hope to spur the construct of robust zebrafish tracking systems which &ldquo;are critically needed to conduct accurate experiments on a grand scale&rdquo;.  &nbsp; Read more: 3D-ZeF: A 3D Zebrafish Tracking Benchmark Dataset (arXiv). &nbsp; Get the dataset here (Multiple Object Tracking Benchmark official site).####################################################Facebook gets its own StreetView with Mapillary acquisition:&hellip;Acquisition gives Facebook lots of data and lots of maps&hellip; Facebook has acquired Mapillary, a startup that had been developing a crowdsourced database of street-level imagery. Mapillary suggests in a blog post that it&rsquo;ll work with Facebook to develop better maps; &ldquo;by merging our efforts, we will further improve the ways that people and machines can work with both aerial and street-level imagery to produce map data,&rdquo; the company writes. Data moats and data maps: Mapping the world is a challenge, because once you&rsquo;ve mapped it, the world keeps changing. That&rsquo;s why companies like Apple and Google have made tremendous investments in infrastructure to regularly map and analyze the world around them (e.g, StreetView). Mapillary may give Facebook access to more data to help it develop sophisticated, current maps. For instance, a few months ago Mapillary announced it had created a dataset of more than 1.6 million images of streets from 30 major cities across six continents (Import AI 196).. &nbsp; &nbsp;  &nbsp; Read more: Mapillary Joins Facebook on the Journey of Improving Maps Everywhere (Mapillary blog). ####################################################Photo upscaling tech highlights bias concerns:&hellip;When photo enhancement magnifies societal biases&hellip;Last week, some researchers with Duke University published information about PULSE, a new photo upscaling technique. This system uses a neural network to upscale low-resolution pixelated picture into high-fidelity counterparts. Unfortunately, how good the neural net is at upscaling stuff depends on a combination of the underlying dataset it was trained on and how well tuned its loss function(s) is. Perhaps because PULSE is so good at upscaling in domains where there&rsquo;s a lot of data (e.g, pictures of white people), then its failures in other domains feel far worse. Broken data means you get Broken Barack Obama: Shortly after publishing the research, some Twitter users started probing the model for biases. And they found some unfortunate stuff:&ndash; Here is the model upscaling Barack Obama into a person with more typically caucasian features.&ndash; Here is a Twitter thread with more examples, where the model tends to skew towards generating caucasian outputs regardless of inputs. &ndash; Here is a more detailed exploration of the Barack Obama example from AI Artist Mario Klingemann, which shows more diversity in the generations (and some fun bugs) &ndash; note this isn&rsquo;t using exactly the same components as PULSE, so treat with a grain of salt. Blame the data or blame the algorithm? In a statement published on GitHub, the PULSE creators say &ldquo;this bias is likely inherited from the dataset StyleGAN was trained on, though there could be other factors that we are unaware of&rdquo;. They say they&rsquo;re going to talk to NVIDIA, which originally developed StyleGAN. However, AI artist Klingemann says &ldquo;StyleGAN is perfectly capable of producing diverse faces, it is their algorithm that fails to capture that diversity&rdquo;. Meanwhile, Yann Lecun, Facebook&rsquo;s head of AI research, says the issue is solely down to data &ndash; &ldquo;train the *exact* same system on a dataset from Senegal, and everyone will look African&rdquo; (this tweet doesn&rsquo;t discuss the issue of dataset creation &ndash; there aren&rsquo;t nearly as many datasets that portray people from Senegal, as those that portray people from other parts of the world).Why this matters: Bias and how it relates to AI is a broad, hard problem in the AI research and deployment space &ndash; that&rsquo;s because bias can creep in at every level, ranging from initial dataset selection, to the techniques used to train models, to the people that develop the systems. Bias is also hard because it relates to machine-readable data, which either means d…