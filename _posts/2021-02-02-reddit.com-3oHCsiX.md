---

layout: post
category: threads
title: "[D] Paper Explained - Feedback Transformers: Addressing Some Limitations of Transformers with Feedback Memory (Full Video Analysis)"
date: 2021-02-02 16:27:45
link: https://vrhk.co/3oHCsiX
image: https://external-preview.redd.it/yNOq2HS2PAzb3uR5FlmewMs_pbJHNYim1bSgdX1hgWc.jpg?width=480&height=251.308900524&auto=webp&crop=480:251.308900524,smart&s=c6dc48b45abb25752131c389c3841535022f0e7a
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "[<https://youtu.be/zdb8MM94A5c>](<https://youtu.be/zdb8MM94A5c>) Autoregressive Transformers have taken over the world of Language Modeling (GPT-3)...."

---

### [D] Paper Explained - Feedback Transformers: Addressing Some Limitations of Transformers with Feedback Memory (Full Video Analysis)

[<https://youtu.be/zdb8MM94A5c>](<https://youtu.be/zdb8MM94A5c>) Autoregressive Transformers have taken over the world of Language Modeling (GPT-3)....