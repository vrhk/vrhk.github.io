---

layout: post
category: product
title: "Import AI 233: AI needs AI designers; estimating COVID risk with AI; the dreams of an old computer programmer."
date: 2021-01-25 16:36:34
link: https://vrhk.co/3a142SN
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Facebook trains a COVID-risk-estimating X-ray image analysis system:&hellip;Collaboration with NYU yields a COVID-spotting AI model&hellip;Facebook has worked with NYU to analyze chest X-rays from people with COVID and has created an AI system that can roughly estimate risks for different people. One of the things this work sheds light on is the different amounts of data we need for training systems from scratch versus fine-tuning them.How they made it: They pre-trained their system on the MIMIC-CXR dataset (377,110 chest x-rays), and CheXpert (224,316) photographs &ndash; neither of these contained pictures of x-rays with COVID symptoms, though did include patients with a range of chest conditions. They then finetuned this on a dataset gathered by NYU, consisting of 26,838 X-rays from patients exhibiting a variety of COVID symptoms. They then train a system to try to predict adverse events and symptoms indicating increased oxygen requirements.&nbsp; Did it work? In tests, the system developed by the NYU/Facebook team outperformed that of a prior COVID detection model (COVID-GMIC) when predicting events out from 48, 72, and 96 hours. It had slightly worse performance when making 24 hour predictions. They also compared the performance of their system against two human radiologists and had better accuracy at 48. 72, and 96 hours than people, and performed slightly worse than them when doing prediction over a 24 hour period. However, &ldquo;It is possible that with further calibration, radiologist performance could be improved for the task of adverse event prediction&rdquo;, they note.&nbsp; Read more: COVID-19 Deterioration Prediction via Self-Supervised Representation Learning and Multi-Image Prediction (arXiv).&nbsp; Get the code here (Facebook, GitHub).###################################################AI needs its own design practice:&hellip;Microsoft researcher lays out the case for more intentional design&hellip;In 2021, AI systems matter. They&rsquo;re being deployed into the economy and they&rsquo;re changing the world. Isn&rsquo;t it time we took a more disciplined approach on how we design these systems and ensure they work for people? That&rsquo;s the idea put forth by Josh Lovejoy, the head of design at Ethics &amp; Society at Microsoft, in a lengthy post called: When are we going to start designing AI with purpose?Three questions everyone designing AI should ask:&ndash; &ldquo;Capability: What is uniquely AI and what is uniquely human?&rdquo;&ndash; &ldquo;Accuracy: What does &ldquo;working as-intended&rdquo; mean for a probabilistic system?&rdquo;&ndash; &ldquo;Learnability: How will people build &mdash; and rebuild &mdash; trust in something that&rsquo;s inherently fallible?&rdquo;Remember the human interacting with your AI system: Along with thinking about system design, people should try to understand the humans interacting with the system &ndash; what will their mental workload be? How situationally aware will they be? Will they be complacent? Will their skills degrade as they become dependent on the AI system itself.What happens if you screw this up? Then people will either misuse your technology (e.g, using it in ways its creators didn&rsquo;t intend, leading to poor performance), or disuse it (not use it because it didn&rsquo;t match their expectations).What can we do to help people use AI effectively? AI developers can make their creations easier to understand by people by adopting a few common practices, including using reference points to help people understand what an AI system might be &lsquo;thinking&rsquo;, optionality so they can choose between recommendations made by a system, nearest neighbors that give a sense of other alternatives the AI was looking at (e.g, a subtly different genre of music would be a nearest neighbor, while a song within the same genre currently being thought about would be an optionality), and they should generally use a card sorting approach to get the system to display a uniform number of different options to people.&nbsp;&nbsp; Read more: When are we going to start designing AI with purpose (UX Collective).###################################################Finally, a million AI-generated anime characters:Do generated anime characters dream of electric humans?A bunch of researchers have created , a website showcasing over a million AI-generated images, made possible by a StyleGANv2 implementation trained on top of the massive Danbooru dataset. I recommend browsing the website &ndash; a few years ago, the idea we could capture all of these rich, stylized images and synthesize them was a pipe dream. Now, here we are, with a bunch of (extremely talented) hacker/hobbyists able to create something that lets people interact with a vast, creative AI model. Bonus points for the addition of a &lsquo;creativity slider&rsquo; so people can vary the temperature and develop intuitions about what this means.&nbsp; &nbsp; Check out the infinite anime here ().&nbsp; &nbsp; Read more about this in the official launch blogpost (NearCyan, personal website).###################################################AI Policy with Matthew van der Merwe:&hellip;Matthew van der Merwe brings you views on AI and AI policy; I (lightly) edit them&hellip;



Face recognition vs the insurrectionists:(H/T CSET&rsquo;s excellent  newsletter)



Face recognition technology is being used by law enforcement investigating the Jan 6th attack on the US Capitol. Clearview AI, used by 2,400 US agencies, saw a 26 percent spike in usage after the attack, with police departments in Florida and Alabama confirming they are using the software to identify suspects in the attack. The extensive footage shared by participants &mdash; ProPublica has collected more than 500 videos from Parler &mdash;is presumably a gift to investigators.&nbsp; Read more: The facial-recognition app Clearview sees a spike in use after Capitol attack (NYT)



Deepfakes and the departed:A Korean TV show has used AI to stage new performances by popular musicians who died tragically young, in their 30s. Lifelike &lsquo;hologram&rsquo; videos of the artists perform on stage alongside other musicians, accompanied by AI-generated vocal tracks, to an audience including the singers&rsquo; families. One clip features Kim Hyun-sik, one of the biggest Korean artists of the 1980s. Another features Turtleman (aka Lim Sung-hoon), the lead singer of hip hop group Turtles. I found the performances, and the reactions of their families, very moving.&nbsp;



&nbsp;&nbsp;&nbsp;Chatbot simulacra: In a similar vein, last month Microsoft filed a patent for a chatbot that simulates an individual based on their messaging data &mdash; while there&rsquo;s no mention of using it to simulate the deceased, commentators have been quick to make the link. (For a great fictional exploration of this sort of tech, see the Black Mirror episode &lsquo;Be Right Back&rsquo;.) Meanwhile, last year people used similar tech to reanimate the victim of a school shooting so they could synthetically campaign for further gun control laws (Import AI 217).



&nbsp;&nbsp;&nbsp;Matthew&rsquo;s view: This seems like a relatively benign use of deepfakes. It&rsquo;s probably unwise to draw too many conclusions from a reality TV show in a language I don&rsquo;t understand, but it raises some interesting issues. I wonder how improved generative AI might shape our experience of death and loss, by facilitating meaningful/novel interactions with vivid representations of the deceased. Lest we think this is all too unprecedented, it&rsquo;s worth recalling how profound an impact things like photography, video, and social media have already had on how we experience grief.&nbsp;Read more: Deepfake technology in music welcomed, with caution (Korea Times)&nbsp;



White House launches National AI Initiative Office (NAIIO)Days from the end of the Trump presidency, the White House established an office for coordinating the government&rsqu…"

---

### Import AI 233: AI needs AI designers; estimating COVID risk with AI; the dreams of an old computer programmer.

Facebook trains a COVID-risk-estimating X-ray image analysis system:&hellip;Collaboration with NYU yields a COVID-spotting AI model&hellip;Facebook has worked with NYU to analyze chest X-rays from people with COVID and has created an AI system that can roughly estimate risks for different people. One of the things this work sheds light on is the different amounts of data we need for training systems from scratch versus fine-tuning them.How they made it: They pre-trained their system on the MIMIC-CXR dataset (377,110 chest x-rays), and CheXpert (224,316) photographs &ndash; neither of these contained pictures of x-rays with COVID symptoms, though did include patients with a range of chest conditions. They then finetuned this on a dataset gathered by NYU, consisting of 26,838 X-rays from patients exhibiting a variety of COVID symptoms. They then train a system to try to predict adverse events and symptoms indicating increased oxygen requirements.&nbsp; Did it work? In tests, the system developed by the NYU/Facebook team outperformed that of a prior COVID detection model (COVID-GMIC) when predicting events out from 48, 72, and 96 hours. It had slightly worse performance when making 24 hour predictions. They also compared the performance of their system against two human radiologists and had better accuracy at 48. 72, and 96 hours than people, and performed slightly worse than them when doing prediction over a 24 hour period. However, &ldquo;It is possible that with further calibration, radiologist performance could be improved for the task of adverse event prediction&rdquo;, they note.&nbsp; Read more: COVID-19 Deterioration Prediction via Self-Supervised Representation Learning and Multi-Image Prediction (arXiv).&nbsp; Get the code here (Facebook, GitHub).###################################################AI needs its own design practice:&hellip;Microsoft researcher lays out the case for more intentional design&hellip;In 2021, AI systems matter. They&rsquo;re being deployed into the economy and they&rsquo;re changing the world. Isn&rsquo;t it time we took a more disciplined approach on how we design these systems and ensure they work for people? That&rsquo;s the idea put forth by Josh Lovejoy, the head of design at Ethics &amp; Society at Microsoft, in a lengthy post called: When are we going to start designing AI with purpose?Three questions everyone designing AI should ask:&ndash; &ldquo;Capability: What is uniquely AI and what is uniquely human?&rdquo;&ndash; &ldquo;Accuracy: What does &ldquo;working as-intended&rdquo; mean for a probabilistic system?&rdquo;&ndash; &ldquo;Learnability: How will people build &mdash; and rebuild &mdash; trust in something that&rsquo;s inherently fallible?&rdquo;Remember the human interacting with your AI system: Along with thinking about system design, people should try to understand the humans interacting with the system &ndash; what will their mental workload be? How situationally aware will they be? Will they be complacent? Will their skills degrade as they become dependent on the AI system itself.What happens if you screw this up? Then people will either misuse your technology (e.g, using it in ways its creators didn&rsquo;t intend, leading to poor performance), or disuse it (not use it because it didn&rsquo;t match their expectations).What can we do to help people use AI effectively? AI developers can make their creations easier to understand by people by adopting a few common practices, including using reference points to help people understand what an AI system might be &lsquo;thinking&rsquo;, optionality so they can choose between recommendations made by a system, nearest neighbors that give a sense of other alternatives the AI was looking at (e.g, a subtly different genre of music would be a nearest neighbor, while a song within the same genre currently being thought about would be an optionality), and they should generally use a card sorting approach to get the system to display a uniform number of different options to people.&nbsp;&nbsp; Read more: When are we going to start designing AI with purpose (UX Collective).###################################################Finally, a million AI-generated anime characters:Do generated anime characters dream of electric humans?A bunch of researchers have created , a website showcasing over a million AI-generated images, made possible by a StyleGANv2 implementation trained on top of the massive Danbooru dataset. I recommend browsing the website &ndash; a few years ago, the idea we could capture all of these rich, stylized images and synthesize them was a pipe dream. Now, here we are, with a bunch of (extremely talented) hacker/hobbyists able to create something that lets people interact with a vast, creative AI model. Bonus points for the addition of a &lsquo;creativity slider&rsquo; so people can vary the temperature and develop intuitions about what this means.&nbsp; &nbsp; Check out the infinite anime here ().&nbsp; &nbsp; Read more about this in the official launch blogpost (NearCyan, personal website).###################################################AI Policy with Matthew van der Merwe:&hellip;Matthew van der Merwe brings you views on AI and AI policy; I (lightly) edit them&hellip;



Face recognition vs the insurrectionists:(H/T CSET&rsquo;s excellent  newsletter)



Face recognition technology is being used by law enforcement investigating the Jan 6th attack on the US Capitol. Clearview AI, used by 2,400 US agencies, saw a 26 percent spike in usage after the attack, with police departments in Florida and Alabama confirming they are using the software to identify suspects in the attack. The extensive footage shared by participants &mdash; ProPublica has collected more than 500 videos from Parler &mdash;is presumably a gift to investigators.&nbsp; Read more: The facial-recognition app Clearview sees a spike in use after Capitol attack (NYT)



Deepfakes and the departed:A Korean TV show has used AI to stage new performances by popular musicians who died tragically young, in their 30s. Lifelike &lsquo;hologram&rsquo; videos of the artists perform on stage alongside other musicians, accompanied by AI-generated vocal tracks, to an audience including the singers&rsquo; families. One clip features Kim Hyun-sik, one of the biggest Korean artists of the 1980s. Another features Turtleman (aka Lim Sung-hoon), the lead singer of hip hop group Turtles. I found the performances, and the reactions of their families, very moving.&nbsp;



&nbsp;&nbsp;&nbsp;Chatbot simulacra: In a similar vein, last month Microsoft filed a patent for a chatbot that simulates an individual based on their messaging data &mdash; while there&rsquo;s no mention of using it to simulate the deceased, commentators have been quick to make the link. (For a great fictional exploration of this sort of tech, see the Black Mirror episode &lsquo;Be Right Back&rsquo;.) Meanwhile, last year people used similar tech to reanimate the victim of a school shooting so they could synthetically campaign for further gun control laws (Import AI 217).



&nbsp;&nbsp;&nbsp;Matthew&rsquo;s view: This seems like a relatively benign use of deepfakes. It&rsquo;s probably unwise to draw too many conclusions from a reality TV show in a language I don&rsquo;t understand, but it raises some interesting issues. I wonder how improved generative AI might shape our experience of death and loss, by facilitating meaningful/novel interactions with vivid representations of the deceased. Lest we think this is all too unprecedented, it&rsquo;s worth recalling how profound an impact things like photography, video, and social media have already had on how we experience grief.&nbsp;Read more: Deepfake technology in music welcomed, with caution (Korea Times)&nbsp;



White House launches National AI Initiative Office (NAIIO)Days from the end of the Trump presidency, the White House established an office for coordinating the government&rsqu…