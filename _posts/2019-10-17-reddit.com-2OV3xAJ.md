---

layout: post
category: threads
title: "[D] Temporal coherence in transformers ? Why Fixed length inputs in Al-Rfou(2018) ?"
date: 2019-10-17 16:12:47
link: https://vrhk.co/2OV3xAJ
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Why use fixed length sequences in transformer ? In what way and why does it effect the performance and training of transformer ? Why did they not..."

---

### [D] Temporal coherence in transformers ? Why Fixed length inputs in Al-Rfou(2018) ?

Why use fixed length sequences in transformer ? In what way and why does it effect the performance and training of transformer ? Why did they not...