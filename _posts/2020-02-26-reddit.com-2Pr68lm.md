---

layout: post
category: threads
title: "[R] When Two-Layer ReLU Networks Provably Fail With High Probability"
date: 2020-02-26 09:37:36
link: https://vrhk.co/2Pr68lm
image: https://external-preview.redd.it/sjKtZ0yQTI3LIaL_ocNPbvYMpOeKfvuwOndrXMWm1wg.jpg?width=140&height=73.2984293194&auto=webp&crop=140:73.2984293194,smart&s=25021e56833e92c444d3d2e44516714c0eb10720
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "**Title:** **Training Two-Layer ReLU Networks with Gradient Descent is Inconsistent** (First author here.) We prove that for certain types of..."

---

### [R] When Two-Layer ReLU Networks Provably Fail With High Probability

**Title:** **Training Two-Layer ReLU Networks with Gradient Descent is Inconsistent** (First author here.) We prove that for certain types of...