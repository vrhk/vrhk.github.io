---

layout: post
category: threads
title: "[R] Transformer Attention as an Implicit Mixture of Effective Energy-Based Models"
date: 2020-12-25 09:37:27
link: https://vrhk.co/3ro7hM9
image: https://external-preview.redd.it/1I4k0F4apfbMJ5GCC-fFZ0YkzhNoEAN70JOwwJzVGno.jpg?width=923&height=360&auto=webp&crop=923:360,smart&s=a8785ab14f9bc4b0bbbb9113fd60d8be2f5c3c28
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "[<https://mcbal.github.io/post/transformer-attention-as-an-implicit-mixture-of-effective-energy-based-models/>](<https://mcbal.github.io/post/transfor>..."

---

### [R] Transformer Attention as an Implicit Mixture of Effective Energy-Based Models

[<https://mcbal.github.io/post/transformer-attention-as-an-implicit-mixture-of-effective-energy-based-models/>](<https://mcbal.github.io/post/transfor>...