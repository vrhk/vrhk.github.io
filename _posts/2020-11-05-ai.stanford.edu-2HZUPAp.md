---

layout: post
category: research
title: "Adapting on the Fly to Test Time Distribution Shift"
date: 2020-11-05 18:30:45
link: https://vrhk.co/2HZUPAp
image: http://ai.stanford.edu/blog/assets/img/posts/2020-11-05-adaptive-risk-minimization/intro.png
domain: ai.stanford.edu
author: "SAIL Blog"
icon: http://ai.stanford.edu/blog/assets/img/favicon-32x32.png
excerpt: "Imagine that you are building the next generation machine learning model for handwriting transcription. Based on previous iterations of your product, you have identified a key challenge for this rollout: after deployment, new end users often have different and unseen handwriting styles, leading to distribution shift. One solution for this challenge is to learn an adaptive model that can specialize and adjust to each user’s handwriting style over time. This solution seems promising, but it must be balanced against concerns about ease of use: requiring users to provide feedback to the model may be cumbersome and hinder adoption. Is it possible instead to learn a model that can adapt to new users without labels?"

---

### Adapting on the Fly to Test Time Distribution Shift

Imagine that you are building the next generation machine learning model for handwriting transcription. Based on previous iterations of your product, you have identified a key challenge for this rollout: after deployment, new end users often have different and unseen handwriting styles, leading to distribution shift. One solution for this challenge is to learn an adaptive model that can specialize and adjust to each user’s handwriting style over time. This solution seems promising, but it must be balanced against concerns about ease of use: requiring users to provide feedback to the model may be cumbersome and hinder adoption. Is it possible instead to learn a model that can adapt to new users without labels?