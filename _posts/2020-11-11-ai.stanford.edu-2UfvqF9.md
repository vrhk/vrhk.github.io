---

layout: post
category: research
title: "Measuring Bias in NLP (with Confidence!)"
date: 2020-11-11 07:30:44
link: https://vrhk.co/2UfvqF9
image: http://ai.stanford.edu/blog/assets/img/posts/2020-11-11-bias-nlp/scales.png
domain: ai.stanford.edu
author: "SAIL Blog"
icon: http://ai.stanford.edu/blog/assets/img/favicon-32x32.png
excerpt: "Countless studies have found that “bias” – typically with respect to race and gender – pervades the embeddings and predictions of the black-box models that dominate natural language processing (NLP). For example, the language model GPT-3, of OpenAI fame, can generate racist rants when given the right prompt. Attempts to detect hate speech can itself harm minority populations, whose dialect is more likely to be flagged as hateful."

---

### Measuring Bias in NLP (with Confidence!)

Countless studies have found that “bias” – typically with respect to race and gender – pervades the embeddings and predictions of the black-box models that dominate natural language processing (NLP). For example, the language model GPT-3, of OpenAI fame, can generate racist rants when given the right prompt. Attempts to detect hate speech can itself harm minority populations, whose dialect is more likely to be flagged as hateful.