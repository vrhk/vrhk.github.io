---

layout: post
category: threads
title: "[D] Generalization problem with large batch sizes, why are we using TPUs?"
date: 2020-08-18 16:17:28
link: https://vrhk.co/3aBveY8
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Multiple publications and blogs mentions that training with large batch sizes reduce the generalization and the model receives higher test error...."

---

### [D] Generalization problem with large batch sizes, why are we using TPUs?

Multiple publications and blogs mentions that training with large batch sizes reduce the generalization and the model receives higher test error....