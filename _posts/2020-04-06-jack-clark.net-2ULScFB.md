---

layout: post
category: product
title: "Import AI 192: Would you live in a GAN-built house?; why medical AI needs an ingredient list; plus, Facebook brews up artificial life"
date: 2020-04-06 17:36:41
link: https://vrhk.co/2ULScFB
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "TartainAir challenges SLAM systems to navigate around lurching robot arms:&hellip;Simulated dataset gives researchers 4TB of data to test navigation systems against&hellip;How can we make smarter robots without destroying them? The answer is to find smarter ways to simulate experiences for our robots, so we can test them out rapidly in software-based environments, rather than having to run them in the physical world. New research from Carnegie Mellon University, the Chinese University of Hong Kong, Tongji University, and Microsoft Research, gives us TartanAir, a dataset meant to push the limits of visual simultaneous location and mapping systems (SLAM). What is TartanAir? TartanAir is a dataset of high-fidelity environments rendered in Unreal Engine, collected via Microsoft&rsquo;s AirSim software (for more on AirSim: Import AI #30). &ldquo;A special focus of our dataset is on the challenging environments with changing light conditions, low illumination, adverse weather and dynamic objects&rdquo;, the researchers write. TartanAir consists of 1037 long motion sequences collected from simulated agents traversing 30 environments, representing 4TB of data in total. Environments range from factories, to lush forests, to cities, rendered in a variety of different ways.  &nbsp; Multi-modal data inputs: Besides the visual inputs, TartanAir data is accompanied by data relating to stereo disparity, simulated LiDAR, optical flow data, depth data, and pose data.  &nbsp; Multi-modal scenes: The visual scenes themselves come in a variety of forms, with environments available in different lighting, weather, and seasonal conditions.  &nbsp;&nbsp;Dynamic objects: The simulator also includes environments that contain objects that move, like factories with industrial arms, and oceans full of fish that dart around, and cities with people that stroll down the streets. Why this matters: As the COVID pandemic sweeps across the world, I find it oddly emotionally affecting to remember that we&rsquo;re able to build elaborate simulations that let us give AI agents compute-enabled dreams of exploration. Just as we find ourselves stuck indoors and dreaming of the outside, our AI agents find themselves stuck on SSDs, dreaming of taking flight in all the worlds we can imagine for them. (More prosaically, systems like TartanAir serve as fuel for research into the creation of more advanced mapping and navigation systems).  &nbsp; Read more: TartanAir: A Dataset to Push the Limits of Visual SLAM (arXiv).  &nbsp; Get access to the data here (official TartanAir page).
####################################################Why medical AI systems need lists of ingredients:&hellip;Duke Researchers introduce &lsquo;Model Facts&rsquo;&hellip;In recent years, there&rsquo;s been a drive to add more documentation to accompany AI models. This has so far taken the form of things like Google&rsquo;s Model Cards for Model Reporting, or Microsoft&rsquo;s Datasheets for Datasets, where people try to come up with standardized ways of talking about the ingredients and capabilities of a given AI model. These labeling schemes are helpful because they encourage developers to spend time explaining their AI systems to other people, and provide a disincentive for doing too much skeezy stuff (as disclosing it in the form of a model card generates a potential PR headache).  &nbsp; Now, researchers with Duke University have tried to figure out a labeling scheme for the medical domain. Their &ldquo;Model Facts&rdquo; label &ldquo;was designed for clinicians who make decisions supported by a machine learning model and its purpose is to collate relevant, actionable information in 1-page,&rdquo; they write. What should be on a medical AI label? We should use these labels to describe the mechanism by which the model communicates information (e.g., a probability score and how to interpret it); the generally recommended uses of the model, along with caveats explaining where it does and doesn&rsquo;t generalize; and, perhaps most importantly, a set of warnings outlining where the model might fail or have an unpredictable effect. Labels should also be customized according to the population the system is deployed against, as different groups of people will have different medical sensitivities. Why this matters: Labeling is a prerequisite for more responsible AI development; by encouraging standardized labeling of models we can discourage the AI equivalent of using harmful ingredients in foodstuffs, and we can create valuable metadata about deployed models which researchers can likely use to analyze the state of the field at large. Label all the things! &nbsp; Read more: Presenting machine learning model information to clinical end users with model facts labels (Nature). ####################################################Turn yourself into a renaissance painting &ndash; if you dare!&hellip;Things that seem like toys usually precede greater changes&hellip;AI. It can help us predict novel protein structures. Map the wonders of the Earth from space. Translate between languages. And now&hellip; it can help take a picture of you and turn it into a renaissance-style painting! Try out the &lsquo;AI Gahaku&rsquo; website and consider donating some money to fund it so other people can do the same.  Why this matters: One of the ways technologies make their way into society is via toys or seemingly trivial entertainment devices &ndash; systems that can shapeshift one data distribution (realworld photographs) into another (renaissance-style illustrations) are just the beginning. &nbsp; Try it out yourself: AI Gahaku (official website).
####################################################Welcome, please make yourself comfortable in my GAN-generated house:&hellip;Generating houses with relational networks&hellip;Researchers with Simon Fraser University and Autodesk Research have built House-GAN, a system to automatically generate floorplans for houses. How it works: House-GAN should be pretty familiar to most GAN-fans:&ndash; Assemble a dataset of real floorplans (in this case, LIFULL HOME, a database of five million real floorplans, from which they used ~120,000)&ndash; Convert these floorplans into graphs representing the connections between different room&ndash; Feed these graphs into a relational generator and a discriminator system, which compete against each other to generate realistic-seeming graphs&ndash; Render the resulting graphs into floorplans&ndash; [magic happens]&ndash; Move into your computationally-generated GAN mansion Lets get relational: One interesting quirk of this research is the use of relational networks, specifically a convolutional message passing neural network (Conv-MPN). I&rsquo;ve been seeing more and more people use relational nets in recent research, so this feels like a trend worth watching. In tests, the researchers show that relational systems significantly outperform ones based on traditional convolutional neural nets. They&rsquo;re able to use this approach to generate floorplans with different constraints, like the number of rooms and their spatial adjacencies. Why this matters: These generative systems are making it easier and easier for us to teach computers to create warped copies of reality &ndash; imagine the implications of being able to automatically generate versions of anything you can gather a large dataset for? That&rsquo;s the world we&rsquo;re heading to. &nbsp; Read more: House-GAN: Relational Generative Adversarial Networks for Graph-constrained House Layout Generation (arXiv).####################################################Facebook makes combinatory chemical system, in search of artificial life: &hellip;Detects surprising emergent structures after simulating life for ten million steps&hellip;Many AI researchers have a longstanding fascination with artificial life: emergent systems that, via simple rules, lead to surprising complexity. The idea is that given a good enough sys…"

---

### Import AI 192: Would you live in a GAN-built house?; why medical AI needs an ingredient list; plus, Facebook brews up artificial life

TartainAir challenges SLAM systems to navigate around lurching robot arms:&hellip;Simulated dataset gives researchers 4TB of data to test navigation systems against&hellip;How can we make smarter robots without destroying them? The answer is to find smarter ways to simulate experiences for our robots, so we can test them out rapidly in software-based environments, rather than having to run them in the physical world. New research from Carnegie Mellon University, the Chinese University of Hong Kong, Tongji University, and Microsoft Research, gives us TartanAir, a dataset meant to push the limits of visual simultaneous location and mapping systems (SLAM). What is TartanAir? TartanAir is a dataset of high-fidelity environments rendered in Unreal Engine, collected via Microsoft&rsquo;s AirSim software (for more on AirSim: Import AI #30). &ldquo;A special focus of our dataset is on the challenging environments with changing light conditions, low illumination, adverse weather and dynamic objects&rdquo;, the researchers write. TartanAir consists of 1037 long motion sequences collected from simulated agents traversing 30 environments, representing 4TB of data in total. Environments range from factories, to lush forests, to cities, rendered in a variety of different ways.  &nbsp; Multi-modal data inputs: Besides the visual inputs, TartanAir data is accompanied by data relating to stereo disparity, simulated LiDAR, optical flow data, depth data, and pose data.  &nbsp; Multi-modal scenes: The visual scenes themselves come in a variety of forms, with environments available in different lighting, weather, and seasonal conditions.  &nbsp;&nbsp;Dynamic objects: The simulator also includes environments that contain objects that move, like factories with industrial arms, and oceans full of fish that dart around, and cities with people that stroll down the streets. Why this matters: As the COVID pandemic sweeps across the world, I find it oddly emotionally affecting to remember that we&rsquo;re able to build elaborate simulations that let us give AI agents compute-enabled dreams of exploration. Just as we find ourselves stuck indoors and dreaming of the outside, our AI agents find themselves stuck on SSDs, dreaming of taking flight in all the worlds we can imagine for them. (More prosaically, systems like TartanAir serve as fuel for research into the creation of more advanced mapping and navigation systems).  &nbsp; Read more: TartanAir: A Dataset to Push the Limits of Visual SLAM (arXiv).  &nbsp; Get access to the data here (official TartanAir page).
####################################################Why medical AI systems need lists of ingredients:&hellip;Duke Researchers introduce &lsquo;Model Facts&rsquo;&hellip;In recent years, there&rsquo;s been a drive to add more documentation to accompany AI models. This has so far taken the form of things like Google&rsquo;s Model Cards for Model Reporting, or Microsoft&rsquo;s Datasheets for Datasets, where people try to come up with standardized ways of talking about the ingredients and capabilities of a given AI model. These labeling schemes are helpful because they encourage developers to spend time explaining their AI systems to other people, and provide a disincentive for doing too much skeezy stuff (as disclosing it in the form of a model card generates a potential PR headache).  &nbsp; Now, researchers with Duke University have tried to figure out a labeling scheme for the medical domain. Their &ldquo;Model Facts&rdquo; label &ldquo;was designed for clinicians who make decisions supported by a machine learning model and its purpose is to collate relevant, actionable information in 1-page,&rdquo; they write. What should be on a medical AI label? We should use these labels to describe the mechanism by which the model communicates information (e.g., a probability score and how to interpret it); the generally recommended uses of the model, along with caveats explaining where it does and doesn&rsquo;t generalize; and, perhaps most importantly, a set of warnings outlining where the model might fail or have an unpredictable effect. Labels should also be customized according to the population the system is deployed against, as different groups of people will have different medical sensitivities. Why this matters: Labeling is a prerequisite for more responsible AI development; by encouraging standardized labeling of models we can discourage the AI equivalent of using harmful ingredients in foodstuffs, and we can create valuable metadata about deployed models which researchers can likely use to analyze the state of the field at large. Label all the things! &nbsp; Read more: Presenting machine learning model information to clinical end users with model facts labels (Nature). ####################################################Turn yourself into a renaissance painting &ndash; if you dare!&hellip;Things that seem like toys usually precede greater changes&hellip;AI. It can help us predict novel protein structures. Map the wonders of the Earth from space. Translate between languages. And now&hellip; it can help take a picture of you and turn it into a renaissance-style painting! Try out the &lsquo;AI Gahaku&rsquo; website and consider donating some money to fund it so other people can do the same.  Why this matters: One of the ways technologies make their way into society is via toys or seemingly trivial entertainment devices &ndash; systems that can shapeshift one data distribution (realworld photographs) into another (renaissance-style illustrations) are just the beginning. &nbsp; Try it out yourself: AI Gahaku (official website).
####################################################Welcome, please make yourself comfortable in my GAN-generated house:&hellip;Generating houses with relational networks&hellip;Researchers with Simon Fraser University and Autodesk Research have built House-GAN, a system to automatically generate floorplans for houses. How it works: House-GAN should be pretty familiar to most GAN-fans:&ndash; Assemble a dataset of real floorplans (in this case, LIFULL HOME, a database of five million real floorplans, from which they used ~120,000)&ndash; Convert these floorplans into graphs representing the connections between different room&ndash; Feed these graphs into a relational generator and a discriminator system, which compete against each other to generate realistic-seeming graphs&ndash; Render the resulting graphs into floorplans&ndash; [magic happens]&ndash; Move into your computationally-generated GAN mansion Lets get relational: One interesting quirk of this research is the use of relational networks, specifically a convolutional message passing neural network (Conv-MPN). I&rsquo;ve been seeing more and more people use relational nets in recent research, so this feels like a trend worth watching. In tests, the researchers show that relational systems significantly outperform ones based on traditional convolutional neural nets. They&rsquo;re able to use this approach to generate floorplans with different constraints, like the number of rooms and their spatial adjacencies. Why this matters: These generative systems are making it easier and easier for us to teach computers to create warped copies of reality &ndash; imagine the implications of being able to automatically generate versions of anything you can gather a large dataset for? That&rsquo;s the world we&rsquo;re heading to. &nbsp; Read more: House-GAN: Relational Generative Adversarial Networks for Graph-constrained House Layout Generation (arXiv).####################################################Facebook makes combinatory chemical system, in search of artificial life: &hellip;Detects surprising emergent structures after simulating life for ten million steps&hellip;Many AI researchers have a longstanding fascination with artificial life: emergent systems that, via simple rules, lead to surprising complexity. The idea is that given a good enough sys…