---

layout: post
category: threads
title: "[R] mT5: A massively multilingual pre-trained text-to-text transformer that supports over 100 languages. SoTA on many cross-lingual NLP tasks. Pre-trained models, code for training and fine-tuning in comments."
date: 2020-10-23 05:07:26
link: https://vrhk.co/3dPUU4O
image: https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?width=600&height=314.136125654&auto=webp&crop=600:314.136125654,smart&s=512847f3b280746dabbf5c5b436734fdd9ee0508
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Posted in r/MachineLearning by u/hardmaru • 4 points and 2 comments"

---

### [R] mT5: A massively multilingual pre-trained text-to-text transformer that supports over 100 languages. SoTA on many cross-lingual NLP tasks. Pre-trained models, code for training and fine-tuning in comments.

Posted in r/MachineLearning by u/hardmaru • 4 points and 2 comments