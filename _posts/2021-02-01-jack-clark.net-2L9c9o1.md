---

layout: post
category: product
title: "Import AI 234: Pre-training with fractals; compute&amp;countries; GANS for good"
date: 2021-02-01 17:56:40
link: https://vrhk.co/2L9c9o1
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Where we&rsquo;re going we don&rsquo;t need data &ndash; we&rsquo;ll pre-train on FRACTALS!!!!&hellip;This research technique is straight out of a Baudrillard notebook&hellip;In Simulacra and Simulation by French philosopher Jean Baudrillard, he argues that human society has become reliant on simulations of reality, with us trafficking in abstractions &ndash; international finance, televised wars &ndash; that feel in some way more real than the thing they&rsquo;re meant to reference. Now, AI researchers are producing papers that, I&rsquo;m sure, would get Baudrillard excited: research from National Institute of Advanced Industrial Science and Technology (AIST), Tokyo Institute of Technology, and Tokyo Denki University, proposes a way to simulate the data necessary to pre-train a vision model, then fine-tune this model on reality. Specifically, they build a dataset called FractalDB which contains several thousand fractals split across a variety of different automatically generated categories. Their experiment shows that they can pre-train on FractalDB then finetune using other datasets (e.g, ImageNet, OmniGlot, Cifar-10), and get performance that is close to using the natural datasets and, in some cases, is better. This isn&rsquo;t a homerun, but it&rsquo;s encouraging.What they did: To do this, they built a fractal generation system which had a few tunable parameters. They then evaluated their approach by using FractalDB as a potential input for pre-training, then evaluated downstream performance.&nbsp; &nbsp; Specific results: &ldquo;FractalDB1k / 10k pre-trained models recorded much higher accuracies than models trained from scratch on relatively small-scale datasets (C10/100, VOC12 and OG). In case of fine-tuning on large-scale datasets (ImageNet/Places365), the effect of pre-training was relatively small. However, in fine-tuning on Places 365, the FractalDB-10k pretrained model helped to improve the performance rate which was also higher than ImageNet-1k pre-training (FractalDB-10k 50.8 vs. ImageNet-1k 50.3)&rdquo; How this fits into the larger picture &ndash; computers become data generators: Real data is expensive, complicated, and slow to gather. That&rsquo;s why the reinforcement learning community has spent decades working in simulators &ndash; e.g, training agents to play Atari, or Go, or explore 3D worlds in a rewritten Quake engine (DeepMind Lab). It&rsquo;s also led researchers to find creative ways to augment real datasets &ndash; e.g, by multiplying the size of an image dataset by flipping the images, adding textures, changing colors and textures, and so on. All of these techniques have proved helpful.&nbsp; Now, if researchers can build simulators to generate arbitrary amounts of data, they might be able to further change the cost curve of data generation. This might have weird economic and strategic implications: if you can simulate your data using a computer program, then you can change the ratio of real versus simulated/augmented data you need. This has the potential to both speed up AI development and also increase the inherent value of computers as primary AI infrastructure &ndash; not only can we use these devices to train and develop algorithms, but we can use them to generate the input &lsquo;fuel&rsquo; for some of the more interesting capabilities. &nbsp;&nbsp; Read more: Pre-training without Natural Images (arXiv).###################################################Using a big anime dataset to train character distinguishers:&hellip;Illustrations + fine-grained character recognition &hellip;Researchers with National Chiao Tung University in Taiwan have built DAF:re (DanbooruAnimeFaces:revamped). DAF:re is a subset of the massive &lsquo;Danbooru&rsquo; Anime dataset (see Import AI 233., filtered to just include heads of different characters. The resulting dataset consists of ~467,000 images across 3,263 distinct character classes. Why do this? Datasets like DAF:re will let people explore fine-grained analysis of stylized pictures (like anime), and could potentially serve as benchmarks for exploring the generalization of vision models trained on a mixture of normal and illustrated images. If it becomes widely used, it could end up being another proxy signal for the broader rate of progress in this type of work. I also expect that, given the vast fanbase for a lot of anime, we&rsquo;ll see more projects like this, and perhaps they&rsquo;ll ultimately help filter, analyze, and map the cultural space of anime writ large. &nbsp; Reader note: This dataset uses cropped photos of faces, but the larger dataset involves images of a sexual nature (including the SFW one).&nbsp; Read more: DAF:re: A Challenging, Crowd-Sourced, Large-Scale, Long-Tailed Dataset For Anime Character Recognition (arXiv).&nbsp; Get the code for the classification stuff here (Animesion, GitHub). ###################################################Big AI means big infrastructure:&hellip;OpenAI* scales Kubernetes to 7,500 nodes&hellip;OpenAI is running Kubernetes across ~7,500 nodes. Why does this matter? Kubernetes is a bit like an air-traffic control system for large-scale computing; the software helps schedule different jobs onto different bits of hardware (think of this as like assigning planes spots on the ground), and also handles things like contention (stopping planes crashing into eachother), and efficiency (prioritizing getting planes up and down quickly and efficiently). 7,500 is up from the 2,500 OpenAI disclosed in 2018. It&rsquo;s worth reading these posts because they give a sense of the complexity of the infrastructure that supports large-scale AI workloads.&nbsp; Read more: Scaling Kubernetes to 7,500 Nodes (OpenAI).*Note: I used to work at OpenAI and no longer work there.###################################################The OECD is going to try and get a handle on AI &amp; Compute:&hellip;Working group, which I&rsquo;m in, will try to solve a persistent policy problem&hellip;We talk about computers a lot in this newsletter. That&rsquo;s because computers are one of the ingredients for AI and, in recent years, some types of AI have started to require a lot of computation.&nbsp; This has created a typical &lsquo;haves&rsquo; and &lsquo;have nots&rsquo; situation at all levels of society, ranging from the difference between an individual researcher with an RTX3080 versus one without, to different funding amounts across academic labs, to different capital expenditures by companies, to differences in compute provisioning across entire nations.&nbsp; Now, the Organization for Economic Co-operation and Development (OECD) wants to help governments get a handle on this issue by putting together a project focused on mapping out AI and its relationship to Compute and how this relates to government policies. I&rsquo;m going to be a member of this group and will be trying to speak publicly about it as much as I am able. Thanks to VentureBeat&rsquo;s Khari Johnson for covering the group&hellip; more to come!  &nbsp; Read more: Why the OECD wants to calculate the AI compute needs of national governments (VentureBeat).###################################################German cops might use generative models to make child porn (to help them catch predators):&hellip;German law highlights the omni-use nature of AI technology&hellip;Synthetic imagery is about to be all around us &ndash; recent advances in generative models have made it possible to tweak existing images or come up with entirely synthetic ones, ranging from people (see: deepfakes), to anime (see: thisanimedoesnotexist in #233), to stylized cartoons (see: DALL-E) . The vast majority of these usecases will be benign, but some will likely be malicious &ndash; e.g, creating fake headshots of people to aid in creating fake identities, or making mysognistic pornography of people who haven&rsquo;t given consent, or spreading disinformation via synthetic images.&nbsp; But what if there was a way to use some …"

---

### Import AI 234: Pre-training with fractals; compute&amp;countries; GANS for good

Where we&rsquo;re going we don&rsquo;t need data &ndash; we&rsquo;ll pre-train on FRACTALS!!!!&hellip;This research technique is straight out of a Baudrillard notebook&hellip;In Simulacra and Simulation by French philosopher Jean Baudrillard, he argues that human society has become reliant on simulations of reality, with us trafficking in abstractions &ndash; international finance, televised wars &ndash; that feel in some way more real than the thing they&rsquo;re meant to reference. Now, AI researchers are producing papers that, I&rsquo;m sure, would get Baudrillard excited: research from National Institute of Advanced Industrial Science and Technology (AIST), Tokyo Institute of Technology, and Tokyo Denki University, proposes a way to simulate the data necessary to pre-train a vision model, then fine-tune this model on reality. Specifically, they build a dataset called FractalDB which contains several thousand fractals split across a variety of different automatically generated categories. Their experiment shows that they can pre-train on FractalDB then finetune using other datasets (e.g, ImageNet, OmniGlot, Cifar-10), and get performance that is close to using the natural datasets and, in some cases, is better. This isn&rsquo;t a homerun, but it&rsquo;s encouraging.What they did: To do this, they built a fractal generation system which had a few tunable parameters. They then evaluated their approach by using FractalDB as a potential input for pre-training, then evaluated downstream performance.&nbsp; &nbsp; Specific results: &ldquo;FractalDB1k / 10k pre-trained models recorded much higher accuracies than models trained from scratch on relatively small-scale datasets (C10/100, VOC12 and OG). In case of fine-tuning on large-scale datasets (ImageNet/Places365), the effect of pre-training was relatively small. However, in fine-tuning on Places 365, the FractalDB-10k pretrained model helped to improve the performance rate which was also higher than ImageNet-1k pre-training (FractalDB-10k 50.8 vs. ImageNet-1k 50.3)&rdquo; How this fits into the larger picture &ndash; computers become data generators: Real data is expensive, complicated, and slow to gather. That&rsquo;s why the reinforcement learning community has spent decades working in simulators &ndash; e.g, training agents to play Atari, or Go, or explore 3D worlds in a rewritten Quake engine (DeepMind Lab). It&rsquo;s also led researchers to find creative ways to augment real datasets &ndash; e.g, by multiplying the size of an image dataset by flipping the images, adding textures, changing colors and textures, and so on. All of these techniques have proved helpful.&nbsp; Now, if researchers can build simulators to generate arbitrary amounts of data, they might be able to further change the cost curve of data generation. This might have weird economic and strategic implications: if you can simulate your data using a computer program, then you can change the ratio of real versus simulated/augmented data you need. This has the potential to both speed up AI development and also increase the inherent value of computers as primary AI infrastructure &ndash; not only can we use these devices to train and develop algorithms, but we can use them to generate the input &lsquo;fuel&rsquo; for some of the more interesting capabilities. &nbsp;&nbsp; Read more: Pre-training without Natural Images (arXiv).###################################################Using a big anime dataset to train character distinguishers:&hellip;Illustrations + fine-grained character recognition &hellip;Researchers with National Chiao Tung University in Taiwan have built DAF:re (DanbooruAnimeFaces:revamped). DAF:re is a subset of the massive &lsquo;Danbooru&rsquo; Anime dataset (see Import AI 233., filtered to just include heads of different characters. The resulting dataset consists of ~467,000 images across 3,263 distinct character classes. Why do this? Datasets like DAF:re will let people explore fine-grained analysis of stylized pictures (like anime), and could potentially serve as benchmarks for exploring the generalization of vision models trained on a mixture of normal and illustrated images. If it becomes widely used, it could end up being another proxy signal for the broader rate of progress in this type of work. I also expect that, given the vast fanbase for a lot of anime, we&rsquo;ll see more projects like this, and perhaps they&rsquo;ll ultimately help filter, analyze, and map the cultural space of anime writ large. &nbsp; Reader note: This dataset uses cropped photos of faces, but the larger dataset involves images of a sexual nature (including the SFW one).&nbsp; Read more: DAF:re: A Challenging, Crowd-Sourced, Large-Scale, Long-Tailed Dataset For Anime Character Recognition (arXiv).&nbsp; Get the code for the classification stuff here (Animesion, GitHub). ###################################################Big AI means big infrastructure:&hellip;OpenAI* scales Kubernetes to 7,500 nodes&hellip;OpenAI is running Kubernetes across ~7,500 nodes. Why does this matter? Kubernetes is a bit like an air-traffic control system for large-scale computing; the software helps schedule different jobs onto different bits of hardware (think of this as like assigning planes spots on the ground), and also handles things like contention (stopping planes crashing into eachother), and efficiency (prioritizing getting planes up and down quickly and efficiently). 7,500 is up from the 2,500 OpenAI disclosed in 2018. It&rsquo;s worth reading these posts because they give a sense of the complexity of the infrastructure that supports large-scale AI workloads.&nbsp; Read more: Scaling Kubernetes to 7,500 Nodes (OpenAI).*Note: I used to work at OpenAI and no longer work there.###################################################The OECD is going to try and get a handle on AI &amp; Compute:&hellip;Working group, which I&rsquo;m in, will try to solve a persistent policy problem&hellip;We talk about computers a lot in this newsletter. That&rsquo;s because computers are one of the ingredients for AI and, in recent years, some types of AI have started to require a lot of computation.&nbsp; This has created a typical &lsquo;haves&rsquo; and &lsquo;have nots&rsquo; situation at all levels of society, ranging from the difference between an individual researcher with an RTX3080 versus one without, to different funding amounts across academic labs, to different capital expenditures by companies, to differences in compute provisioning across entire nations.&nbsp; Now, the Organization for Economic Co-operation and Development (OECD) wants to help governments get a handle on this issue by putting together a project focused on mapping out AI and its relationship to Compute and how this relates to government policies. I&rsquo;m going to be a member of this group and will be trying to speak publicly about it as much as I am able. Thanks to VentureBeat&rsquo;s Khari Johnson for covering the group&hellip; more to come!  &nbsp; Read more: Why the OECD wants to calculate the AI compute needs of national governments (VentureBeat).###################################################German cops might use generative models to make child porn (to help them catch predators):&hellip;German law highlights the omni-use nature of AI technology&hellip;Synthetic imagery is about to be all around us &ndash; recent advances in generative models have made it possible to tweak existing images or come up with entirely synthetic ones, ranging from people (see: deepfakes), to anime (see: thisanimedoesnotexist in #233), to stylized cartoons (see: DALL-E) . The vast majority of these usecases will be benign, but some will likely be malicious &ndash; e.g, creating fake headshots of people to aid in creating fake identities, or making mysognistic pornography of people who haven&rsquo;t given consent, or spreading disinformation via synthetic images.&nbsp; But what if there was a way to use some …