---

layout: post
category: product
title: "Import AI 198: TSMC+USA = Chiplomacy; open source Deepfakes; and environmental justice via ML tools"
date: 2020-05-18 18:46:33
link: https://vrhk.co/3cUyxtG
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Facebook wants an AI that can spot&hellip; offensive memes?&hellip;The Hateful Memes Challenge is more serious than it sounds&hellip;Facebook wants researchers to build AI systems that can spot harmful or hateful memes. This is a challenging problem: &ldquo;Consider a sentence like &ldquo;love the way you smell today&rdquo; or &ldquo;look how many people love you&rdquo;. Unimodally, these sentences are harmless, but combine them with an equally harmless image of a skunk or a tumbleweed, and suddenly they become mean,&rdquo; Facebook writes.The Hateful Memes Challenge: Now, similar to its prior &lsquo;Deepfake Detection Challenge&rsquo;, Facebook wants help from the wider AI community in developing systems that can better identify hateful memes. To do this, it has partnered with Getty images to generate a dataset of hateful memes that also shows sensitivity to those content-miners of the internet, meme creators.  &nbsp; &ldquo;One important issue with respect to dataset creation is having clarity around licensing of the underlying content. We&rsquo;ve constructed our dataset specifically with this in mind. Instead of trying to release original memes with unknown creators, we use &ldquo;in the wild&rdquo; memes to manually reconstruct new memes by placing, without loss of meaning, meme text over a new underlying stock image. These new underlying images were obtained in partnership with Getty Images under a license negotiated to allow redistribution for research purposes,&rdquo; they write.The key figure: AI systems can get around 65% accuracy, while humans get around 85% accuracy &ndash; that&rsquo;s a big gap to close. Why this is hard from a research perspective: This is an inherently multimodal challenge &ndash; successful hateful meme-spotting systems won&rsquo;t be able to solely condition off of the text or the image contents of a given meme, but will have to analyze both things together and jointly reason about them. It makes sense, then, that some of the baseline systems developed by Facebook use pre-training: typically, they train systems on large datasets, then finetune these models on the meme data. Therefore, progress on this competition might encourage progress on multimodal work as a whole. Enter the competition, get the data: You can sign up for the competition and access the dataset here: Hateful Memes Challenge and Data Set (Facebook). &nbsp; Read more: The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes (arXiv). ####################################################Care about publication norms in machine learning? Join an online discussion next week!The Montreal AI Ethics Institute and the Partnership on AI have teamed up to host an online workshop about &ldquo;publication norms for responsible AI&rdquo;. This is part of a project by PAI to better understand how the ML community can public research responsibly, while accounting for the impacts of AI technology to minimize downsides and maximize upsides.  &nbsp; Sign up for the free discussion here (Eventbrite). ####################################################Covid = Social Distancing = Robots++One side-effect of COVID may be a push towards more types of automation. The CEO of robot shopping company Simbe Robotics says: &ldquo;It creates an opportunity where there is actually more social distancing in the environment because the tasks are being performed by a robot and not a person,&rdquo; according to Bloomberg. In other words &ndash; robots might be a cleaner way of cleaning. Expect more of this. &nbsp; Check out the quick video here (Bloomberg QuickTake, Twitter).####################################################Deepfake systems are well-documented, open source commodity tech now. What happens next?&hellip;DeepFaceLab paper lays out how to build a Deepfake system&hellip;Deepfakes, the slang term given to AI technologies that let you take someone&rsquo;s face and superimpose it on someone else in an image or video, are a problem for the AI sector. That&rsquo;s because deepfakes are made out of basic, multi-purpose AI systems that are themselves typically open source. And while some of the uses of deepfakes could be socially useful, like being able to create new forms of art, many of their immediate applications skew towards the malicious end of the spectrum, namely: pornography (particularly revenge porn) and vehicles for spreading politicial disinformation.  &nbsp; So what do we do when Deepfakes are not only well documented in terms of code, but also integrated into consumer-friendly software systems? That&rsquo;s the conundrem raised by DeepFaceLab, open source software on GitHubs for the creation of deepfakes. In a new research paper, the lead author of DeepFaceLab (Ivan Petrov) and his collaborators (mostly freelancers, or Publication norms and AI research: The paper doesn&rsquo;t contain much detailed discussion of the inherent ethics of publishing or not publishing this technology. Their justification for this paper is, recursively, a quote of a prior justification from a 2019 paper about FSGAN: Subject Agnostic Face Swapping and Reenactment: &ldquo;Suppressing the publication of such methods would not stop their development, but rather make them only available to a limited number of experts and potentially blindside policy makers if it goes without any limits&rdquo;. Based on this quote, the DeepFaceLab authors say they &ldquo;found we are responsible to publish DeepFaceLab to the academia community formally&rdquo;. Why this matters: We&rsquo;re in the uncanny valley of AI research, these days: we can make systems that generate synthetic text, images, video, and more. The reigning norm in the research community tends towards fully open source code and research. I think it&rsquo;s unclear if this is long-term the smartest approach to take if you&rsquo;re keen to minimize downsides (see: today, deepfakes are mostly used for porn, which doesn&rsquo;t seem like an especially useful use of societal resources, especially since it inherently damages the economic bargaining power of human pornstars). We live in interesting times&hellip; &nbsp; Read more: DeepFaceLab: A simple, flexible and extensible face swapping framework (arXiv). &nbsp; Check out the code for DeepFaceLab here (GitHub).####################################################Facebook makes an ultra-cheap voice generator:&hellip;What samples two times a second and sounds like a human?&hellip;In recent years, peopl;e have started using neural network-based techniques to synthesize voices for AI-based text-to-speech programs. This is the sort of technology that gives voice to Apple&rsquo;s Siri, Amazon&rsquo;s Alexa, and Google&rsquo;s whatever-it-is. When generating these synthetic voices, there&rsquo;s typically a tradeoff between efficiency (how fast you can generate the voice on your computer) and quality (how good it sounds). Facebook has developed some new approaches that give it a 160X speedup over its internal baseline, which means it can generate voices &ldquo;in real time using regular CPUs &ndash; without any specialized hardware&rdquo;. With this technology, Facebook hopes to make &ldquo;new voice applications that sound more human and expressive and are more enjoyable to use&rdquo;. The tech has already been deployed inside Facebook&rsquo;s &lsquo;Portal&rsquo; videocalling system, as well as in applications like reading assistance and virtual reality. What it takes to make a computer talk: Facebook&rsquo;s system has four elements that, added together, create an expressive voice:&ndash; A front-end that converts text into linguistic features&ndash; A prosody model that predicts the rhythm and melody to create natural-sounding speech&ndash; An acoustic model which generates the spectral representation of the speech&ndash; A neura; vocoder that generates am24 kHz speech waveform, which is conditioned on prosody and spectral featuresGoing from an expensive to a cheap system: Facebook&rsq…"

---

### Import AI 198: TSMC+USA = Chiplomacy; open source Deepfakes; and environmental justice via ML tools

Facebook wants an AI that can spot&hellip; offensive memes?&hellip;The Hateful Memes Challenge is more serious than it sounds&hellip;Facebook wants researchers to build AI systems that can spot harmful or hateful memes. This is a challenging problem: &ldquo;Consider a sentence like &ldquo;love the way you smell today&rdquo; or &ldquo;look how many people love you&rdquo;. Unimodally, these sentences are harmless, but combine them with an equally harmless image of a skunk or a tumbleweed, and suddenly they become mean,&rdquo; Facebook writes.The Hateful Memes Challenge: Now, similar to its prior &lsquo;Deepfake Detection Challenge&rsquo;, Facebook wants help from the wider AI community in developing systems that can better identify hateful memes. To do this, it has partnered with Getty images to generate a dataset of hateful memes that also shows sensitivity to those content-miners of the internet, meme creators.  &nbsp; &ldquo;One important issue with respect to dataset creation is having clarity around licensing of the underlying content. We&rsquo;ve constructed our dataset specifically with this in mind. Instead of trying to release original memes with unknown creators, we use &ldquo;in the wild&rdquo; memes to manually reconstruct new memes by placing, without loss of meaning, meme text over a new underlying stock image. These new underlying images were obtained in partnership with Getty Images under a license negotiated to allow redistribution for research purposes,&rdquo; they write.The key figure: AI systems can get around 65% accuracy, while humans get around 85% accuracy &ndash; that&rsquo;s a big gap to close. Why this is hard from a research perspective: This is an inherently multimodal challenge &ndash; successful hateful meme-spotting systems won&rsquo;t be able to solely condition off of the text or the image contents of a given meme, but will have to analyze both things together and jointly reason about them. It makes sense, then, that some of the baseline systems developed by Facebook use pre-training: typically, they train systems on large datasets, then finetune these models on the meme data. Therefore, progress on this competition might encourage progress on multimodal work as a whole. Enter the competition, get the data: You can sign up for the competition and access the dataset here: Hateful Memes Challenge and Data Set (Facebook). &nbsp; Read more: The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes (arXiv). ####################################################Care about publication norms in machine learning? Join an online discussion next week!The Montreal AI Ethics Institute and the Partnership on AI have teamed up to host an online workshop about &ldquo;publication norms for responsible AI&rdquo;. This is part of a project by PAI to better understand how the ML community can public research responsibly, while accounting for the impacts of AI technology to minimize downsides and maximize upsides.  &nbsp; Sign up for the free discussion here (Eventbrite). ####################################################Covid = Social Distancing = Robots++One side-effect of COVID may be a push towards more types of automation. The CEO of robot shopping company Simbe Robotics says: &ldquo;It creates an opportunity where there is actually more social distancing in the environment because the tasks are being performed by a robot and not a person,&rdquo; according to Bloomberg. In other words &ndash; robots might be a cleaner way of cleaning. Expect more of this. &nbsp; Check out the quick video here (Bloomberg QuickTake, Twitter).####################################################Deepfake systems are well-documented, open source commodity tech now. What happens next?&hellip;DeepFaceLab paper lays out how to build a Deepfake system&hellip;Deepfakes, the slang term given to AI technologies that let you take someone&rsquo;s face and superimpose it on someone else in an image or video, are a problem for the AI sector. That&rsquo;s because deepfakes are made out of basic, multi-purpose AI systems that are themselves typically open source. And while some of the uses of deepfakes could be socially useful, like being able to create new forms of art, many of their immediate applications skew towards the malicious end of the spectrum, namely: pornography (particularly revenge porn) and vehicles for spreading politicial disinformation.  &nbsp; So what do we do when Deepfakes are not only well documented in terms of code, but also integrated into consumer-friendly software systems? That&rsquo;s the conundrem raised by DeepFaceLab, open source software on GitHubs for the creation of deepfakes. In a new research paper, the lead author of DeepFaceLab (Ivan Petrov) and his collaborators (mostly freelancers, or Publication norms and AI research: The paper doesn&rsquo;t contain much detailed discussion of the inherent ethics of publishing or not publishing this technology. Their justification for this paper is, recursively, a quote of a prior justification from a 2019 paper about FSGAN: Subject Agnostic Face Swapping and Reenactment: &ldquo;Suppressing the publication of such methods would not stop their development, but rather make them only available to a limited number of experts and potentially blindside policy makers if it goes without any limits&rdquo;. Based on this quote, the DeepFaceLab authors say they &ldquo;found we are responsible to publish DeepFaceLab to the academia community formally&rdquo;. Why this matters: We&rsquo;re in the uncanny valley of AI research, these days: we can make systems that generate synthetic text, images, video, and more. The reigning norm in the research community tends towards fully open source code and research. I think it&rsquo;s unclear if this is long-term the smartest approach to take if you&rsquo;re keen to minimize downsides (see: today, deepfakes are mostly used for porn, which doesn&rsquo;t seem like an especially useful use of societal resources, especially since it inherently damages the economic bargaining power of human pornstars). We live in interesting times&hellip; &nbsp; Read more: DeepFaceLab: A simple, flexible and extensible face swapping framework (arXiv). &nbsp; Check out the code for DeepFaceLab here (GitHub).####################################################Facebook makes an ultra-cheap voice generator:&hellip;What samples two times a second and sounds like a human?&hellip;In recent years, peopl;e have started using neural network-based techniques to synthesize voices for AI-based text-to-speech programs. This is the sort of technology that gives voice to Apple&rsquo;s Siri, Amazon&rsquo;s Alexa, and Google&rsquo;s whatever-it-is. When generating these synthetic voices, there&rsquo;s typically a tradeoff between efficiency (how fast you can generate the voice on your computer) and quality (how good it sounds). Facebook has developed some new approaches that give it a 160X speedup over its internal baseline, which means it can generate voices &ldquo;in real time using regular CPUs &ndash; without any specialized hardware&rdquo;. With this technology, Facebook hopes to make &ldquo;new voice applications that sound more human and expressive and are more enjoyable to use&rdquo;. The tech has already been deployed inside Facebook&rsquo;s &lsquo;Portal&rsquo; videocalling system, as well as in applications like reading assistance and virtual reality. What it takes to make a computer talk: Facebook&rsquo;s system has four elements that, added together, create an expressive voice:&ndash; A front-end that converts text into linguistic features&ndash; A prosody model that predicts the rhythm and melody to create natural-sounding speech&ndash; An acoustic model which generates the spectral representation of the speech&ndash; A neura; vocoder that generates am24 kHz speech waveform, which is conditioned on prosody and spectral featuresGoing from an expensive to a cheap system: Facebook&rsq…