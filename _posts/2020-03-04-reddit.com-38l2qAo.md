---

layout: post
category: threads
title: "[D] Ways to significantly increase inference speed for deployment?"
date: 2020-03-04 09:37:37
link: https://vrhk.co/38l2qAo
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "We deployed a pytorch model (following all standard deployment tricks: eval mode, no grads,..) but a single inference still takes too long. What..."

---

### [D] Ways to significantly increase inference speed for deployment?

We deployed a pytorch model (following all standard deployment tricks: eval mode, no grads,..) but a single inference still takes too long. What...