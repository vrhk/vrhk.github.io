---

layout: post
category: threads
title: "[D] Attention Is All You Need - Encoder-Decoder Attention Module Question"
date: 2020-01-19 06:27:31
link: https://vrhk.co/2GfQrZz
image: https://external-preview.redd.it/_30wJpzbtsBAIQYThTEBp8e2067WVexM_vG2RbdZfOE.jpg?width=1200&height=628.272251309&auto=webp&s=81de939ed7ee64a80ff1e107878579992ae1175d
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Hi all, I am trying to implement Transformer from the Attention is All You Need paper. However, I am confused by what the K and V that are passed..."

---

### [D] Attention Is All You Need - Encoder-Decoder Attention Module Question

Hi all, I am trying to implement Transformer from the Attention is All You Need paper. However, I am confused by what the K and V that are passed...