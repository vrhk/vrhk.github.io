---

layout: post
category: threads
title: "Transformers Pos-Enc Scalar Sizes vs. Input-Embedding Scalar Sizes? [D]"
date: 2020-08-11 15:37:28
link: https://vrhk.co/30NwyUo
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "I can input (before addition of pos encoding) embedding vectors into transformers where the values lie between 0-and-1 or between -1-and-1 or..."

---

### Transformers Pos-Enc Scalar Sizes vs. Input-Embedding Scalar Sizes? [D]

I can input (before addition of pos encoding) embedding vectors into transformers where the values lie between 0-and-1 or between -1-and-1 or...