---

layout: post
category: threads
title: "[D] Some novel techniques I found that accelerates Transformer-XL to some extent"
date: 2019-12-27 04:27:32
link: https://vrhk.co/2EYp2up
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "1. Original Transformer-XL cached previous activations (input to Q, K and V) and computed K&amp;V for the memory each iteration, but I found that you..."

---

### [D] Some novel techniques I found that accelerates Transformer-XL to some extent

1. Original Transformer-XL cached previous activations (input to Q, K and V) and computed K&amp;V for the memory each iteration, but I found that you...