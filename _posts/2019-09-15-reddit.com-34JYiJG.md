---

layout: post
category: threads
title: "[P] SpeedTorch. 4x faster pinned CPU -&gt; GPU data transfer than Pytorch pinned CPU tensors, and 110x faster GPU -&gt; CPU transfer. Augment parameter size by hosting on CPU. Use non sparse optimizers (Adadelta, Adamax, RMSprop, Rprop, etc.) for sparse training (word2vec, node2vec, GloVe, NCF, etc.)."
date: 2019-09-15 23:12:30
link: https://vrhk.co/34JYiJG
image: https://external-preview.redd.it/HXaD9AXcJOYhOEi1lQmyu3EPPVIozvFqLonNGQiL5vU.png?width=1200&height=628.272251309&auto=webp&s=a6cc77f2493ce2054cb2cb47d0604cac3d488558
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "<https://i.imgur.com/wr4VaUV.png> <https://github.com/Santosh-Gupta/SpeedTorch> This is library I made for Pytorch, for fast transfer between pinned..."

---

### [P] SpeedTorch. 4x faster pinned CPU -&gt; GPU data transfer than Pytorch pinned CPU tensors, and 110x faster GPU -&gt; CPU transfer. Augment parameter size by hosting on CPU. Use non sparse optimizers (Adadelta, Adamax, RMSprop, Rprop, etc.) for sparse training (word2vec, node2vec, GloVe, NCF, etc.).

<https://i.imgur.com/wr4VaUV.png> <https://github.com/Santosh-Gupta/SpeedTorch> This is library I made for Pytorch, for fast transfer between pinned...