---

layout: post
category: threads
title: "[D] What does it mean when the training loss and validation loss of your model are constant and identical regardless of the increase in the number of epochs??"
date: 2020-03-09 07:17:33
link: https://vrhk.co/2xol1in
image: https://external-preview.redd.it/f8z6kjviill41.png?overlay-align=bottom,left&crop=640:335.078534031,smart&overlay-height=15p&overlay=%2Fwatermark%2Ft5_2r3gv.png%3Fs%3D25fde90502025a808e495a452fb2218b991321bd&width=640&height=335.078534031&auto=webp&s=55d016c8f7f819994153847a330f9c4177c70567
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Posted in r/MachineLearning by u/kphyx • 1 point and 0 comments"

---

### [D] What does it mean when the training loss and validation loss of your model are constant and identical regardless of the increase in the number of epochs??

Posted in r/MachineLearning by u/kphyx • 1 point and 0 comments