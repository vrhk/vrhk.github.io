---

layout: post
category: product
title: "Import AI 216: Google learns a learning optimizer; resources for African NLP; US and UK deepen AI coordination"
date: 2020-09-28 18:46:30
link: https://vrhk.co/30g7sgk
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Google uses ML to learn better ML optimization &ndash; a surprisingly big deal:&hellip;Yo dawg, we heard you like learning to learn, so we learned how to learn a learning optimizer&hellip;In recent years, AI researchers have used machine learning to do meta-optimization of AI research; we&rsquo;ve used ML to learn how to search for new network architectures, to learn how to distribute nets across chips during training, and learning how to do better memory allocation. These kinds of research projects create AI flywheels &ndash; systems that become ever-more optimized over time, with humans doing less and less direct work and more abstract work, managing the learning algorithms.&nbsp;Now, researchers with Google Brain have turned their attention to learning how to learn ML optimizers &ndash; this is a (potentially) big deal, because an optimizer, like ADAM, is fundamental to the efficiency of training machine learning models. If you build a better optimizer that works in a bunch of different contexts, you can generically speed up all of your model training.What did they do: With this work, Google did a couple of things that are common to some types of frontier research &ndash; they spent a lot more computation on the project than is typical, and they also gathered a really large dataset. Specifically, they build a dataset of &ldquo;more than a thousand diverse optimization tasks commonly found in machine learning&rdquo;, they write. &ldquo;These tasks include RNNs, CNNs, masked auto regressive flows, fully connected networks, language modeling, variational autoencoders, simple 2D test functions, quadratic bowls, and more.&rdquo;How well does it work? &ldquo;Our proposed learned optimizer has a greater sample efficiency than existing methods,&rdquo; they write. They also did the ultimate meta-test &ndash; checking whether their learned optimizer could help them train other, new learned optimizers. &ldquo;This &ldquo;self-optimized&rdquo; training curve is similar to the training curve using our hand-tuned training setup (using the Adam optimizer),&rdquo; they wrote. &ldquo;We interpret this as evidence of unexpectedly effective generalization, as the training of a learned optimizer is unlike anything in the set of training tasks used to train the optimizer&rdquo;.&nbsp; Read more: Tasks, stability, architecture, and compute: Training more effective learned optimizers, and using them to train themselves (arXiv).###################################################Dark Web + Facial Recognition: Uh-Oh:A subscontractor for the Department of Homeland Security accessed almost 200,000 facial recognition pictures, then lost them. 19 of these images were subsequently &ldquo;posted to the dark web&rdquo;, according to the Department of Homeland Security (PDF).&nbsp; Read more: DHS Admits Facial Recognition Photos Were Hacked, Released on Dark Web (Vice).&nbsp;###################################################African languages have a data problem. Lacuna Fun&rsquo;s new grant wants to fix this:&hellip;Want to build more representative datasets? Apply here&hellip;Lacuna Fund, an initiative to provide money and resources for developers focused on low- and middle-income parts of the world, has announced a request for proposals for the creation of language datasets in Sub-saharan Africa.The RFP says proposals &ldquo;should move forward the current state of data and potential for the development of NLP tools in the language(s) for which efforts are proposed&rdquo;. Some of the datasets could be for tasks like speech, parallel corporate for machine translation, or datasets for downstream tasks like Q&amp;A, Lacuna says. Applicants should be based in Africa or have significant, demonstrable experience with the continent, Lacuna says.Why this matters: If your data isn&rsquo;t available, then researchers won&rsquo;t develop systems that are representative of you or your experience. (Remember &ndash; a third of the world&rsquo;s living languages today are found in Africa, but African authors only represented half of one percent of submissions to the ACL conference, recently.) This Lacuna Fund RFP is one thing designed to change this representational issue. It&rsquo;ll sit alongside other efforts, like the pan-african Masakhane group (Import AI 191), that are trying to improve representation in our data.&nbsp; Read more: Datasets for Language in Sub-Saharan Africa (Lacuna Fund website).Check out the full RFP here (PDF).###################################################KILT: 11 data sets, 5 types of test, one big benchmark:&hellip;Think your AI system can use its own knowledge? Test it on KILT&hellip;Facebook has built a benchmark for knowledge-intensive language tasks, called KILT. KILT gives researchers a single interface for multiple types of knowledge-checking test. All the tasks in KILT draw on the same underlying dataset (a single Wikipedia snapshot), letting researchers disentangle performance from the underlying dataset.KILT&rsquo;s five tasks: Fact checking; entity linking; slot filing (a fancy form of information gathering); open domain question answering; and dialogue.What is KILT good for? &ldquo;&rdquo;The goal is to catalyze and facilitate research towards general and explainable models equipped with task-agnostic representations of knowledge&rdquo;, the authors write.&nbsp; Read more: Introducing KILT, a new unified benchmark for knowledge-intensive NLP tasks (FAIR blog).&nbsp; Get the code for KILT (Facebook AI Research, GitHub).&nbsp; Read more: KILT: a Benchmark for Knowledge Intensive Language Tasks (arXiv).###################################################What costs $250 and lets you plan the future of a nation? RAND&rsquo;s new wargame:&hellip;Scary thinktank gets into the tabletop gaming business. Hey, it&rsquo;s 2020, are you really that surprised?&hellip;RAND, the scary thinktank that helps the US government think about geopolitics, game theory, and maintaining strategic stability via military strategy, is getting into the boardgame business. RAND has released Hedgemony: A Game of Strategic Choices, a boardgame that was originally developed to help the Pentagon create its 2018 National Defense Strategy.Let&rsquo;s play Hedgemony! &ldquo;The players in Hedgemony are the United States&mdash;specifically the Secretary of Defense&mdash;Russia, China, North Korea, Iran, and U.S. allies. Play begins amid a specific global situation and spans five years. Each player has a set of military forces, with defined capacities and capabilities, and a pool of renewable resources. Players outline strategic objectives and then must employ their forces in the face of resource and time constraints, as well as events beyond their control,&rdquo; RAND says.&nbsp; Read more: New Game, the First Offered by RAND to Public, Challenges Players to Design Defense Strategies for Uncertain World (RAND Corporation).&nbsp;



###################################################It&rsquo;s getting cheaper to have machines translate the web for us:&hellip;Unsupervised machine translation means we can avoid data labeling costs&hellip;Unsupervised machine translation is the idea where we can crawl the web and find text in multiple languages that refers to the same thing, then automatically assemble these snippets into a single, labeled corpus we can point machine learning algorithms to.&nbsp; &nbsp; New research from Carnegie Mellon University shows how to build a system that can do unsupervised machine translation, automatically build a dictionary of language pairs out of this corpus, crawl the web for data that seems to consist of parallel pairs, then filter the results for quality.Big unsupervised translation works: So, how well does this technique work? The authors compare the translation scores obtained by their unsupervised system, to supervised ones trained on labeled datasets. The surprising result? Unsupervised translation seems to work well. &ldquo;We observe that the machine t…"

---

### Import AI 216: Google learns a learning optimizer; resources for African NLP; US and UK deepen AI coordination

Google uses ML to learn better ML optimization &ndash; a surprisingly big deal:&hellip;Yo dawg, we heard you like learning to learn, so we learned how to learn a learning optimizer&hellip;In recent years, AI researchers have used machine learning to do meta-optimization of AI research; we&rsquo;ve used ML to learn how to search for new network architectures, to learn how to distribute nets across chips during training, and learning how to do better memory allocation. These kinds of research projects create AI flywheels &ndash; systems that become ever-more optimized over time, with humans doing less and less direct work and more abstract work, managing the learning algorithms.&nbsp;Now, researchers with Google Brain have turned their attention to learning how to learn ML optimizers &ndash; this is a (potentially) big deal, because an optimizer, like ADAM, is fundamental to the efficiency of training machine learning models. If you build a better optimizer that works in a bunch of different contexts, you can generically speed up all of your model training.What did they do: With this work, Google did a couple of things that are common to some types of frontier research &ndash; they spent a lot more computation on the project than is typical, and they also gathered a really large dataset. Specifically, they build a dataset of &ldquo;more than a thousand diverse optimization tasks commonly found in machine learning&rdquo;, they write. &ldquo;These tasks include RNNs, CNNs, masked auto regressive flows, fully connected networks, language modeling, variational autoencoders, simple 2D test functions, quadratic bowls, and more.&rdquo;How well does it work? &ldquo;Our proposed learned optimizer has a greater sample efficiency than existing methods,&rdquo; they write. They also did the ultimate meta-test &ndash; checking whether their learned optimizer could help them train other, new learned optimizers. &ldquo;This &ldquo;self-optimized&rdquo; training curve is similar to the training curve using our hand-tuned training setup (using the Adam optimizer),&rdquo; they wrote. &ldquo;We interpret this as evidence of unexpectedly effective generalization, as the training of a learned optimizer is unlike anything in the set of training tasks used to train the optimizer&rdquo;.&nbsp; Read more: Tasks, stability, architecture, and compute: Training more effective learned optimizers, and using them to train themselves (arXiv).###################################################Dark Web + Facial Recognition: Uh-Oh:A subscontractor for the Department of Homeland Security accessed almost 200,000 facial recognition pictures, then lost them. 19 of these images were subsequently &ldquo;posted to the dark web&rdquo;, according to the Department of Homeland Security (PDF).&nbsp; Read more: DHS Admits Facial Recognition Photos Were Hacked, Released on Dark Web (Vice).&nbsp;###################################################African languages have a data problem. Lacuna Fun&rsquo;s new grant wants to fix this:&hellip;Want to build more representative datasets? Apply here&hellip;Lacuna Fund, an initiative to provide money and resources for developers focused on low- and middle-income parts of the world, has announced a request for proposals for the creation of language datasets in Sub-saharan Africa.The RFP says proposals &ldquo;should move forward the current state of data and potential for the development of NLP tools in the language(s) for which efforts are proposed&rdquo;. Some of the datasets could be for tasks like speech, parallel corporate for machine translation, or datasets for downstream tasks like Q&amp;A, Lacuna says. Applicants should be based in Africa or have significant, demonstrable experience with the continent, Lacuna says.Why this matters: If your data isn&rsquo;t available, then researchers won&rsquo;t develop systems that are representative of you or your experience. (Remember &ndash; a third of the world&rsquo;s living languages today are found in Africa, but African authors only represented half of one percent of submissions to the ACL conference, recently.) This Lacuna Fund RFP is one thing designed to change this representational issue. It&rsquo;ll sit alongside other efforts, like the pan-african Masakhane group (Import AI 191), that are trying to improve representation in our data.&nbsp; Read more: Datasets for Language in Sub-Saharan Africa (Lacuna Fund website).Check out the full RFP here (PDF).###################################################KILT: 11 data sets, 5 types of test, one big benchmark:&hellip;Think your AI system can use its own knowledge? Test it on KILT&hellip;Facebook has built a benchmark for knowledge-intensive language tasks, called KILT. KILT gives researchers a single interface for multiple types of knowledge-checking test. All the tasks in KILT draw on the same underlying dataset (a single Wikipedia snapshot), letting researchers disentangle performance from the underlying dataset.KILT&rsquo;s five tasks: Fact checking; entity linking; slot filing (a fancy form of information gathering); open domain question answering; and dialogue.What is KILT good for? &ldquo;&rdquo;The goal is to catalyze and facilitate research towards general and explainable models equipped with task-agnostic representations of knowledge&rdquo;, the authors write.&nbsp; Read more: Introducing KILT, a new unified benchmark for knowledge-intensive NLP tasks (FAIR blog).&nbsp; Get the code for KILT (Facebook AI Research, GitHub).&nbsp; Read more: KILT: a Benchmark for Knowledge Intensive Language Tasks (arXiv).###################################################What costs $250 and lets you plan the future of a nation? RAND&rsquo;s new wargame:&hellip;Scary thinktank gets into the tabletop gaming business. Hey, it&rsquo;s 2020, are you really that surprised?&hellip;RAND, the scary thinktank that helps the US government think about geopolitics, game theory, and maintaining strategic stability via military strategy, is getting into the boardgame business. RAND has released Hedgemony: A Game of Strategic Choices, a boardgame that was originally developed to help the Pentagon create its 2018 National Defense Strategy.Let&rsquo;s play Hedgemony! &ldquo;The players in Hedgemony are the United States&mdash;specifically the Secretary of Defense&mdash;Russia, China, North Korea, Iran, and U.S. allies. Play begins amid a specific global situation and spans five years. Each player has a set of military forces, with defined capacities and capabilities, and a pool of renewable resources. Players outline strategic objectives and then must employ their forces in the face of resource and time constraints, as well as events beyond their control,&rdquo; RAND says.&nbsp; Read more: New Game, the First Offered by RAND to Public, Challenges Players to Design Defense Strategies for Uncertain World (RAND Corporation).&nbsp;



###################################################It&rsquo;s getting cheaper to have machines translate the web for us:&hellip;Unsupervised machine translation means we can avoid data labeling costs&hellip;Unsupervised machine translation is the idea where we can crawl the web and find text in multiple languages that refers to the same thing, then automatically assemble these snippets into a single, labeled corpus we can point machine learning algorithms to.&nbsp; &nbsp; New research from Carnegie Mellon University shows how to build a system that can do unsupervised machine translation, automatically build a dictionary of language pairs out of this corpus, crawl the web for data that seems to consist of parallel pairs, then filter the results for quality.Big unsupervised translation works: So, how well does this technique work? The authors compare the translation scores obtained by their unsupervised system, to supervised ones trained on labeled datasets. The surprising result? Unsupervised translation seems to work well. &ldquo;We observe that the machine t…