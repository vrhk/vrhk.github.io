---

layout: post
category: threads
title: "[D] Paper Explained - Big Bird: Transformers for Longer Sequences (Full Video Analysis)"
date: 2020-08-02 11:17:29
link: https://vrhk.co/39LxNGO
image: https://external-preview.redd.it/fTN9a4hK-oOiC8cOnqJKCLN2xsk9-6NnXw7RTm0NnfU.jpg?width=480&height=251.308900524&auto=webp&crop=480:251.308900524,smart&s=35f8746398d1b77e6474d8ceac9fb823850f8ee8
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "[<https://youtu.be/WVPE62Gk3EM>](<https://youtu.be/WVPE62Gk3EM>) The quadratic resource requirements of the attention mechanism are the main..."

---

### [D] Paper Explained - Big Bird: Transformers for Longer Sequences (Full Video Analysis)

[<https://youtu.be/WVPE62Gk3EM>](<https://youtu.be/WVPE62Gk3EM>) The quadratic resource requirements of the attention mechanism are the main...