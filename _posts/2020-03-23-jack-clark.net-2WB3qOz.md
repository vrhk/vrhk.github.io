---

layout: post
category: product
title: "Import AI 190: AnimeGAN; why Bengali is hard for OCR systems; help with COVID by mining the CORD-19 dataset; plus ball-dodging drones."
date: 2020-03-23 18:26:46
link: https://vrhk.co/2WB3qOz
image: https://mappingbabel.files.wordpress.com/2020/03/dronedodge.jpg?fit=200%2C150
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Work in AI? Want to help with COVID? Work on the CORD-19 dataset:&hellip;Uncle Sam wants the world&rsquo;s AI researchers to make COVID-19 dataset navigable&hellip;As the COVID pandemic moves across the world, many AI researchers have been wondering how they can best help. A good starting place is developing new data mining and text analysis tools for the COVID-19 Open Research Dataset (CORD-19), a new machine-readable Coronavirus literature dataset containing 29,000 articles.Where the dataset came from: &nbsp;The dataset was assembled by a collaboration of the Allen Institute for AI, Chan Zuckerberg Initiative (CZI), Georgetown University&rsquo;s Center for Security and Emerging Technology (CSET), Microsoft, and the National Library of Medicine (NLM). The White House&rsquo;s Office of Science and Technology Policy (OSTP) requested the dataset, according to a government statement. Enter the COVID-19 challenge:&nbsp; If you want to build tools to navigate the dataset, then download the data and complete various tasks and challenges hosted at Kaggle. Why this matters: Hopefully obvious!  &nbsp; Read more: Call to Action to the Tech Community on New Machine Readable COVID-19 Dataset (White House Office of Science and Technology Policy).####################################################What can your algorithm learn from a 1 kilometer stretch of road in Toronto?&hellip;Train it on Toronto-3D and find out&hellip;Researchers with the University of Waterloo, the Chinese Academy of Sciences, Jimei University, and the University of Waterloo have created Toronto-3D, a high-definition dataset made out of a one kilometer stretch of road in Toronto, Canada. What&rsquo;s in Toronto-3D? The dataset was collected via a mobile laser scanner (a Teledyne Optech Maverick) which recorded data from a one kilometer stretch of Avenue Road in Toronto, Canada, yielding around ~78 million distinct points. The data comes in the form of a point cloud &ndash; so this is inherently a three dimensional dataset. It has eight types of label &ndash; unclassified, road, road marking, natural, building, utility line, car, and fence; a couple of these objects &ndash; road markings and utility lines &ndash; are pretty rare to see in datasets like this and are quite challenging to identify. How well do baselines work? The researchers test out six deep learning-based systems on the dataset, measuring the accuracy with which they can classify objects. Their baseline systems get an overall accuracy of around 90%. Poor scoring areas include road markings (multiple 0% scores), cars (most scores average around 50%), and fences (scores between 10% and 20%, roughly).&nbsp; They also develop their own system, which improves scores on a few of the labels, and nets out to an average of around 91% &ndash; promising, but we&rsquo;re a ways away from &lsquo;good enough for most real world use-cases&rsquo;.Why this matters: Datasets like this will help us build AI systems that can analyze and understand the world around them. I also suspect that we&rsquo;re going to see an increasingly large number of artists play around with 3-D datasets like this to make various funhouse-mirror versions of reality.  &nbsp; Read more: Toronto-3D: A Large-scale Mobile LiDAR Dataset for Semantic Segmentation of Urban Roadways (arXiv). ####################################################AnimeGAN: Turn your photos into anime:&hellip;How AI systems let us bottle up a subjective &lsquo;mind&rsquo;s eye&rsquo; and give it to someone else&hellip;Ever wanted to turn your photos into something straight out of an Anime cartoon? Now you can, via AnimeGAN. AnimeGAN is a model that helps you convert photos into Anime-style pictures. It is implemented in TensorFlow and is described on its GitHub page as an &ldquo;open source of the paper &rdquo; (I haven&rsquo;t been able to find the paper on arXiv, and Google is failing me, so send a link through if you can find it). Get the code from GitHub and give it a try!Why this matters: I think one of the weird aspects of AI is that it lets us augment our own imagination with external tools, built by others, that give us different lenses on the world.
When I was a kid I used to draw a lot of cartoons and I&rsquo;d sometimes wonder around my neighborhood looking at the world and trying to convert it in my mind into a cartoon representation. &nbsp;I had a friend who tried to &lsquo;see&rsquo; the world in black and white after getting obsessed with movies. Another one would stop at traffic lights as they beeped and hear additional music in the poly-rhythms of beeps and cars and traffic. Now, AI lets us create tools that make these idiosyncratic, subjective views of the world real to others &ndash; I don&rsquo;t need to have spent years watching and/or drawing Anime to be able to look at the world and see an Anime representation of it, instead I can use something like &lsquo;AnimeGAN&rsquo; and take a shortcut. This feels like a weirder thing than we take it to be, and I expect the cultural effects to be profound in the long term.  &nbsp; Get the code: AnimeGAN (GitHub). ####################################################
Want computers that can read Bengali? Do these things:&hellip;Plus, how cultures will thrive or decline according to how legibile they are to AI systems&hellip;What happens if AI systems can&rsquo;t read an alphabet? The language ends up not being digitized much, which ultimately means it has less representation, which likely reduces the number of people that speak that language in the long term.&nbsp; New research from the United International University in Bangladesh lays out some of the problems inherent to building systems to recognize Bengali text, giving researchers a list of things to work through to improve digitization efforts for the language.&nbsp;Why Bengali is challenging for OCR: The Bengali alphabet has 50 letters, 11 vowels, and 39 consonants, and is one of the top ten writing systems used worldwide (with the top three dominant ones being Latin, Chinese, and Arabic). It&rsquo;s a hard language to perform OCR on because some characters look very similar to one another, and some compound characters &ndash; characters where the meaning shifts according to the surrounding context -are particularly hard to parse. The researchers have some tips for data augmentations or manipulations that can make it easier for machines to read Bengali:
Alignment: Ensure images are oriented so they&rsquo;re vertically straight
Line segmentation: Ensure line segmentation systems are sensitive to the size of the font.&nbsp;
Character segmentation: Bengali characters are connected together via something called a matra-line (a big horizontal line on the top of a load of Bengali characters).&nbsp;
Character recognition: It&rsquo;s tricky to do character recognition on the Bengali alphabet because of the use of compound characters &ndash; of which there are about 170 common uses. In addition, there are ten modified vowels in the Bengali script which can be present in the left, right, top or bottom of a character. &ldquo;The position of different modified vowels alongside a character creates complexity in recognition,&rdquo; they write. &ldquo;The combination of these modified vowels with each of the characters also creates a large set of classes for the model to learn from&rdquo;.&nbsp;
Why this matters: What cultures will be &lsquo;seen&rsquo; by AI systems in the future, and which ones won&rsquo;t be? And what knock-on effects will this have on society? We&rsquo;ll know the answer in a few years, and papers like this give us an indication of the difficulty people might face when digitizing different languages written with different systems.  &nbsp; Read more: Constraints in Developing a Complete Bengali Optical Character Recognition System (arXiv). ####################################################Self-driving freight company Starsky Robotics shuts down:&hellip;Startup cites immaturi…"

---

### Import AI 190: AnimeGAN; why Bengali is hard for OCR systems; help with COVID by mining the CORD-19 dataset; plus ball-dodging drones.

Work in AI? Want to help with COVID? Work on the CORD-19 dataset:&hellip;Uncle Sam wants the world&rsquo;s AI researchers to make COVID-19 dataset navigable&hellip;As the COVID pandemic moves across the world, many AI researchers have been wondering how they can best help. A good starting place is developing new data mining and text analysis tools for the COVID-19 Open Research Dataset (CORD-19), a new machine-readable Coronavirus literature dataset containing 29,000 articles.Where the dataset came from: &nbsp;The dataset was assembled by a collaboration of the Allen Institute for AI, Chan Zuckerberg Initiative (CZI), Georgetown University&rsquo;s Center for Security and Emerging Technology (CSET), Microsoft, and the National Library of Medicine (NLM). The White House&rsquo;s Office of Science and Technology Policy (OSTP) requested the dataset, according to a government statement. Enter the COVID-19 challenge:&nbsp; If you want to build tools to navigate the dataset, then download the data and complete various tasks and challenges hosted at Kaggle. Why this matters: Hopefully obvious!  &nbsp; Read more: Call to Action to the Tech Community on New Machine Readable COVID-19 Dataset (White House Office of Science and Technology Policy).####################################################What can your algorithm learn from a 1 kilometer stretch of road in Toronto?&hellip;Train it on Toronto-3D and find out&hellip;Researchers with the University of Waterloo, the Chinese Academy of Sciences, Jimei University, and the University of Waterloo have created Toronto-3D, a high-definition dataset made out of a one kilometer stretch of road in Toronto, Canada. What&rsquo;s in Toronto-3D? The dataset was collected via a mobile laser scanner (a Teledyne Optech Maverick) which recorded data from a one kilometer stretch of Avenue Road in Toronto, Canada, yielding around ~78 million distinct points. The data comes in the form of a point cloud &ndash; so this is inherently a three dimensional dataset. It has eight types of label &ndash; unclassified, road, road marking, natural, building, utility line, car, and fence; a couple of these objects &ndash; road markings and utility lines &ndash; are pretty rare to see in datasets like this and are quite challenging to identify. How well do baselines work? The researchers test out six deep learning-based systems on the dataset, measuring the accuracy with which they can classify objects. Their baseline systems get an overall accuracy of around 90%. Poor scoring areas include road markings (multiple 0% scores), cars (most scores average around 50%), and fences (scores between 10% and 20%, roughly).&nbsp; They also develop their own system, which improves scores on a few of the labels, and nets out to an average of around 91% &ndash; promising, but we&rsquo;re a ways away from &lsquo;good enough for most real world use-cases&rsquo;.Why this matters: Datasets like this will help us build AI systems that can analyze and understand the world around them. I also suspect that we&rsquo;re going to see an increasingly large number of artists play around with 3-D datasets like this to make various funhouse-mirror versions of reality.  &nbsp; Read more: Toronto-3D: A Large-scale Mobile LiDAR Dataset for Semantic Segmentation of Urban Roadways (arXiv). ####################################################AnimeGAN: Turn your photos into anime:&hellip;How AI systems let us bottle up a subjective &lsquo;mind&rsquo;s eye&rsquo; and give it to someone else&hellip;Ever wanted to turn your photos into something straight out of an Anime cartoon? Now you can, via AnimeGAN. AnimeGAN is a model that helps you convert photos into Anime-style pictures. It is implemented in TensorFlow and is described on its GitHub page as an &ldquo;open source of the paper &rdquo; (I haven&rsquo;t been able to find the paper on arXiv, and Google is failing me, so send a link through if you can find it). Get the code from GitHub and give it a try!Why this matters: I think one of the weird aspects of AI is that it lets us augment our own imagination with external tools, built by others, that give us different lenses on the world.
When I was a kid I used to draw a lot of cartoons and I&rsquo;d sometimes wonder around my neighborhood looking at the world and trying to convert it in my mind into a cartoon representation. &nbsp;I had a friend who tried to &lsquo;see&rsquo; the world in black and white after getting obsessed with movies. Another one would stop at traffic lights as they beeped and hear additional music in the poly-rhythms of beeps and cars and traffic. Now, AI lets us create tools that make these idiosyncratic, subjective views of the world real to others &ndash; I don&rsquo;t need to have spent years watching and/or drawing Anime to be able to look at the world and see an Anime representation of it, instead I can use something like &lsquo;AnimeGAN&rsquo; and take a shortcut. This feels like a weirder thing than we take it to be, and I expect the cultural effects to be profound in the long term.  &nbsp; Get the code: AnimeGAN (GitHub). ####################################################
Want computers that can read Bengali? Do these things:&hellip;Plus, how cultures will thrive or decline according to how legibile they are to AI systems&hellip;What happens if AI systems can&rsquo;t read an alphabet? The language ends up not being digitized much, which ultimately means it has less representation, which likely reduces the number of people that speak that language in the long term.&nbsp; New research from the United International University in Bangladesh lays out some of the problems inherent to building systems to recognize Bengali text, giving researchers a list of things to work through to improve digitization efforts for the language.&nbsp;Why Bengali is challenging for OCR: The Bengali alphabet has 50 letters, 11 vowels, and 39 consonants, and is one of the top ten writing systems used worldwide (with the top three dominant ones being Latin, Chinese, and Arabic). It&rsquo;s a hard language to perform OCR on because some characters look very similar to one another, and some compound characters &ndash; characters where the meaning shifts according to the surrounding context -are particularly hard to parse. The researchers have some tips for data augmentations or manipulations that can make it easier for machines to read Bengali:
Alignment: Ensure images are oriented so they&rsquo;re vertically straight
Line segmentation: Ensure line segmentation systems are sensitive to the size of the font.&nbsp;
Character segmentation: Bengali characters are connected together via something called a matra-line (a big horizontal line on the top of a load of Bengali characters).&nbsp;
Character recognition: It&rsquo;s tricky to do character recognition on the Bengali alphabet because of the use of compound characters &ndash; of which there are about 170 common uses. In addition, there are ten modified vowels in the Bengali script which can be present in the left, right, top or bottom of a character. &ldquo;The position of different modified vowels alongside a character creates complexity in recognition,&rdquo; they write. &ldquo;The combination of these modified vowels with each of the characters also creates a large set of classes for the model to learn from&rdquo;.&nbsp;
Why this matters: What cultures will be &lsquo;seen&rsquo; by AI systems in the future, and which ones won&rsquo;t be? And what knock-on effects will this have on society? We&rsquo;ll know the answer in a few years, and papers like this give us an indication of the difficulty people might face when digitizing different languages written with different systems.  &nbsp; Read more: Constraints in Developing a Complete Bengali Optical Character Recognition System (arXiv). ####################################################Self-driving freight company Starsky Robotics shuts down:&hellip;Startup cites immaturi…