---

layout: post
category: product
title: "Import AI 227: MAAD-Face; GPT2 and Human Brains; Facebook detects Hateful Memes"
date: 2020-12-14 17:46:33
link: https://vrhk.co/2LAAbbn
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "University of Texas ditches algorithm over bias concerns:&hellip;.Gives an F to the GRADE software&hellip;The University of Texas at Austin has stopped using software, called GRADE, to screen for those applying for a PHD at its CS department. UT Austin used GRADE between 2013 and 2019, and stopped using it in early 2020, according to reporting from The Register. Some of the developers of GRADE thinks it doesn&rsquo;t have major issues with regard to manifesting bias along racial or gender lines, but others say it could magnify existing biases present in the decisions made by committees of humans.Why this matters: As AI has matured rapidly, it has started being integrated into all facets of life. But some parts of life probably don&rsquo;t need AI in them &ndash; especially those that involve making screening determinations about people in ways that could have an existential impact on them, like admission to possible graduate programs.&nbsp; Read more: Uni revealed it killed off its PhD-applicant screening AI just as its inventors gave a lecture about the tech (The Register).###################################################Element AI sells to ServiceNow:&hellip;The great Canadian AI hope gets sold for parts&hellip;American software company ServiceNow has acquired Element AI; the purchase looks like an acquihire, with ServiceNow executives stressing the value of Element AI&rsquo;s talent, rather than any particular product the company had developed.Why this is a big deal for Canada: Element AI was formed in 2016 and designed as a counterpoint to the talent-vacuums of Google, Facebook, Microsoft, and so on. It was founded with the ambition it could become a major worldwide player, and a talent magnet for Canada. It even signed on Yoshua Bengio, one of the Turing Award winners responsible for the rise of deep learning, as an advisor. Element AI raised around $250+ million in its lifespan. Now it has been sold, allegedly for less than $400 million, according to the Globe and Mail. Shortly after the deal closed, ServiceNow started laying off of a variety of Element AI staff, including its public policy team.Why this matters: As last week&rsquo;s Timnit Gebru situation highlights, AI research is at present concentrated in a small number of private sector firms, which makes it inherently harder to do research into different forms of governance, regulation, and oversight. During its lifetime, Element AI did some interesting work on data repositories, and I&rsquo;d run into Element AI people at various government events where they&rsquo;d be encouraging nations to build shared data repositories for public goods &ndash; a useful idea. Element AI being sold to a US firm increases this amount of concentration and also reduces the diversity of experiments being run in the space of &lsquo;potential AI organizations&rsquo; and potential AI policy. I wish everyone at Element AI luck and hope Canada takes another swing at trying to form a counterpoint to the major powers of the day.&nbsp; Read more: Element AI acquisition brings better, smarter AI capabilities for customers (ServiceNow).###################################################Uh oh, a new gigantic face dataset has appeared:&hellip;123 million labels for 3 million+ photographs&hellip;German researchers have developed MAAD-Face, a dataset containing more than a hundred million labels applied to millions of images of 9,000 people. MAAD-Face was built by researchers at the Fraunhofer Institute for Computer Graphics and is designed to substitute for other, labeled datasets like CelebA and LFW. It also, like any dataset involving a ton of labeled data about people introduces a range of ethical questions.But the underlying dataset might be offline? MAAD-Face is based on VGG, a massive facial recognition dataset. VGG is currently offline for unclear reasons, potentially due to controversies associated with the dataset. I think we&rsquo;ll see more examples of this &ndash; in the future, perhaps some % of datasets like this will be traded surreptitiously via torrent networks. (Today, datasets like DukeMTMC and ImageNet-ILSVRC-2012 are circulating via torrents, having been pulled off of public repositories following criticism relating to biases or other issues with their datasets.)What&rsquo;s in a label? MAAD-Face has 47 distinct labels which can get applied to images, with labels ranging from non-controversial subjects (are they wearing glasses? Is their forehead visible? Can you see their teeth?) to ones that have significant subjectivity (whether the person is &lsquo;attractive&rsquo;, &lsquo;chubby&rsquo;, &lsquo;middle aged&rsquo;), to ones where it&rsquo;s dubious whether we should be assigning the label at all (e.g, ones that assign a gender of male or female, or which classifies people into races like &lsquo;asian&rsquo;, &lsquo;white&rsquo;, or &lsquo;black&rsquo;).Why this matters &ndash; labels define culture: As more of the world becomes classified and analyzed by software systems, the labels we use to build the machines that do this classification matter more and more. Datasets like MAAD-Face both gesture at the broad range of labels we&rsquo;re currently assigning to things, and also should prepare us for a world where someone uses computer vision systems to do something with an understanding of &lsquo;chubby&rsquo;, or other similarly subjective labels. I doubt the results will be easy to anticipate.&nbsp; Read more: MAAD-Face: A Massively Annotated Attribute Dataset for Face Images (arXiv).Get the dataset from here (GitHub).&nbsp; Via Adam Harvey (Twitter), who works on projects tracking computer vision like &lsquo;MegaPixels&lsquo; (official site).



###################################################Is GPT2 like the human brain? In one way &ndash; yes!&hellip;Neuroscience paper finds surprising overlaps between how humans approach language and how GPT2 does&hellip;Are contemporary language models smart? That&rsquo;s a controversial question. Are they doing something like the human brain? That&rsquo;s an even more controversial question. But a new paper involving gloopy experiments with real human brains suggests the answer could be &lsquo;yes&rsquo; at least when it comes to how we predict words in sentences and use our memory to improve our predictions.But, before the fun stuff, a warning: Picture yourself in a dark room with a giant neon sign in front of you. The sign says CORRELATION != CAUSATION. Keep this image in mind while reading this section. The research is extremely interesting, but also the sort of thing prone to wild misinterpretation, so Remember The Neon Sign while reading. Now&hellip;What they investigated: &ldquo;Modern deep language models incorporate two key principles: they learn in a self-supervised way by automatically generating next-word predictions, and they build their representations of meaning based on a large trailing window of context,&rdquo; the researchers write. &ldquo;We explore the hypothesis that human language in natural settings also abides by these fundamental principles of prediction and context&rdquo;.What they found: For their experiments, they used three types of word features (arbitrary, GloVe, and GPT2) and compared how well these features could predict neural activity in people compared to what happened when given different sentences where they needed to predict the next word, and they tried to see which of these features could do the most effective predictions. Their findings are quite striking &ndash; GPT2 models assign very similar probabilities for the next words in a sentence to humans, and as you increase the context window (the number of words the person or algo sees before it makes a prediction), performance improves further, and human and algorithmic answers continue to be in agreement.Something very interesting about the brain: &ldquo;On the neural level, by carefully analyzing the temporally resolved ECoG responses to each word as subjec…"

---

### Import AI 227: MAAD-Face; GPT2 and Human Brains; Facebook detects Hateful Memes

University of Texas ditches algorithm over bias concerns:&hellip;.Gives an F to the GRADE software&hellip;The University of Texas at Austin has stopped using software, called GRADE, to screen for those applying for a PHD at its CS department. UT Austin used GRADE between 2013 and 2019, and stopped using it in early 2020, according to reporting from The Register. Some of the developers of GRADE thinks it doesn&rsquo;t have major issues with regard to manifesting bias along racial or gender lines, but others say it could magnify existing biases present in the decisions made by committees of humans.Why this matters: As AI has matured rapidly, it has started being integrated into all facets of life. But some parts of life probably don&rsquo;t need AI in them &ndash; especially those that involve making screening determinations about people in ways that could have an existential impact on them, like admission to possible graduate programs.&nbsp; Read more: Uni revealed it killed off its PhD-applicant screening AI just as its inventors gave a lecture about the tech (The Register).###################################################Element AI sells to ServiceNow:&hellip;The great Canadian AI hope gets sold for parts&hellip;American software company ServiceNow has acquired Element AI; the purchase looks like an acquihire, with ServiceNow executives stressing the value of Element AI&rsquo;s talent, rather than any particular product the company had developed.Why this is a big deal for Canada: Element AI was formed in 2016 and designed as a counterpoint to the talent-vacuums of Google, Facebook, Microsoft, and so on. It was founded with the ambition it could become a major worldwide player, and a talent magnet for Canada. It even signed on Yoshua Bengio, one of the Turing Award winners responsible for the rise of deep learning, as an advisor. Element AI raised around $250+ million in its lifespan. Now it has been sold, allegedly for less than $400 million, according to the Globe and Mail. Shortly after the deal closed, ServiceNow started laying off of a variety of Element AI staff, including its public policy team.Why this matters: As last week&rsquo;s Timnit Gebru situation highlights, AI research is at present concentrated in a small number of private sector firms, which makes it inherently harder to do research into different forms of governance, regulation, and oversight. During its lifetime, Element AI did some interesting work on data repositories, and I&rsquo;d run into Element AI people at various government events where they&rsquo;d be encouraging nations to build shared data repositories for public goods &ndash; a useful idea. Element AI being sold to a US firm increases this amount of concentration and also reduces the diversity of experiments being run in the space of &lsquo;potential AI organizations&rsquo; and potential AI policy. I wish everyone at Element AI luck and hope Canada takes another swing at trying to form a counterpoint to the major powers of the day.&nbsp; Read more: Element AI acquisition brings better, smarter AI capabilities for customers (ServiceNow).###################################################Uh oh, a new gigantic face dataset has appeared:&hellip;123 million labels for 3 million+ photographs&hellip;German researchers have developed MAAD-Face, a dataset containing more than a hundred million labels applied to millions of images of 9,000 people. MAAD-Face was built by researchers at the Fraunhofer Institute for Computer Graphics and is designed to substitute for other, labeled datasets like CelebA and LFW. It also, like any dataset involving a ton of labeled data about people introduces a range of ethical questions.But the underlying dataset might be offline? MAAD-Face is based on VGG, a massive facial recognition dataset. VGG is currently offline for unclear reasons, potentially due to controversies associated with the dataset. I think we&rsquo;ll see more examples of this &ndash; in the future, perhaps some % of datasets like this will be traded surreptitiously via torrent networks. (Today, datasets like DukeMTMC and ImageNet-ILSVRC-2012 are circulating via torrents, having been pulled off of public repositories following criticism relating to biases or other issues with their datasets.)What&rsquo;s in a label? MAAD-Face has 47 distinct labels which can get applied to images, with labels ranging from non-controversial subjects (are they wearing glasses? Is their forehead visible? Can you see their teeth?) to ones that have significant subjectivity (whether the person is &lsquo;attractive&rsquo;, &lsquo;chubby&rsquo;, &lsquo;middle aged&rsquo;), to ones where it&rsquo;s dubious whether we should be assigning the label at all (e.g, ones that assign a gender of male or female, or which classifies people into races like &lsquo;asian&rsquo;, &lsquo;white&rsquo;, or &lsquo;black&rsquo;).Why this matters &ndash; labels define culture: As more of the world becomes classified and analyzed by software systems, the labels we use to build the machines that do this classification matter more and more. Datasets like MAAD-Face both gesture at the broad range of labels we&rsquo;re currently assigning to things, and also should prepare us for a world where someone uses computer vision systems to do something with an understanding of &lsquo;chubby&rsquo;, or other similarly subjective labels. I doubt the results will be easy to anticipate.&nbsp; Read more: MAAD-Face: A Massively Annotated Attribute Dataset for Face Images (arXiv).Get the dataset from here (GitHub).&nbsp; Via Adam Harvey (Twitter), who works on projects tracking computer vision like &lsquo;MegaPixels&lsquo; (official site).



###################################################Is GPT2 like the human brain? In one way &ndash; yes!&hellip;Neuroscience paper finds surprising overlaps between how humans approach language and how GPT2 does&hellip;Are contemporary language models smart? That&rsquo;s a controversial question. Are they doing something like the human brain? That&rsquo;s an even more controversial question. But a new paper involving gloopy experiments with real human brains suggests the answer could be &lsquo;yes&rsquo; at least when it comes to how we predict words in sentences and use our memory to improve our predictions.But, before the fun stuff, a warning: Picture yourself in a dark room with a giant neon sign in front of you. The sign says CORRELATION != CAUSATION. Keep this image in mind while reading this section. The research is extremely interesting, but also the sort of thing prone to wild misinterpretation, so Remember The Neon Sign while reading. Now&hellip;What they investigated: &ldquo;Modern deep language models incorporate two key principles: they learn in a self-supervised way by automatically generating next-word predictions, and they build their representations of meaning based on a large trailing window of context,&rdquo; the researchers write. &ldquo;We explore the hypothesis that human language in natural settings also abides by these fundamental principles of prediction and context&rdquo;.What they found: For their experiments, they used three types of word features (arbitrary, GloVe, and GPT2) and compared how well these features could predict neural activity in people compared to what happened when given different sentences where they needed to predict the next word, and they tried to see which of these features could do the most effective predictions. Their findings are quite striking &ndash; GPT2 models assign very similar probabilities for the next words in a sentence to humans, and as you increase the context window (the number of words the person or algo sees before it makes a prediction), performance improves further, and human and algorithmic answers continue to be in agreement.Something very interesting about the brain: &ldquo;On the neural level, by carefully analyzing the temporally resolved ECoG responses to each word as subjec…