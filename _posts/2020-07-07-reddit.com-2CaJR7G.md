---

layout: post
category: threads
title: "[R] Gradient Origin Networks (GONs) - gradients from the origin can act as a latent space in implicit representation networks (e.g. SIRENs) to avoid the need for encoders"
date: 2020-07-07 14:37:31
link: https://vrhk.co/2CaJR7G
image: https://external-preview.redd.it/nsSf86f_WhCQgfyLAECewvq7eP5_tEYRTKH3kQ6Mdp4.jpg?width=1200&height=628.272251309&auto=webp&crop=1200:628.272251309,smart&s=1b248c9f1a64f5f9abf264a59ec6eac8430b25b5
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "We were surprised how well this works, e.g. capturing MNIST in a single SIREN network with just 4,385 parameters. This shares many of the..."

---

### [R] Gradient Origin Networks (GONs) - gradients from the origin can act as a latent space in implicit representation networks (e.g. SIRENs) to avoid the need for encoders

We were surprised how well this works, e.g. capturing MNIST in a single SIREN network with just 4,385 parameters. This shares many of the...