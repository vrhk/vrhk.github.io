---

layout: post
category: threads
title: "[D] scaled dot product vs. scaled cosine similarity in transformer attention"
date: 2020-05-03 01:27:32
link: https://vrhk.co/2z87D2s
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "In the original transformer paper, it introduces scaled dot product\[1\]. In the recent simclr paper\[2\], it uses scaled cosine similarity, where..."

---

### [D] scaled dot product vs. scaled cosine similarity in transformer attention

In the original transformer paper, it introduces scaled dot product\[1\]. In the recent simclr paper\[2\], it uses scaled cosine similarity, where...