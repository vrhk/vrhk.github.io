---

layout: post
category: research
title: "Fine-Tuning GPT-2 from Human Preferences"
date: 2019-09-19 16:03:34
link: https://vrhk.co/31zIeIH
image: https://openai.com/content/images/2019/09/fine-tuning-gpt-2.png
domain: openai.com
author: "OpenAI"
icon: https://openai.com/assets/images/favicon.png
excerpt: "We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we’d only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required"

---

### Fine-Tuning GPT-2 from Human Preferences

We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we’d only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required