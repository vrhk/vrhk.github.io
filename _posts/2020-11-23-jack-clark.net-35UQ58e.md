---

layout: post
category: product
title: "Import AI 224: AI cracks the exaflop barrier;  robots and COVID surveillance; gender bias in computer vision"
date: 2020-11-23 18:46:31
link: https://vrhk.co/35UQ58e
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "How robots get used for COVID surveillance:&hellip;&rsquo;SeekNet&rsquo; lets University of Maryland use a robot to check people for symptoms&hellip;Researchers with the University of Maryland have built SeekNet, software to help them train robots to navigate a environment and intelligently visually inspect the people in it by navigating to get a good look at people, if they&rsquo;re at first colluded. To test out how useful the technology is, they use it to do COVID surveillance.What they did: SeekNet is a network that smushes together a perception network with a movement one, with the two networks informing eachother; if the perception network thinks it has spotted part of a human (e.g, someone standing behind someone else), it&rsquo;ll talk to the movement network and get it to reposition the robot to get a better look.What they used it for: To test out their system, they put it on a small mobile robot and used it to surveil people for COVID symptoms. &ldquo;We fuse multiple modalities to simultaneously measure the vital signs, like body temperature, respiratory rate, heart rate, etc., to improve the screening accuracy,&rdquo; they write.What happens next: As I&rsquo;ve written for CSET (analysis here, tweet thread here), COVID is going to lead to an increase in the use of computer vision for a variety of surveillance applications. The open question is whether a particular nation or part of the world becomes dominant in the development of this technology, and about how Western governments choose to use this technology after the crisis is over and we have all these cheap, powerful, surveillance tools available.&nbsp; Read more: SeekNet: Improved Human Instance Segmentation via Reinforcement Learning Based Optimized Robot Relocation (arXiv).###################################################DeepMind open-sources a 2D RL simulator:..Yes, another 2D simulator &ndash; the more the merrier&hellip;DeepMind has released DeepMind Lab 2D, software to help people carry out reinforcement learning tasks in 2D. The software makes it easy to create different 2D environments and unleash agents on them and also supports multiple simultaneous agents being run in the same simulation.&nbsp;What is DeepMind Lab 2D useful for? The software &rdquo; generalizes and extends a popular internal system at DeepMind which supported a large range of research projects,&rdquo; the authors write. &ldquo;It was especially popular for multi-agent research involving workflows with significant environment-side iteration.&rdquo;Why might you not want to use DeepMind Lab 2D? While the software seems useful, there are some existing alternatives based on the video game description language (VGDL) (including competitions and systems built on top of it, like the &lsquo;General Video Game AI Framework&rsquo; (Import AI: 101) and &lsquo;Deceptive Gains&rsquo; (#80)), or DeepMind&rsquo;s own 2017-era &lsquo;AI Safety Gridworlds&lsquo;. However, I think we&rsquo;ll ultimately evaluate RL agents across a whole bunch of different problems running in a variety of simulators, so I expect it&rsquo;s useful to have more of them.&nbsp; Read more: DeepMind Lab2D (arXiv).&nbsp; Get the code: DeepMind Lab2D (GitHub).###################################################



Facebook&rsquo;s attempt to use AI for content moderation hurts its contractors:&hellip;Open letter highlights pitfalls of using AI to analyze AI&hellip;Over 200 Facebook content moderators recently complained to the leadership of Facebook as well as contractor companies Covalen and Accenture about the ways they&rsquo;ve been treated during the pandemic. And in the letter, published by technology advocacy group Foxglove, they discuss an AI moderation experiment Facebook conducted earlier this year&hellip;AI to monitor AI: &ldquo;To cover the pressing need to moderate the masses of violence, hate, terrorism, child abuse, and other horrors that we fight for you every day, you sought to substitute our work with the work of a machine.Without informing the public, Facebook undertook a massive live experiment in heavily automated content moderation. Management told moderators that we should no longer see certain varieties of toxic content coming up in the review tool from which we work&mdash; such as graphic violence or child abuse, for example.



The AI wasn&rsquo;t up to the job. Important speech got swept into the maw of the Facebook filter&mdash;and risky content, like self-harm, stayed up.&rdquo;Why this matters: At some point, we&rsquo;re going to be able to use AI systems to analyze and classify subtle, thorny issues like sexualization, violence, racism, and so on. But we&rsquo;re definitely in the &lsquo;Wright Brothers&rsquo; phase of this technology, with much to be discovered before it become reliable enough to substitute for people. In the meanwhile, humans and machines will need to team together on these issues, with all the complication that entails.&nbsp;&nbsp; Read the letter in full here: Open letter from content moderators re: pandemic (Foxglove).



###################################################Google, Microsoft, Amazon&rsquo;s commercial computer vision systems exhibit serious gender biases:&hellip;Study shows gender-based mis-identification of people, and worse&hellip;An interdisciplinary team of researchers have analyzed how commercially available computer vision systems classify differently gendered people &ndash; and the results seem to show significant biases.What they found: In tests on Google Cloud, Microsoft Azure, and Amazon Web Services, they find that object recognition systems offered by these companies display &ldquo;significant gender bias&rdquo; in how they label photos of men and women. Of more potential concern, they found that Google&rsquo;s system in particular had a poor recognition rate for men versus women &ndash; when tested on one dataset, it correctly labeled men 85.8% correctly, versus 75.5% for women (and for a more complex dataset, it guessed men correctly 45.3% of the time and women 25.8%.Why this matters: &ldquo;If &ldquo;a picture is worth a thousand words,&rdquo; but an algorithm provides only a handful, the words it chooses are of immense consequence,&rdquo; the researchers write. This feels true &ndash; the decisions that AI people make about their machines are, ultimately, going to lead to the magnification of those assumptions in the systems that get deployed into the world, which will have real consequences on who does and doesn&rsquo;t get &lsquo;seen&rsquo; or &lsquo;perceived&rsquo; by AI.&nbsp; Read more: Diagnosing Gender Bias in Image Recognition Systems (SAGE Journals).###################################################(AI) Supercomputers crack the exaflop barrier!&hellip;Mixed-precision results put Top500 list in perspective&hellip;Twice a year, the Top 500 List spits out the rankings for the world&rsquo;s fastest supercomputers. Right now, multiple countries are racing against eachother to crack the exaflop barrier (1000 petaflops per second peak computation). This year, the top system (Fugaku, in Japan) has 500 petaflops of peak computational performance per second, and, perhaps more importantly, 2 exaflops of peak performance from on the Top500 &lsquo;HPL-AI&rsquo; benchmark.The exaflop AI benchmark: HPL-AI is a test that &ldquo;seeks to highlight the convergence of HPC and artificial intelligence (AI) workloads based on machine learning and deep learning by solving a system of linear equations using novel, mixed-precision algorithms that exploit modern hardware&rdquo;. The test predominantly uses 16-bit computation, so it makes intuitive sense that a 500pf system for 64-bit computation would be capable of ~2exaflops of mostly 16-bit performance (500*4 = 2000, 16*4=64).World&rsquo;s fastest supercomputer 2020: Fugaku (Japan): 537 petaflops (Pf) peak performance.2015: Tianhe-2A (China): 54 Pf peak.2010: Tianhe-1A (China): 4.7 Pf peak 2005: BlueGene (USA): 367 teraflops p…"

---

### Import AI 224: AI cracks the exaflop barrier;  robots and COVID surveillance; gender bias in computer vision

How robots get used for COVID surveillance:&hellip;&rsquo;SeekNet&rsquo; lets University of Maryland use a robot to check people for symptoms&hellip;Researchers with the University of Maryland have built SeekNet, software to help them train robots to navigate a environment and intelligently visually inspect the people in it by navigating to get a good look at people, if they&rsquo;re at first colluded. To test out how useful the technology is, they use it to do COVID surveillance.What they did: SeekNet is a network that smushes together a perception network with a movement one, with the two networks informing eachother; if the perception network thinks it has spotted part of a human (e.g, someone standing behind someone else), it&rsquo;ll talk to the movement network and get it to reposition the robot to get a better look.What they used it for: To test out their system, they put it on a small mobile robot and used it to surveil people for COVID symptoms. &ldquo;We fuse multiple modalities to simultaneously measure the vital signs, like body temperature, respiratory rate, heart rate, etc., to improve the screening accuracy,&rdquo; they write.What happens next: As I&rsquo;ve written for CSET (analysis here, tweet thread here), COVID is going to lead to an increase in the use of computer vision for a variety of surveillance applications. The open question is whether a particular nation or part of the world becomes dominant in the development of this technology, and about how Western governments choose to use this technology after the crisis is over and we have all these cheap, powerful, surveillance tools available.&nbsp; Read more: SeekNet: Improved Human Instance Segmentation via Reinforcement Learning Based Optimized Robot Relocation (arXiv).###################################################DeepMind open-sources a 2D RL simulator:..Yes, another 2D simulator &ndash; the more the merrier&hellip;DeepMind has released DeepMind Lab 2D, software to help people carry out reinforcement learning tasks in 2D. The software makes it easy to create different 2D environments and unleash agents on them and also supports multiple simultaneous agents being run in the same simulation.&nbsp;What is DeepMind Lab 2D useful for? The software &rdquo; generalizes and extends a popular internal system at DeepMind which supported a large range of research projects,&rdquo; the authors write. &ldquo;It was especially popular for multi-agent research involving workflows with significant environment-side iteration.&rdquo;Why might you not want to use DeepMind Lab 2D? While the software seems useful, there are some existing alternatives based on the video game description language (VGDL) (including competitions and systems built on top of it, like the &lsquo;General Video Game AI Framework&rsquo; (Import AI: 101) and &lsquo;Deceptive Gains&rsquo; (#80)), or DeepMind&rsquo;s own 2017-era &lsquo;AI Safety Gridworlds&lsquo;. However, I think we&rsquo;ll ultimately evaluate RL agents across a whole bunch of different problems running in a variety of simulators, so I expect it&rsquo;s useful to have more of them.&nbsp; Read more: DeepMind Lab2D (arXiv).&nbsp; Get the code: DeepMind Lab2D (GitHub).###################################################



Facebook&rsquo;s attempt to use AI for content moderation hurts its contractors:&hellip;Open letter highlights pitfalls of using AI to analyze AI&hellip;Over 200 Facebook content moderators recently complained to the leadership of Facebook as well as contractor companies Covalen and Accenture about the ways they&rsquo;ve been treated during the pandemic. And in the letter, published by technology advocacy group Foxglove, they discuss an AI moderation experiment Facebook conducted earlier this year&hellip;AI to monitor AI: &ldquo;To cover the pressing need to moderate the masses of violence, hate, terrorism, child abuse, and other horrors that we fight for you every day, you sought to substitute our work with the work of a machine.Without informing the public, Facebook undertook a massive live experiment in heavily automated content moderation. Management told moderators that we should no longer see certain varieties of toxic content coming up in the review tool from which we work&mdash; such as graphic violence or child abuse, for example.



The AI wasn&rsquo;t up to the job. Important speech got swept into the maw of the Facebook filter&mdash;and risky content, like self-harm, stayed up.&rdquo;Why this matters: At some point, we&rsquo;re going to be able to use AI systems to analyze and classify subtle, thorny issues like sexualization, violence, racism, and so on. But we&rsquo;re definitely in the &lsquo;Wright Brothers&rsquo; phase of this technology, with much to be discovered before it become reliable enough to substitute for people. In the meanwhile, humans and machines will need to team together on these issues, with all the complication that entails.&nbsp;&nbsp; Read the letter in full here: Open letter from content moderators re: pandemic (Foxglove).



###################################################Google, Microsoft, Amazon&rsquo;s commercial computer vision systems exhibit serious gender biases:&hellip;Study shows gender-based mis-identification of people, and worse&hellip;An interdisciplinary team of researchers have analyzed how commercially available computer vision systems classify differently gendered people &ndash; and the results seem to show significant biases.What they found: In tests on Google Cloud, Microsoft Azure, and Amazon Web Services, they find that object recognition systems offered by these companies display &ldquo;significant gender bias&rdquo; in how they label photos of men and women. Of more potential concern, they found that Google&rsquo;s system in particular had a poor recognition rate for men versus women &ndash; when tested on one dataset, it correctly labeled men 85.8% correctly, versus 75.5% for women (and for a more complex dataset, it guessed men correctly 45.3% of the time and women 25.8%.Why this matters: &ldquo;If &ldquo;a picture is worth a thousand words,&rdquo; but an algorithm provides only a handful, the words it chooses are of immense consequence,&rdquo; the researchers write. This feels true &ndash; the decisions that AI people make about their machines are, ultimately, going to lead to the magnification of those assumptions in the systems that get deployed into the world, which will have real consequences on who does and doesn&rsquo;t get &lsquo;seen&rsquo; or &lsquo;perceived&rsquo; by AI.&nbsp; Read more: Diagnosing Gender Bias in Image Recognition Systems (SAGE Journals).###################################################(AI) Supercomputers crack the exaflop barrier!&hellip;Mixed-precision results put Top500 list in perspective&hellip;Twice a year, the Top 500 List spits out the rankings for the world&rsquo;s fastest supercomputers. Right now, multiple countries are racing against eachother to crack the exaflop barrier (1000 petaflops per second peak computation). This year, the top system (Fugaku, in Japan) has 500 petaflops of peak computational performance per second, and, perhaps more importantly, 2 exaflops of peak performance from on the Top500 &lsquo;HPL-AI&rsquo; benchmark.The exaflop AI benchmark: HPL-AI is a test that &ldquo;seeks to highlight the convergence of HPC and artificial intelligence (AI) workloads based on machine learning and deep learning by solving a system of linear equations using novel, mixed-precision algorithms that exploit modern hardware&rdquo;. The test predominantly uses 16-bit computation, so it makes intuitive sense that a 500pf system for 64-bit computation would be capable of ~2exaflops of mostly 16-bit performance (500*4 = 2000, 16*4=64).World&rsquo;s fastest supercomputer 2020: Fugaku (Japan): 537 petaflops (Pf) peak performance.2015: Tianhe-2A (China): 54 Pf peak.2010: Tianhe-1A (China): 4.7 Pf peak 2005: BlueGene (USA): 367 teraflops p…