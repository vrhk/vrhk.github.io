---

layout: post
category: threads
title: "[D] why softmax+CE over sigmoid+BCE?"
date: 2019-11-08 17:12:30
link: https://vrhk.co/2qvbkLv
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Most of the popular neural network language models use softmax+cross entropy loss during training, which is based on the assumption that only the..."

---

### [D] why softmax+CE over sigmoid+BCE?

Most of the popular neural network language models use softmax+cross entropy loss during training, which is based on the assumption that only the...