---

layout: post
category: threads
title: "[D] Attention is All You Need - Transformer Decoder &amp; Shared Matrices Question"
date: 2020-03-01 03:37:38
link: https://vrhk.co/3a9dbXY
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "I was reading the paper and I am confused about the things below: * Under section 3.4 Embeddings and Softmax it is stated: 'we share the same..."

---

### [D] Attention is All You Need - Transformer Decoder &amp; Shared Matrices Question

I was reading the paper and I am confused about the things below: * Under section 3.4 Embeddings and Softmax it is stated: 'we share the same...