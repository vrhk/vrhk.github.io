---

layout: post
category: product
title: "Import AI 173: Here come the Chinese “violence detection” systems; how to use GPT-2 to spot propaganda; + can Twitter deal with deepfakes?"
date: 2019-11-18 16:36:35
link: https://vrhk.co/2Xvrukr
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "What happens when CCTV cameras come with automatic violence detectors?&hellip;&rdquo;Real-World Fighting&rdquo; dataset sketches out a future of automated surveillance&hellip;Researchers with Duke Kunshan University and Sun Yat-sen University in China have developed RWF-2000, a new dataset of &ldquo;violent&rdquo; behaviors collected from YouTube. They also train a classifier on this dataset, letting them (with quite poor accuracy) automatically identify violent behaviors in CCTV videos.
&nbsp; &nbsp;The Real-World Fighting (RWF) dataset consists of 2000 video clips captured by surveillance cameras, collected from YouTube. Each clip is 5-seconds long and half contain &ldquo;violent behaviors&rdquo; while the others do not. RWF is twice as large as the &lsquo;Hockey Fight&rsquo; dataset, and roughly 10X as large as other datasets (Movies Fight and Crowd Violence) used in this domain.&nbsp;
&nbsp; &nbsp;Can your algorithm spot violence? In tests, the researchers develop a system (which they call a &ldquo;Flow Gated Network&rdquo;) to categorize violent versus non-violent videos. They get a test accuracy of approximately 86.75% on the RWF-2000 dataset, and scores of 98%, 100%, and 84.44% on the Hockey Fight, Movies Fight, and Crowd Violence datasets.
&nbsp; &nbsp;Why this matters: It seems like the ultimate purpose of systems like this will be automated surveillance systems which spot so-called violent behavior and likely flag it to humans (or, eventually, drones/robots) to intercede. The technology will need to mature before it becomes useful enough to be used in production, but papers like this sketch out how with a lot of data and a little bit of determination it&rsquo;s becoming pretty easy to create systems to perform video classification. The next question is: which organizations or states will deploy this technology first, and how will people feel about it when it is deployed?&nbsp;&nbsp;&nbsp;Read more: RWF-2000: An Open Large Scale Video Database for Violence Detection (Arxiv).&nbsp;&nbsp;&nbsp;Get the RWF-2000 dataset from here (GitHub).
####################################################
Canada refuses visas to visiting AI researchers:&hellip;In repeat of 2018 NeurIPS, Canadian officials withhold visas from African AI researchers&hellip;Last year Canada&rsquo;s PM, Justin Trudeau, was asked at a press conference if he knew about the fact multiple AI researchers associated with &ldquo;Black in AI&rdquo; had been refused visas to enter the country for the annual NeurIPS conference. Trudeau said he&rsquo;d look into it. Clearly, someone forgot to write a memo, as the same thing is happening again ahead of NeurIPS 2019. Black in AI told the BBC that it was aware of around 30 researchers who had so far been unable to enter the country.&nbsp;
&nbsp;&nbsp;&nbsp;&ldquo;The importance cannot be overstressed. It&rsquo;s more and more important for AI to build a diverse body,&rdquo; Black in AI organizer Charles Onu told the BBC.&nbsp;&nbsp;&nbsp;Read more: Canada refuses visas to over a dozen African AI researchers (BBC News).
####################################################
Fine-tuning language models to spot (and generate) propaganda:&hellip;FireEye, GPT-2 and the Russian Internet Research Agency&hellip;Researchers with security company FireEye have used the GPT2 language model to make a system that can help identify (and potentially generate) propaganda in the style of Russia&rsquo;s Internet Research Agency.
&nbsp; &nbsp;Making a troll-spotter: For this project, the researchers fine-tune GPT-2 so it can identify and generate synthetic text in the style of the IRA. To do this, they gather millions of tweets attributed to the IRA, then fine-tune GPT-2 against them. After fine-tuning, their model can spit out some IRA-esque tweets (e.g, &ldquo;It&rsquo;s disgraceful that our military has to be in Syria &amp; Iraq&rdquo;, &ldquo;It&rsquo;s disgraceful that people have to waste time, energy to pay lip service to #Junk-Science #fakenews&rdquo;, etc).
&nbsp; &nbsp;Building a propaganda detector: Once you can use a language model to generate something, you can use that same language model to try and detect its own generations. That&rsquo;s basically what they do here by fine-tuning GPT-2 on a few distinct IRA datasets, then seeing how well they can distinguish synthetic tweets from real tweets. In experiments, they&rsquo;re able to build a detector that can accurately classify some of the tweets. &ldquo;The fine-tuned classifier should generalize well to newly ingested social media posts,&rdquo; they write, &ldquo;providing analysts a capability they can use to separate signal from noise&rdquo;.
&nbsp; &nbsp;Why this matters: &ldquo;GPT-2&rsquo;s authors and subsequent researchers have warned about potential malicious use cases enabled by this powerful natural language generation technology, and while it was conducted here for a defensive application in a controlled offline setting using readily available open source data, our research reinforces this concern,&rdquo; they write.&nbsp;&nbsp;&nbsp;Read more: Attention Is All They Need: Combating Social Media Information Operations with Neural Language Models (FireEye).
####################################################
AI for reading lips in the wild:&hellip;How computers can help deaf people and double up for other applications enroute&hellip;In Stanley Kubrick&rsquo;s 2001: A Space Odyssey two of the astronauts retreat to a small pod to hide from HAL, a faulty AI system running the spaceship. Unfortunately for them, though HAL can&rsquo;t hear their conversation from within the pod, it can see their lips through a window. HAL reads their lips and figures out their plan, leading to some fairly gruesome consequences. Today, we&rsquo;re starting to develop AI systems capable of accurate lip-reading under constrained circumstances. Now, researchers with Imperial College London, the University of Nottingham and the Samsung AI Center have extended a lip-reading dataset to make it easier for people to train systems that can read lips under a variety of circumstances.
&nbsp; &nbsp;Expanding LRW: To do this, the researchers use a technology called a 3D morphable model (3DMM) to augment the data in LRW, a popular lip-reading dataset. LRW contains 1,000 speakers saying more than 500 distinct words, with 800 utterances for each word. Through the use of 3DMM, they augment the faces in LRW so that each face gets tilted in 3D space, creating a training dataset with more variety than the original LRW. They call this new dataset LRW in Large Pose (LP).
&nbsp; &nbsp;Learning to read lips: In experiments, the researchers are able to use the augmented dataset to train systems to about 80% accuracy. Lip-reading is a very hard problem, though, and they obtain performance of near-60% accuracy on the Lip Reading Sentences 2 (LRS2) database, which mostly consists of footage from BBC TV shows and news and is therefore &ldquo;very challenging due to a large variation in the utterance length and speaker&rsquo;s head pose&rdquo;. They also show that their system yields significant improvements when applied on heads with poses tilted far away from front-facing the camera.
&nbsp; &nbsp;Why this matters: Lip-reading is a classic omni-use AI technology &ndash; the technology will eventually aid the deaf or hard-of-hearing, but it will also be inevitably used for surveillance and, most likely, advertising as well. We should generally prepare for a world where &ndash; eventually &ndash; anything attached to a camera has the capability to have &ldquo;human-equivalent&rdquo; sensing capabilities for things like lip-reading. Society will drastically alter in response.&nbsp;&nbsp;&nbsp;Read more: Towards Pose-invariant Lip-Reading (Arxiv).
####################################################
How should Twitter deal with deepfakes?&hellip;The social media company wants to hear from YOU!&hellip;Twitter is currently figuring out what poli…"

---

### Import AI 173: Here come the Chinese “violence detection” systems; how to use GPT-2 to spot propaganda; + can Twitter deal with deepfakes?

What happens when CCTV cameras come with automatic violence detectors?&hellip;&rdquo;Real-World Fighting&rdquo; dataset sketches out a future of automated surveillance&hellip;Researchers with Duke Kunshan University and Sun Yat-sen University in China have developed RWF-2000, a new dataset of &ldquo;violent&rdquo; behaviors collected from YouTube. They also train a classifier on this dataset, letting them (with quite poor accuracy) automatically identify violent behaviors in CCTV videos.
&nbsp; &nbsp;The Real-World Fighting (RWF) dataset consists of 2000 video clips captured by surveillance cameras, collected from YouTube. Each clip is 5-seconds long and half contain &ldquo;violent behaviors&rdquo; while the others do not. RWF is twice as large as the &lsquo;Hockey Fight&rsquo; dataset, and roughly 10X as large as other datasets (Movies Fight and Crowd Violence) used in this domain.&nbsp;
&nbsp; &nbsp;Can your algorithm spot violence? In tests, the researchers develop a system (which they call a &ldquo;Flow Gated Network&rdquo;) to categorize violent versus non-violent videos. They get a test accuracy of approximately 86.75% on the RWF-2000 dataset, and scores of 98%, 100%, and 84.44% on the Hockey Fight, Movies Fight, and Crowd Violence datasets.
&nbsp; &nbsp;Why this matters: It seems like the ultimate purpose of systems like this will be automated surveillance systems which spot so-called violent behavior and likely flag it to humans (or, eventually, drones/robots) to intercede. The technology will need to mature before it becomes useful enough to be used in production, but papers like this sketch out how with a lot of data and a little bit of determination it&rsquo;s becoming pretty easy to create systems to perform video classification. The next question is: which organizations or states will deploy this technology first, and how will people feel about it when it is deployed?&nbsp;&nbsp;&nbsp;Read more: RWF-2000: An Open Large Scale Video Database for Violence Detection (Arxiv).&nbsp;&nbsp;&nbsp;Get the RWF-2000 dataset from here (GitHub).
####################################################
Canada refuses visas to visiting AI researchers:&hellip;In repeat of 2018 NeurIPS, Canadian officials withhold visas from African AI researchers&hellip;Last year Canada&rsquo;s PM, Justin Trudeau, was asked at a press conference if he knew about the fact multiple AI researchers associated with &ldquo;Black in AI&rdquo; had been refused visas to enter the country for the annual NeurIPS conference. Trudeau said he&rsquo;d look into it. Clearly, someone forgot to write a memo, as the same thing is happening again ahead of NeurIPS 2019. Black in AI told the BBC that it was aware of around 30 researchers who had so far been unable to enter the country.&nbsp;
&nbsp;&nbsp;&nbsp;&ldquo;The importance cannot be overstressed. It&rsquo;s more and more important for AI to build a diverse body,&rdquo; Black in AI organizer Charles Onu told the BBC.&nbsp;&nbsp;&nbsp;Read more: Canada refuses visas to over a dozen African AI researchers (BBC News).
####################################################
Fine-tuning language models to spot (and generate) propaganda:&hellip;FireEye, GPT-2 and the Russian Internet Research Agency&hellip;Researchers with security company FireEye have used the GPT2 language model to make a system that can help identify (and potentially generate) propaganda in the style of Russia&rsquo;s Internet Research Agency.
&nbsp; &nbsp;Making a troll-spotter: For this project, the researchers fine-tune GPT-2 so it can identify and generate synthetic text in the style of the IRA. To do this, they gather millions of tweets attributed to the IRA, then fine-tune GPT-2 against them. After fine-tuning, their model can spit out some IRA-esque tweets (e.g, &ldquo;It&rsquo;s disgraceful that our military has to be in Syria &amp; Iraq&rdquo;, &ldquo;It&rsquo;s disgraceful that people have to waste time, energy to pay lip service to #Junk-Science #fakenews&rdquo;, etc).
&nbsp; &nbsp;Building a propaganda detector: Once you can use a language model to generate something, you can use that same language model to try and detect its own generations. That&rsquo;s basically what they do here by fine-tuning GPT-2 on a few distinct IRA datasets, then seeing how well they can distinguish synthetic tweets from real tweets. In experiments, they&rsquo;re able to build a detector that can accurately classify some of the tweets. &ldquo;The fine-tuned classifier should generalize well to newly ingested social media posts,&rdquo; they write, &ldquo;providing analysts a capability they can use to separate signal from noise&rdquo;.
&nbsp; &nbsp;Why this matters: &ldquo;GPT-2&rsquo;s authors and subsequent researchers have warned about potential malicious use cases enabled by this powerful natural language generation technology, and while it was conducted here for a defensive application in a controlled offline setting using readily available open source data, our research reinforces this concern,&rdquo; they write.&nbsp;&nbsp;&nbsp;Read more: Attention Is All They Need: Combating Social Media Information Operations with Neural Language Models (FireEye).
####################################################
AI for reading lips in the wild:&hellip;How computers can help deaf people and double up for other applications enroute&hellip;In Stanley Kubrick&rsquo;s 2001: A Space Odyssey two of the astronauts retreat to a small pod to hide from HAL, a faulty AI system running the spaceship. Unfortunately for them, though HAL can&rsquo;t hear their conversation from within the pod, it can see their lips through a window. HAL reads their lips and figures out their plan, leading to some fairly gruesome consequences. Today, we&rsquo;re starting to develop AI systems capable of accurate lip-reading under constrained circumstances. Now, researchers with Imperial College London, the University of Nottingham and the Samsung AI Center have extended a lip-reading dataset to make it easier for people to train systems that can read lips under a variety of circumstances.
&nbsp; &nbsp;Expanding LRW: To do this, the researchers use a technology called a 3D morphable model (3DMM) to augment the data in LRW, a popular lip-reading dataset. LRW contains 1,000 speakers saying more than 500 distinct words, with 800 utterances for each word. Through the use of 3DMM, they augment the faces in LRW so that each face gets tilted in 3D space, creating a training dataset with more variety than the original LRW. They call this new dataset LRW in Large Pose (LP).
&nbsp; &nbsp;Learning to read lips: In experiments, the researchers are able to use the augmented dataset to train systems to about 80% accuracy. Lip-reading is a very hard problem, though, and they obtain performance of near-60% accuracy on the Lip Reading Sentences 2 (LRS2) database, which mostly consists of footage from BBC TV shows and news and is therefore &ldquo;very challenging due to a large variation in the utterance length and speaker&rsquo;s head pose&rdquo;. They also show that their system yields significant improvements when applied on heads with poses tilted far away from front-facing the camera.
&nbsp; &nbsp;Why this matters: Lip-reading is a classic omni-use AI technology &ndash; the technology will eventually aid the deaf or hard-of-hearing, but it will also be inevitably used for surveillance and, most likely, advertising as well. We should generally prepare for a world where &ndash; eventually &ndash; anything attached to a camera has the capability to have &ldquo;human-equivalent&rdquo; sensing capabilities for things like lip-reading. Society will drastically alter in response.&nbsp;&nbsp;&nbsp;Read more: Towards Pose-invariant Lip-Reading (Arxiv).
####################################################
How should Twitter deal with deepfakes?&hellip;The social media company wants to hear from YOU!&hellip;Twitter is currently figuring out what poli…