---

layout: post
category: threads
title: "r/MachineLearning - [D] Computing `q dot q` instead of `q dot k` when calculating scores for self-attention in Transformer"
date: 2019-08-28 08:17:29
link: https://vrhk.co/2ZpgaL1
image: https://external-preview.redd.it/-kIssHH3THoxKqORIlpxzHrMPIzNQpXy3HRihwx5jNM.jpg?auto=webp&s=1be8201f880a5c366de54369c2aa4e955104cb29
domain: reddit.com
author: "reddit"
icon: https://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "0 votes and 0 comments so far on Reddit"

---

### r/MachineLearning - [D] Computing `q dot q` instead of `q dot k` when calculating scores for self-attention in Transformer

0 votes and 0 comments so far on Reddit