---

layout: post
category: product
title: "Import AI 220: Google builds an AI borderwall; better speech rec via pre-training; plus, a summary of ICLR papers"
date: 2020-10-26 17:46:35
link: https://vrhk.co/2HtB83H
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Want to measure progress towards AGI? Welcome to a sissyphean task! &hellip;.Whenever we surpass an AGI-scale benchmark, we discover just how limited it really was&hellip;One of the reasons it&rsquo;s so hard to develop general intelligence is whenever people come close to beating a benchmark oriented around measuring progress towards AGI, we discover just how limited this benchmark was and how far we have to go. That&rsquo;s the gist of a new blogpost from a &ldquo;fervent generalist&rdquo; from a person using the pseudonym &lsquo;Z&rsquo;, which discusses some of the problems inherent to measuring progress towards advanced AI systems.&nbsp; &ldquo;Tasks we&rsquo;ve succeeded at addressing with computers seem mundane, mere advances in some other field, not true AI. We miss that it was work in AI that lead to them,&rdquo; they write. &ldquo;Perhaps the benchmarks were always flawed, because we set them as measures of a general system, forgetting that the first systems to break through might be specialized to the task. You only see how &ldquo;hackable&rdquo; the test was after you see it &ldquo;passed&rdquo; by a system that clearly isn&rsquo;t &ldquo;intelligent&rdquo;.&rdquo;So, what should we do? The author is fairly pessimistic about our ability to make progress here, because whenever people define new harder benchmarks, that usually incentivizes the AI community to collectively race to develop a system that can beat the benchmark. &ldquo;Against such relentless optimization both individually and as a community, any decoupling between the new benchmark and AGI progress will manifest.&rdquo;Why this matters: Metrics are one of the ways we can orient ourselves with regard to the scientific progress being made by AI systems &ndash; and posts like this remind us that any single set of metrics is likely to be flawed or overfit in some way. My intuition is the way to go is developing ever-larger suites of AI testing systems which we can then use to more holistically characterize the capabilities of any given system.&nbsp; Read more: The difficulty of AI benchmarks (Singular Paths, blog).###################################################What&rsquo;s hard and what&rsquo;s easy about measuring AI? Check out what the experts say:&hellip;Research paper lays out measurement and assessment challenges for AI policy&hellip;Last year I helped organize a workshop at Stanford that brought together over a hundred AI practitioners and researchers to discuss the challenges of measuring and assessing AI. Our workshop identified six core challenges for measuring AI systems:&ndash; Defining AI; as anyone knows, every policymaking exercise starts with definitions, and our definitions of AI are lacking.&ndash; What are the factors that drive AI progress and how can we disambiguate them?&ndash; How do we use bibliometric data to improve our analysis?&ndash; What tools are available to help us analyze the economic impact of AI?&ndash; How can we measure the societal impact of AI?&ndash; What methods can we use to better anticipate the risks and threats of deployed AI systems?Podcast conversation: Myself and Ray Perrault, co-chairs of the AI Index &ndash; a Stanford initiative to measure and assess AI, which hosted the workshop &ndash; recently appeared on the &lsquo;Let&rsquo;s Talk AI&rsquo; podcast to discuss the paper with Sharon Zhou.Why this matters: Before we can regulate AI, we need to be able to measure and assess it at various levels of abstraction. Figuring out better tools to use to measure AI systems will help technologists create information that can drive policy decisions. More broadly, by building &lsquo;measurement infrastructure&rsquo; within governments, we can improve the ability for civil society to anticipate and oversee challenges brought on by the maturation of AI technology.&nbsp; Read more: Measurement in AI Policy: Opportunities and Challenges (arXiv).&nbsp; &nbsp; Listen to the podcast here: Measurement in AI Policy: Opportunities and Challenges (Let&rsquo;s Talk AI, Podbean).###################################################



ICLR &ndash; a sampling of interesting papers for the 2021 conference:&hellip;General scaling methods! NLP! Optimization! And so much more&hellip;ICLR is a major AI research conference that uses anonymous, public submissions during the review phase. Papers are currently under review and AI researcher Aran Komatsuzaki has written a blog summarizing some of the more interesting papers and the trends behind them.What&rsquo;s hot in 2021:&ndash; Scaling models to unprecedented sizes, while developing techniques to improve the efficiency of massive model training.&ndash; Natural language processing; scaling models, novel training regimes, and methods to improve the efficiency of attention operations.&ndash; RL agents that learn in part by modelling &ndash; sometimes described more colloquially as &lsquo;dreaming&rsquo; &ndash; the world, then using this to improve performance.&ndash; Optimization: Learning optimizations systems to do better optimization, and so on.Why this matters: Scaling has typically led to quite strong gains in certain types of machine learning &ndash; if we look at the above trends, they&rsquo;re all inherently either about improving the efficiency of scaling, or figuring out way to make models with fewer priors that learn richer structures at scale.&nbsp;&nbsp; Read more: Some Notable Recent ML Papers and Future Trends (Aran Komatsuzaki, blog).###################################################Robot navigation gets a boost with &lsquo;RxR&rsquo; dataset:&hellip;The era of autonomous robot navigation trundles closer&hellip;How can we create robots that can intelligently navigate their environment, teach eachother to navigate, and follow instructions? Google thinks one way is to create a massive dataset consisting of various paths through high-fidelity 3D buildings (recorded via &lsquo;MatterPort&lsquo;), where each path is accompanied by detailed telemetry data as the navigator goes through the building, as well as instructions describing the path they take.The dataset: The &lsquo;Room-Across-Room&rsquo; (RxR) dataset contains ~126,000 instructions for ~16500 distinct paths through a rich, varied set of rooms. &ldquo;RxR is 10x larger, multilingual (English, Hindi and Telugu), with longer and more variable paths, and it includes&hellip; fine-grained visual groundings that relate each word to pixels/surfaces in the environment,&rdquo; Google says in a research paper.The most interesting thing about this is&hellip; the use of what Google terms pose traces &ndash; that is, when the people building the RxR dataset move around the world they &ldquo;speak as they move and later transcribe their audio; our annotation tool records their 3D poses and time-aligns the entire pose trace with words in the transcription&rdquo;. This means researchers who use this data have a rich, multi-modal dataset that pairs complex 3D information with written instructions, all within a simulated environment that provides togglable options for surface reconstructions, RGB-D panoramas, and 2D and 3D semantic segmentations. This means it&rsquo;s likely we&rsquo;ll see people figure out a bunch of creative ways to use this rich set of data.&nbsp; Get the code: Room-Across-Room (RxR) Dataset (GitHub).&nbsp; Read the paper: Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding (arXiv).&nbsp; Read a thread about the research from Google here (Peter Anderson, Twitter).###################################################Google helps Anduril build America&rsquo;s virtual, AI-infused border wall:&hellip;.21st century state capabilities = AI capabilities&hellip;Google has a contract with the Customers and Border Protection agency to do work with Anduril, the military/defence AI startup founded by former VR wunderkind Palmer Luckey (and backed by Peter Thiel). This comes via The Intercept, which base…"

---

### Import AI 220: Google builds an AI borderwall; better speech rec via pre-training; plus, a summary of ICLR papers

Want to measure progress towards AGI? Welcome to a sissyphean task! &hellip;.Whenever we surpass an AGI-scale benchmark, we discover just how limited it really was&hellip;One of the reasons it&rsquo;s so hard to develop general intelligence is whenever people come close to beating a benchmark oriented around measuring progress towards AGI, we discover just how limited this benchmark was and how far we have to go. That&rsquo;s the gist of a new blogpost from a &ldquo;fervent generalist&rdquo; from a person using the pseudonym &lsquo;Z&rsquo;, which discusses some of the problems inherent to measuring progress towards advanced AI systems.&nbsp; &ldquo;Tasks we&rsquo;ve succeeded at addressing with computers seem mundane, mere advances in some other field, not true AI. We miss that it was work in AI that lead to them,&rdquo; they write. &ldquo;Perhaps the benchmarks were always flawed, because we set them as measures of a general system, forgetting that the first systems to break through might be specialized to the task. You only see how &ldquo;hackable&rdquo; the test was after you see it &ldquo;passed&rdquo; by a system that clearly isn&rsquo;t &ldquo;intelligent&rdquo;.&rdquo;So, what should we do? The author is fairly pessimistic about our ability to make progress here, because whenever people define new harder benchmarks, that usually incentivizes the AI community to collectively race to develop a system that can beat the benchmark. &ldquo;Against such relentless optimization both individually and as a community, any decoupling between the new benchmark and AGI progress will manifest.&rdquo;Why this matters: Metrics are one of the ways we can orient ourselves with regard to the scientific progress being made by AI systems &ndash; and posts like this remind us that any single set of metrics is likely to be flawed or overfit in some way. My intuition is the way to go is developing ever-larger suites of AI testing systems which we can then use to more holistically characterize the capabilities of any given system.&nbsp; Read more: The difficulty of AI benchmarks (Singular Paths, blog).###################################################What&rsquo;s hard and what&rsquo;s easy about measuring AI? Check out what the experts say:&hellip;Research paper lays out measurement and assessment challenges for AI policy&hellip;Last year I helped organize a workshop at Stanford that brought together over a hundred AI practitioners and researchers to discuss the challenges of measuring and assessing AI. Our workshop identified six core challenges for measuring AI systems:&ndash; Defining AI; as anyone knows, every policymaking exercise starts with definitions, and our definitions of AI are lacking.&ndash; What are the factors that drive AI progress and how can we disambiguate them?&ndash; How do we use bibliometric data to improve our analysis?&ndash; What tools are available to help us analyze the economic impact of AI?&ndash; How can we measure the societal impact of AI?&ndash; What methods can we use to better anticipate the risks and threats of deployed AI systems?Podcast conversation: Myself and Ray Perrault, co-chairs of the AI Index &ndash; a Stanford initiative to measure and assess AI, which hosted the workshop &ndash; recently appeared on the &lsquo;Let&rsquo;s Talk AI&rsquo; podcast to discuss the paper with Sharon Zhou.Why this matters: Before we can regulate AI, we need to be able to measure and assess it at various levels of abstraction. Figuring out better tools to use to measure AI systems will help technologists create information that can drive policy decisions. More broadly, by building &lsquo;measurement infrastructure&rsquo; within governments, we can improve the ability for civil society to anticipate and oversee challenges brought on by the maturation of AI technology.&nbsp; Read more: Measurement in AI Policy: Opportunities and Challenges (arXiv).&nbsp; &nbsp; Listen to the podcast here: Measurement in AI Policy: Opportunities and Challenges (Let&rsquo;s Talk AI, Podbean).###################################################



ICLR &ndash; a sampling of interesting papers for the 2021 conference:&hellip;General scaling methods! NLP! Optimization! And so much more&hellip;ICLR is a major AI research conference that uses anonymous, public submissions during the review phase. Papers are currently under review and AI researcher Aran Komatsuzaki has written a blog summarizing some of the more interesting papers and the trends behind them.What&rsquo;s hot in 2021:&ndash; Scaling models to unprecedented sizes, while developing techniques to improve the efficiency of massive model training.&ndash; Natural language processing; scaling models, novel training regimes, and methods to improve the efficiency of attention operations.&ndash; RL agents that learn in part by modelling &ndash; sometimes described more colloquially as &lsquo;dreaming&rsquo; &ndash; the world, then using this to improve performance.&ndash; Optimization: Learning optimizations systems to do better optimization, and so on.Why this matters: Scaling has typically led to quite strong gains in certain types of machine learning &ndash; if we look at the above trends, they&rsquo;re all inherently either about improving the efficiency of scaling, or figuring out way to make models with fewer priors that learn richer structures at scale.&nbsp;&nbsp; Read more: Some Notable Recent ML Papers and Future Trends (Aran Komatsuzaki, blog).###################################################Robot navigation gets a boost with &lsquo;RxR&rsquo; dataset:&hellip;The era of autonomous robot navigation trundles closer&hellip;How can we create robots that can intelligently navigate their environment, teach eachother to navigate, and follow instructions? Google thinks one way is to create a massive dataset consisting of various paths through high-fidelity 3D buildings (recorded via &lsquo;MatterPort&lsquo;), where each path is accompanied by detailed telemetry data as the navigator goes through the building, as well as instructions describing the path they take.The dataset: The &lsquo;Room-Across-Room&rsquo; (RxR) dataset contains ~126,000 instructions for ~16500 distinct paths through a rich, varied set of rooms. &ldquo;RxR is 10x larger, multilingual (English, Hindi and Telugu), with longer and more variable paths, and it includes&hellip; fine-grained visual groundings that relate each word to pixels/surfaces in the environment,&rdquo; Google says in a research paper.The most interesting thing about this is&hellip; the use of what Google terms pose traces &ndash; that is, when the people building the RxR dataset move around the world they &ldquo;speak as they move and later transcribe their audio; our annotation tool records their 3D poses and time-aligns the entire pose trace with words in the transcription&rdquo;. This means researchers who use this data have a rich, multi-modal dataset that pairs complex 3D information with written instructions, all within a simulated environment that provides togglable options for surface reconstructions, RGB-D panoramas, and 2D and 3D semantic segmentations. This means it&rsquo;s likely we&rsquo;ll see people figure out a bunch of creative ways to use this rich set of data.&nbsp; Get the code: Room-Across-Room (RxR) Dataset (GitHub).&nbsp; Read the paper: Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding (arXiv).&nbsp; Read a thread about the research from Google here (Peter Anderson, Twitter).###################################################Google helps Anduril build America&rsquo;s virtual, AI-infused border wall:&hellip;.21st century state capabilities = AI capabilities&hellip;Google has a contract with the Customers and Border Protection agency to do work with Anduril, the military/defence AI startup founded by former VR wunderkind Palmer Luckey (and backed by Peter Thiel). This comes via The Intercept, which base…