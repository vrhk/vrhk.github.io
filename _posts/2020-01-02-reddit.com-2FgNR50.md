---

layout: post
category: threads
title: "[R] Benchmarking OpenAI's GPT-2 on GPUs vs. CPUs (realtime inference)"
date: 2020-01-02 16:27:34
link: https://vrhk.co/2FgNR50
image: https://external-preview.redd.it/nD0M4jt-20T4AC6DJZUyl-UApZeS8XOkoZ8Prk2kheA.jpg?width=1200&height=628.272251309&auto=webp&s=8764f64aa4a7623ad2dab92f7c7d8af11d3a96a7
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "I ran an experiment comparing both the latency and cost of serving realtime inference with GPT-2 on AWS using GPUs and CPUs. I also added a bit of..."

---

### [R] Benchmarking OpenAI's GPT-2 on GPUs vs. CPUs (realtime inference)

I ran an experiment comparing both the latency and cost of serving realtime inference with GPT-2 on AWS using GPUs and CPUs. I also added a bit of...