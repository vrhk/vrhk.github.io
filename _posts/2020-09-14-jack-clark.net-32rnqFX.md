---

layout: post
category: product
title: "Import AI 214: NVIDIA’s $40bn ARM deal; a new 57-subject NLP test; AI for plant disease detection"
date: 2020-09-14 17:16:30
link: https://vrhk.co/32rnqFX
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Should you buy NVIDIA&rsquo;s new GPU? Read this and find out:&hellip;Short answer: yes, though be prepared to cry a little upon opening your wallet&hellip;Every year, NVIDIA announces some GPUs, and some machine learning researchers stare tearfully at the thousands of dollars of hardware they need to buy to stay at the frontier, then crack open their wallets and buy a card. But how, exactly, are NVIDIA&rsquo;s new GPUs useful? Tim Dettmers has written a ludicrously detailed blog post which can help people understand what GPU to buy for Deep Learning and what the inherent tradeoffs  the Ampere architecture worth it? NVIDIA&rsquo;s new &lsquo;Ampere&rsquo; architecture cards come with a bunch of substantial performance improvements over their predecessors that makes it worth buying. Some particular highlights include: &ldquo;sparse network training and inference. Other features, such as the new data types should be seen more as an ease-of-use-feature as they provide the same performance boost as Turing does but without any extra programming required,&rdquo; writes Dettmers.&nbsp; &nbsp; Read more: Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning (Tim Dettmers, blog).Plus: NVIDIA to acquire ARM for $40 billion:&hellip;Acquisition may reshape the chip industry, though let&rsquo;s check back in a year&hellip;Late on Sunday, news broke that NVIDIA is going to acquire ARM from Softbank. ARM invents and licenses out chip designs to all of the world&rsquo;s top phone makers and Internet-of-Things companies (and, increasingly, a broad range of PCs, and burgeoning server and networking chips). The acquisition gives NVIDIA control of one of the planet&rsquo;s most strategically important semiconductor designers, though how well ARM&rsquo;s design-license business model works alongside NVIDIA&rsquo;s product business remains to be seen.&nbsp; &ldquo;Arm will continue to operate its open-licensing model while maintaining the global customer neutrality that has been foundational to its success,&rdquo; NVIDIA said in a press release.What does this have to do with AI? For the next few years, we can expect the majority of AI systems to be trained on GPUS and specialized hardware (e.g, TPUs, Graphcore). ARM&rsquo;s RISC-architecture chips don&rsquo;t lend themselves as well to the sort of massively parallelized computing operations required to train AI systems efficiently. But NVIDIA has plans to change this, as it plans to &ldquo;build a world-class [ARM] AI research facility, supporting developments in healthcare, life sciences, robotics, self-driving cars and other fields&rdquo;.&nbsp; An ARM supercomputer? The company also said it &ldquo;will build a state-of-the-art AI supercomputer, powered by Arm CPUs&rdquo;. (My bet is we&rsquo;ll see Arm CPUs as the co-processor linked to NVIDIA GPUs, and if NVIDIA executes well I&rsquo;d hope to see them build a ton of software to make these two somewhat dissimilar architectures play nice with eachother).Does this matter? Large technology acquisitions are difficult to get right, and it&rsquo;ll be at least a year till we&rsquo;ll have a sense of how much this deal matters for the broader field of AI and semiconductors. But NVIDIA has executed phenomenally well in recent years and the ever-growing strategic importance nations assign to computation means that, with ARM, it has become one of the world&rsquo;s most influential companies with regard to the future of computation. Let&rsquo;s hope they do ok!&nbsp; Read more: NVIDIA to Acquire Arm for $40 Billion, Creating World&rsquo;s Premier Computing Company for the Age of AI (NVIDIA press release).



###################################################Language models have got so good they&rsquo;ve broken our benchmarks. Enter a 57-subject NLP benchmark:&hellip;Benchmark lets researchers test out language models&rsquo; knowledge and capabilities in a range of areas&hellip;&nbsp; How can we measure the capabilities of large-scale language models (LMs)? That&rsquo;s a question researchers have been struggling with as, in recent years, LM development has outpaced LM testing &ndash; think of how the &lsquo;SQuAD&rsquo; test had to be revamped to &lsquo;SQuAD 2.0&rsquo; in a year due to rapid performance gains on the dataset, or the &lsquo;GLUE&rsquo; multi-task benchmark moving to &lsquo;SuperGLUE&rsquo; in response to faster-than-expected progress. Now, with language models like GPT3, even things like SuperGLUE are becoming less relevant. That&rsquo;s why researchers with UC Berkeley, Columbia, the University of Chicago, and the University of Illinois at Urbana-Champaign have developed a new way to assess language models.One test to eval them all: The benchmark &ldquo;ranges in difficulty from an elementary level to an advanced professional level, and it tests both world knowledge and problem solving ability&rdquo;. It consists of around 16,000 multiple choice questions across 57 distinct tasks. &ldquo;These include practice questions for tests such as the Graduate Record Examination and the United States Medical Licensing Examination. It also includes questions designed for undergraduate courses and questions designed for readers of Oxford University Press books. Some tasks cover a subject, like psychology, but at a specific level of difficulty, such as &ldquo;Elementary,&rdquo; &ldquo;High School,&rdquo; &ldquo;College,&rdquo; or &ldquo;Professional&rdquo;&rdquo;, they write.GPT-3: Quite smart for a machine, quite dumb for a human: In tests, GPT3 does markedly better than other systems (even obtaining superior performance to UnifiedQA, a QA-specific system), but the results still show our systems have a long way to go before they&rsquo;re very sophisticated. &ndash; 25%: Random baseline, guessing at answer out of four.&ndash;&nbsp; 24.8%: &lsquo;T5&rsquo;, a multipurpose language model from Google.&ndash; 38.5%: &lsquo;UnifiedQA&lsquo;, a question answering AI system&ndash; 25.9%: GPT-3 small (2.7 billion parameters)&ndash; 43.9%: GPT-3 X-Large (175 billion parameters).Where language models are weak: One notable weakness in the evaluated LMs are &ldquo;STEM subjects that emphasize mathematics or calculations. We speculate that is in part because GPT-3 acquires declarative knowledge more readily than procedural knowledge,&rdquo; they write.&nbsp; Read more: Measuring Massive Multitask Language Understanding (arXiv).&nbsp; Get the benchmark here (GitHub).



###################################################Could Anduril tell us about the future of military drones?&hellip;Defense tech startup releases fourth version of its &lsquo;Ghost&rsquo; drone&hellip;Anduril, an AI-defense-tech startup co-founded by former Oculus founder Palmer Luckey, has released the &lsquo;Ghost 4&rsquo;, a military-grade drone developed in the US for the US government (and others). The Ghost 4 is a visceral example of the advancement of low-cost robotics and avionics, as well as the continued progression of AI software (both modern DL systems, and classical AI) in the domain of drone surveillance and warfare. Anduril raised $200 million earlier this summer (#205).Fully autonomous: &ldquo;Ghosts are fully autonomous,&rdquo; Andrul says in a blog post about the tech. &ldquo;Ghost is controlled entirely through the Lattice software platform and requires minimal operator training.&rdquo;Drone swarms: &ldquo;Groups of Ghosts collaborate to achieve mission objectives that are impossible to achieve via a single unit. Additionally, Ghosts communicate status data with one another and can collaborate to conduct a &ldquo;battlefield handover&rdquo; to maintain persistence target coverage.&rdquo;&nbsp; &nbsp; The Ghost 4 can be outfitted with a range of modules for tasks like SLAM (simultaneous location and mapping), electronic warfare, the addition of alternate radios, and more. Other objects can be attached to it via a gimbal, such as surveillance cameras or &ndash;…"

---

### Import AI 214: NVIDIA’s $40bn ARM deal; a new 57-subject NLP test; AI for plant disease detection

Should you buy NVIDIA&rsquo;s new GPU? Read this and find out:&hellip;Short answer: yes, though be prepared to cry a little upon opening your wallet&hellip;Every year, NVIDIA announces some GPUs, and some machine learning researchers stare tearfully at the thousands of dollars of hardware they need to buy to stay at the frontier, then crack open their wallets and buy a card. But how, exactly, are NVIDIA&rsquo;s new GPUs useful? Tim Dettmers has written a ludicrously detailed blog post which can help people understand what GPU to buy for Deep Learning and what the inherent tradeoffs  the Ampere architecture worth it? NVIDIA&rsquo;s new &lsquo;Ampere&rsquo; architecture cards come with a bunch of substantial performance improvements over their predecessors that makes it worth buying. Some particular highlights include: &ldquo;sparse network training and inference. Other features, such as the new data types should be seen more as an ease-of-use-feature as they provide the same performance boost as Turing does but without any extra programming required,&rdquo; writes Dettmers.&nbsp; &nbsp; Read more: Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning (Tim Dettmers, blog).Plus: NVIDIA to acquire ARM for $40 billion:&hellip;Acquisition may reshape the chip industry, though let&rsquo;s check back in a year&hellip;Late on Sunday, news broke that NVIDIA is going to acquire ARM from Softbank. ARM invents and licenses out chip designs to all of the world&rsquo;s top phone makers and Internet-of-Things companies (and, increasingly, a broad range of PCs, and burgeoning server and networking chips). The acquisition gives NVIDIA control of one of the planet&rsquo;s most strategically important semiconductor designers, though how well ARM&rsquo;s design-license business model works alongside NVIDIA&rsquo;s product business remains to be seen.&nbsp; &ldquo;Arm will continue to operate its open-licensing model while maintaining the global customer neutrality that has been foundational to its success,&rdquo; NVIDIA said in a press release.What does this have to do with AI? For the next few years, we can expect the majority of AI systems to be trained on GPUS and specialized hardware (e.g, TPUs, Graphcore). ARM&rsquo;s RISC-architecture chips don&rsquo;t lend themselves as well to the sort of massively parallelized computing operations required to train AI systems efficiently. But NVIDIA has plans to change this, as it plans to &ldquo;build a world-class [ARM] AI research facility, supporting developments in healthcare, life sciences, robotics, self-driving cars and other fields&rdquo;.&nbsp; An ARM supercomputer? The company also said it &ldquo;will build a state-of-the-art AI supercomputer, powered by Arm CPUs&rdquo;. (My bet is we&rsquo;ll see Arm CPUs as the co-processor linked to NVIDIA GPUs, and if NVIDIA executes well I&rsquo;d hope to see them build a ton of software to make these two somewhat dissimilar architectures play nice with eachother).Does this matter? Large technology acquisitions are difficult to get right, and it&rsquo;ll be at least a year till we&rsquo;ll have a sense of how much this deal matters for the broader field of AI and semiconductors. But NVIDIA has executed phenomenally well in recent years and the ever-growing strategic importance nations assign to computation means that, with ARM, it has become one of the world&rsquo;s most influential companies with regard to the future of computation. Let&rsquo;s hope they do ok!&nbsp; Read more: NVIDIA to Acquire Arm for $40 Billion, Creating World&rsquo;s Premier Computing Company for the Age of AI (NVIDIA press release).



###################################################Language models have got so good they&rsquo;ve broken our benchmarks. Enter a 57-subject NLP benchmark:&hellip;Benchmark lets researchers test out language models&rsquo; knowledge and capabilities in a range of areas&hellip;&nbsp; How can we measure the capabilities of large-scale language models (LMs)? That&rsquo;s a question researchers have been struggling with as, in recent years, LM development has outpaced LM testing &ndash; think of how the &lsquo;SQuAD&rsquo; test had to be revamped to &lsquo;SQuAD 2.0&rsquo; in a year due to rapid performance gains on the dataset, or the &lsquo;GLUE&rsquo; multi-task benchmark moving to &lsquo;SuperGLUE&rsquo; in response to faster-than-expected progress. Now, with language models like GPT3, even things like SuperGLUE are becoming less relevant. That&rsquo;s why researchers with UC Berkeley, Columbia, the University of Chicago, and the University of Illinois at Urbana-Champaign have developed a new way to assess language models.One test to eval them all: The benchmark &ldquo;ranges in difficulty from an elementary level to an advanced professional level, and it tests both world knowledge and problem solving ability&rdquo;. It consists of around 16,000 multiple choice questions across 57 distinct tasks. &ldquo;These include practice questions for tests such as the Graduate Record Examination and the United States Medical Licensing Examination. It also includes questions designed for undergraduate courses and questions designed for readers of Oxford University Press books. Some tasks cover a subject, like psychology, but at a specific level of difficulty, such as &ldquo;Elementary,&rdquo; &ldquo;High School,&rdquo; &ldquo;College,&rdquo; or &ldquo;Professional&rdquo;&rdquo;, they write.GPT-3: Quite smart for a machine, quite dumb for a human: In tests, GPT3 does markedly better than other systems (even obtaining superior performance to UnifiedQA, a QA-specific system), but the results still show our systems have a long way to go before they&rsquo;re very sophisticated. &ndash; 25%: Random baseline, guessing at answer out of four.&ndash;&nbsp; 24.8%: &lsquo;T5&rsquo;, a multipurpose language model from Google.&ndash; 38.5%: &lsquo;UnifiedQA&lsquo;, a question answering AI system&ndash; 25.9%: GPT-3 small (2.7 billion parameters)&ndash; 43.9%: GPT-3 X-Large (175 billion parameters).Where language models are weak: One notable weakness in the evaluated LMs are &ldquo;STEM subjects that emphasize mathematics or calculations. We speculate that is in part because GPT-3 acquires declarative knowledge more readily than procedural knowledge,&rdquo; they write.&nbsp; Read more: Measuring Massive Multitask Language Understanding (arXiv).&nbsp; Get the benchmark here (GitHub).



###################################################Could Anduril tell us about the future of military drones?&hellip;Defense tech startup releases fourth version of its &lsquo;Ghost&rsquo; drone&hellip;Anduril, an AI-defense-tech startup co-founded by former Oculus founder Palmer Luckey, has released the &lsquo;Ghost 4&rsquo;, a military-grade drone developed in the US for the US government (and others). The Ghost 4 is a visceral example of the advancement of low-cost robotics and avionics, as well as the continued progression of AI software (both modern DL systems, and classical AI) in the domain of drone surveillance and warfare. Anduril raised $200 million earlier this summer (#205).Fully autonomous: &ldquo;Ghosts are fully autonomous,&rdquo; Andrul says in a blog post about the tech. &ldquo;Ghost is controlled entirely through the Lattice software platform and requires minimal operator training.&rdquo;Drone swarms: &ldquo;Groups of Ghosts collaborate to achieve mission objectives that are impossible to achieve via a single unit. Additionally, Ghosts communicate status data with one another and can collaborate to conduct a &ldquo;battlefield handover&rdquo; to maintain persistence target coverage.&rdquo;&nbsp; &nbsp; The Ghost 4 can be outfitted with a range of modules for tasks like SLAM (simultaneous location and mapping), electronic warfare, the addition of alternate radios, and more. Other objects can be attached to it via a gimbal, such as surveillance cameras or &ndash;…