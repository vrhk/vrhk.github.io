---

layout: post
category: product
title: "Import AI 187: Real world robot tests at CVPR; all hail the Molecule Transformer; the four traits needed for smarter AI systems."
date: 2020-03-02 16:16:40
link: https://vrhk.co/3cmIyA9
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "A somewhat short issue this week, as I&rsquo;ve been at the OECD in Paris, speaking about opportunities and challenges of AI policy, and figuring out ways for the AI Index () to support the OECD&rsquo;s new &lsquo;AI Policy Observatory&rsquo;.&nbsp;
How useful are simulators? Find out at CVPR 2020!&hellip;Three challenges will put three simulation approaches through their paces&hellip;In the past few years, researchers have started using software-based simulators to train increasingly sophisticated machine learning systems. One notable trend has been the use of high-fidelity simulators, as researchers try to train systems in these rich, visually-stimulating environments, then transfer these systems into reality. At CVPR 2020, three competitions will push the limits of different simulators, generating valuable information about how useful these tools may be. Three challenges for one big problem:RoboTHOR Challenge 2020: This challenge evaluates how good we are at developing systems that can navigate to objects specified by name (e.g., go to the table in the kitchen), using the &lsquo;Thor&rsquo; simulator (Import AI: 73). &ldquo;Participants will train their models in simulation and these models will be evaluated by the challenge organizers using a real robot in physical apartments&rdquo; (emphasis mine). Habitat Challenge 2020: This challenge has two components, a point navigation challenge, and an object navigation challenge, both set in the Habitat multi-environment simulator (Import AI 141). The point navigation one tries to deprive the system of various senses (e.g., GPS), and adds noise to its actuations, which will help us test the robustness of these navigation systems. The object navigation challenge asks an agent to find an object in the environment without access to a map.Sim2Real Challenge with Gibson: Similar to RoboTHOR, this challenge asks people to train agents to navigate through a variety of photorealistic environments using the &lsquo;Gibson&rsquo; simulator (Import AI: 111). It has three tiers of difficulty &ndash; a standard point navigation task, a point navigation task where the environment contains interactive objects, and a point navigation task where the environment contains other objects that move (and the agent must avoid colliding with them). This challenge also contains a sim2real element, where top-ranking teams (along with the top-five teams from the Habitat Challenge) will get to test out their system on a real robot as well.&nbsp; Why this matters: Let&rsquo;s put this in perspective: in 2013 the AI community was very impressed with work from DeepMind showing you could train an agent to play space invaders via reinforcement learning. Now look where we are &ndash; we&rsquo;re training systems in photorealistic 3D simulators featuring complex physical dynamics &ndash; AND we&rsquo;re going to try and boot these systems into real-world robots and test out their performance. We&rsquo;ve come a very, very long way in a relatively short period of time, and it&rsquo;s worth appreciating it. I am the frog being boiled, reflecting on the temperature of the water. It&rsquo;s getting hot, folks!&nbsp; &nbsp; Read more about the Embodied-AI Workshop here (official webpage). ####################################################Predicting molecular properties with the Molecule Transformer:&hellip;Figuring out the mysteries of chemistry with transformers, molecular self attention layers, and atom embeddings&hellip;Researchers with Ardigen; Jagiellonian University; Molecule.one; and New York University have extended the widely-used &lsquo;Transformer&rsquo; component so it can process data relating to molecule property prediction tasks &ndash; a capability critical to drug discovery and material design. The resulting Molecule Attention Transformer (MAT) performs well across a range of tasks, ranging from predicting ability of molecule to penetrate blood-brain barrier, to predicting whether a compound is active towards a given target (e.g., Estrogen Alpha, Estrogen Beta), and so on. Transformers for Molecules: To get Transformers to process molecule data, the researchers implement what they call &ldquo;Molecular Self Attention Layers&rdquo;, and each atom is embedded as a 26-dimensional vector.How well does MAT stack up? They compare the MAT to three baselines: random forest (RF); Support Vector Machine with RBF kernel (SVM); and graph convolutional networks (GCN)s. The MAT gets state-of-the-art scores on four out of the seven tests (RF and SVM take the other one and two, respectively).  &nbsp; MAT pre-training: Just like with image and text models, molecular models can benefit from being pre-trained on a (relevant) dataset and fine-tuned from there. They compare their system against a Pretrained EAGCN, and SMILES, where MAT with pre-training gets significantly improved scores. Why this matters: Molecular property prediction is the sort of task where if we&rsquo;re able to develop AI systems that make meaningful, accurate predictions, then we can expect large chunks of the economy to change as a consequence. Papers like this highlight how generically useful components like the Transformer are, and highlights how much modern AI has in common with plumbing &ndash; here, the researchers are basically trying to design an interface system that lets them port molecular data into a Transformer-based system, and vice versa.  &nbsp; Read more: Molecule Attention Transformer (arXiv). ####################################################Deepfakes are being commoditized &ndash; uh oh!&hellip;What happens when Deepfakes get really cheap?&hellip;Deepfakes &ndash; the slang term for AI systems that let you create synthetic videos where you superimpose someone&rsquo;s face onto someone else&rsquo;s &ndash; are becoming easier and cheaper to make, though they&rsquo;re primarily being used for pornography rather than political disruption, according to a new analysis from Deeptracelabs and Nisos.&nbsp; Porn, porn, porn: &ldquo;We found that the majority of deepfake activity centers on dedicated deepfake pornography platforms,&rdquo; they write. &ldquo;These videos consistently attract millions of views, with some of the websites featuring polls where users can vote for who they want to see targeted next&rdquo;. Little (non-porn) misuse: &ldquo;We assess that deepfakes are not being widely bought or sold for criminal or disinformation purposes as of early February 2020,&rdquo; they write. &ldquo;Techniques being developed by academic and industry leaders have arguably reached the required quality for criminal uses, but these techniques are not currently publicly accessible and will take time to be translated into stable, user-friendly implementations&rdquo;. Why this matters: This research highlights how AI tools are diffusing into society, with some of them being misused. I think the most significant (implicit) thing here is the importance this places on publication norms in AI research &ndash; what kind of responsibility might academics and corporate researchers have here, with regard to proliferating the technology? And can we do anything to reduce misuses of the technology while maintaining a relatively open scientific culture? &ldquo;We anticipate that as deepfakes reach higher quality and &ldquo;believability&rdquo;, coupled with advancing technology proliferation, they will increasingly be used for criminal purposes&rdquo;, they write. Get ready.  &nbsp; Read more: Analyzing The Commoditization Of Deepfakes (NYU Journal of Legislation &amp; Public Policy).&nbsp;
####################################################What stands between us and smarter AI? &hellip;Four traits we need to build to develop more powerful AI systems&hellip;Cognitive scientist and entrepreneur Gary Marcus has published a paper describing an alternative to the dominant contemporary approach to AI research. Where existing systems focus on &ldquo;general-purpose learning and eve…"

---

### Import AI 187: Real world robot tests at CVPR; all hail the Molecule Transformer; the four traits needed for smarter AI systems.

A somewhat short issue this week, as I&rsquo;ve been at the OECD in Paris, speaking about opportunities and challenges of AI policy, and figuring out ways for the AI Index () to support the OECD&rsquo;s new &lsquo;AI Policy Observatory&rsquo;.&nbsp;
How useful are simulators? Find out at CVPR 2020!&hellip;Three challenges will put three simulation approaches through their paces&hellip;In the past few years, researchers have started using software-based simulators to train increasingly sophisticated machine learning systems. One notable trend has been the use of high-fidelity simulators, as researchers try to train systems in these rich, visually-stimulating environments, then transfer these systems into reality. At CVPR 2020, three competitions will push the limits of different simulators, generating valuable information about how useful these tools may be. Three challenges for one big problem:RoboTHOR Challenge 2020: This challenge evaluates how good we are at developing systems that can navigate to objects specified by name (e.g., go to the table in the kitchen), using the &lsquo;Thor&rsquo; simulator (Import AI: 73). &ldquo;Participants will train their models in simulation and these models will be evaluated by the challenge organizers using a real robot in physical apartments&rdquo; (emphasis mine). Habitat Challenge 2020: This challenge has two components, a point navigation challenge, and an object navigation challenge, both set in the Habitat multi-environment simulator (Import AI 141). The point navigation one tries to deprive the system of various senses (e.g., GPS), and adds noise to its actuations, which will help us test the robustness of these navigation systems. The object navigation challenge asks an agent to find an object in the environment without access to a map.Sim2Real Challenge with Gibson: Similar to RoboTHOR, this challenge asks people to train agents to navigate through a variety of photorealistic environments using the &lsquo;Gibson&rsquo; simulator (Import AI: 111). It has three tiers of difficulty &ndash; a standard point navigation task, a point navigation task where the environment contains interactive objects, and a point navigation task where the environment contains other objects that move (and the agent must avoid colliding with them). This challenge also contains a sim2real element, where top-ranking teams (along with the top-five teams from the Habitat Challenge) will get to test out their system on a real robot as well.&nbsp; Why this matters: Let&rsquo;s put this in perspective: in 2013 the AI community was very impressed with work from DeepMind showing you could train an agent to play space invaders via reinforcement learning. Now look where we are &ndash; we&rsquo;re training systems in photorealistic 3D simulators featuring complex physical dynamics &ndash; AND we&rsquo;re going to try and boot these systems into real-world robots and test out their performance. We&rsquo;ve come a very, very long way in a relatively short period of time, and it&rsquo;s worth appreciating it. I am the frog being boiled, reflecting on the temperature of the water. It&rsquo;s getting hot, folks!&nbsp; &nbsp; Read more about the Embodied-AI Workshop here (official webpage). ####################################################Predicting molecular properties with the Molecule Transformer:&hellip;Figuring out the mysteries of chemistry with transformers, molecular self attention layers, and atom embeddings&hellip;Researchers with Ardigen; Jagiellonian University; Molecule.one; and New York University have extended the widely-used &lsquo;Transformer&rsquo; component so it can process data relating to molecule property prediction tasks &ndash; a capability critical to drug discovery and material design. The resulting Molecule Attention Transformer (MAT) performs well across a range of tasks, ranging from predicting ability of molecule to penetrate blood-brain barrier, to predicting whether a compound is active towards a given target (e.g., Estrogen Alpha, Estrogen Beta), and so on. Transformers for Molecules: To get Transformers to process molecule data, the researchers implement what they call &ldquo;Molecular Self Attention Layers&rdquo;, and each atom is embedded as a 26-dimensional vector.How well does MAT stack up? They compare the MAT to three baselines: random forest (RF); Support Vector Machine with RBF kernel (SVM); and graph convolutional networks (GCN)s. The MAT gets state-of-the-art scores on four out of the seven tests (RF and SVM take the other one and two, respectively).  &nbsp; MAT pre-training: Just like with image and text models, molecular models can benefit from being pre-trained on a (relevant) dataset and fine-tuned from there. They compare their system against a Pretrained EAGCN, and SMILES, where MAT with pre-training gets significantly improved scores. Why this matters: Molecular property prediction is the sort of task where if we&rsquo;re able to develop AI systems that make meaningful, accurate predictions, then we can expect large chunks of the economy to change as a consequence. Papers like this highlight how generically useful components like the Transformer are, and highlights how much modern AI has in common with plumbing &ndash; here, the researchers are basically trying to design an interface system that lets them port molecular data into a Transformer-based system, and vice versa.  &nbsp; Read more: Molecule Attention Transformer (arXiv). ####################################################Deepfakes are being commoditized &ndash; uh oh!&hellip;What happens when Deepfakes get really cheap?&hellip;Deepfakes &ndash; the slang term for AI systems that let you create synthetic videos where you superimpose someone&rsquo;s face onto someone else&rsquo;s &ndash; are becoming easier and cheaper to make, though they&rsquo;re primarily being used for pornography rather than political disruption, according to a new analysis from Deeptracelabs and Nisos.&nbsp; Porn, porn, porn: &ldquo;We found that the majority of deepfake activity centers on dedicated deepfake pornography platforms,&rdquo; they write. &ldquo;These videos consistently attract millions of views, with some of the websites featuring polls where users can vote for who they want to see targeted next&rdquo;. Little (non-porn) misuse: &ldquo;We assess that deepfakes are not being widely bought or sold for criminal or disinformation purposes as of early February 2020,&rdquo; they write. &ldquo;Techniques being developed by academic and industry leaders have arguably reached the required quality for criminal uses, but these techniques are not currently publicly accessible and will take time to be translated into stable, user-friendly implementations&rdquo;. Why this matters: This research highlights how AI tools are diffusing into society, with some of them being misused. I think the most significant (implicit) thing here is the importance this places on publication norms in AI research &ndash; what kind of responsibility might academics and corporate researchers have here, with regard to proliferating the technology? And can we do anything to reduce misuses of the technology while maintaining a relatively open scientific culture? &ldquo;We anticipate that as deepfakes reach higher quality and &ldquo;believability&rdquo;, coupled with advancing technology proliferation, they will increasingly be used for criminal purposes&rdquo;, they write. Get ready.  &nbsp; Read more: Analyzing The Commoditization Of Deepfakes (NYU Journal of Legislation &amp; Public Policy).&nbsp;
####################################################What stands between us and smarter AI? &hellip;Four traits we need to build to develop more powerful AI systems&hellip;Cognitive scientist and entrepreneur Gary Marcus has published a paper describing an alternative to the dominant contemporary approach to AI research. Where existing systems focus on &ldquo;general-purpose learning and eve…