---

layout: post
category: product
title: "Import AI 179: Explore Arabic text with BERT-based AraNet; get ready for the teenage-made deepfakes; plus DeepMind AI makes doctors more effective"
date: 2020-01-06 16:46:45
link: https://vrhk.co/36FVi1m
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Explore Arabic-language with AraNet:&hellip;Making culture legible with pre-trained BERT models&hellip;University of British Columbia researchers have developed AraNet, software to help people analyze Arabic-language text for identifiers like age, gender, dialect, emotion, irony and sentiment. Tools like AraNet help make cultural outputs (e.g., tweets) legible to large-scale machine learning systems and thereby help broaden cultural representation within the datasets and classifiers used in AI research. What does AraNet contain? AraNet is essentially a set of pre-trained models, along with software for using AraNet via the command line or as a specific python package. The models have typically been fine-tuned from Google&rsquo;s &ldquo;BERT-Base Multilingual Case&rdquo; model which was pre-trained on 104 languages. AraNet includes the following models:
Age &amp; Gender: Arab-Tweet, a dataset of tweets from different users of 17 Arabic countries, annotated with gender and age labels. UBC Twitter Gender dataset, an in-house dataset with gender labels applied to 1,989 users from 21 Arab countries.
Dialect identification: It uses a previously developed dialect-identification model for the &lsquo;MADAR&rsquo; Arabic Fine-Grained Dialect Identification.
Emotion: LAMA-DINA dataset where each tweet is labelled with one of eight primary emotions, with a mixture of human- and machine-generated labels.&nbsp;
Irony: A dataset drawn from the IDAT@FIRE2019 competition, which contains 5,000 tweets related to events taking place in the Middle East between 2011 and 2018, labeled according to whether the tweets are ironic or non-ironic.&nbsp;
Sentiment: 15 datasets relating to sentiment analysis, which are edited and combined together (with labels normalized to positive or negative, and excluding &lsquo;neutral&rsquo; or otherwise-labeled samples).
Why this matters: AI tools let us navigate digitized cultures &ndash; once we have (vaguely reliable) models we can start to search over large bodies of cultural information for abstract things, like the presence of a specific emotion, or the use of irony. I think tools like AraNet are going to eventually give scholars with expert intuition (e.g., experts on, say, Arabic blogging during the Arab Spring) tools to extend their own research, generating new insights via AI. What are we going to learn about ourselves along the way, I wonder? &nbsp; Read more: AraNet: A Deep Learning Toolkit for Arabic Social Media (Arxiv).&nbsp;&nbsp;&nbsp;Get the code here (UBC-NLP GitHub) &ndash; note, when I wrote this section on Saturday the 4th the GitHub repo wasn&rsquo;t yet online; I emailed the authors to let them know.&nbsp;
####################################################Deep learning isn&rsquo;t all about terminators and drones &ndash; Chinese researchers make a butterfly detector!&hellip;Take a break from all the crazy impacts of AI and think about this comparatively pleasant research&hellip;I spend a lot of time in this newsletter writing about surveillance technology, drone/robot movement systems, and other symptoms of the geopolitical changes brought about by AI. So sometimes it&rsquo;s nice to step back and relax with a paper about something quite nice: butterfly identification! Here, researchers with Beijing Jiaotong University publish a simple, short paper on using YOLOv3 for butterfly identification. Make your own butterfly detector: The paper gives us a sense of how (relatively) easy it is to create high-performance object detectors for specific types of imagery.&nbsp;
Gather data: In this case, they label around ~1,000 photos of butterflies using data from the 3rd China Data Mining Competition butterfly recognition contest as well as images generated by searching for specific types of butterflies on the Baidu search engine.&nbsp;
Train and run models: Train multiple YOLO v3 models with different image sizes as input data, then combine results from multiple models to make a prediction.&nbsp;
Obtain a system that gets around 98% accuracy on locating butterflies in photos, with lower accuracies for species and subject identification.&nbsp;
Why this matters: Deep learning technologies let us automate some (basic) human sensory capabilities, like certain vision or audio identification tasks. The 2020s will be the decade of personalized AI, in which we&rsquo;ll see it become increasingly easy for people to gather small datasets and train their own classifiers. I can&rsquo;t wait to see what people come up with!&nbsp;&nbsp;&nbsp;Read more: Butterfly detection and classification based on integrated YOLO algorithm (Arxiv).&nbsp;
####################################################
Prepare yourself for watching your teenage kid make deepfakes:&hellip;First, deepfakes industrialized. Now, they&rsquo;re being consumerized&hellip;Tik Tok &amp; Douyin: Bytedance, the Chinese company behind smash hit app TikTok, is making it easier for people to make synthetic videos of themselves. The company recently added code for a &lsquo;Face Swap&rsquo; feature to the latest versions of its TikTok and Douyin Android apps, according to TechCrunch. This unreleased technology would, according to unpublished application notes, let a user take a detailed series of photos of their face, then they can easily morph their face to match a target video, like pasting themselves into scenes from the Titanic or reality TV.&nbsp;&nbsp;&nbsp;However, the feature may only come to the Chinese-version of the app (Douyin): &ldquo;After checking with the teams I can confirm this is definitely not a function in TikTok, nor do we have any intention of introducing it. I think what you may be looking at is something slated for Douyin &ndash; your email includes screenshots that would be from Douyin, and a privacy policy that mentions Douyin. That said, we don&rsquo;t work on Douyin here at TikTok&rdquo;, a TikTok spokesperson told TechCrunch. &ldquo;They later told TechCrunch that &ldquo;The inactive code fragments are being removed to eliminate any confusion,&rdquo; which implicitly confirms that Face Swap code was found in TikTok.&rdquo;
Snapchat: Separately, Snapchat has acquired AI Factory, a company that had been developing AI tech to let a user take a selfie and paste and animate that selfie into another video, according to TechCrunch &ndash; this technology isn&rsquo;t quite as amenable to making deepfakes out of the box as the potential Tik Tok &amp; Douyin ones, but gives us a sense of the direction Snap is headed in.
Why this matters: For the past half decade, AI technologies for generating synthetic images and video have been improving. So far, many of the abuses of the technology have either occurred abroad (see: mysoginistic disinformation in India, alleged propaganda in Gabon), or in pornography. Politicians have become worried that they&rsquo;ll be the next targets. No one is quite sure how to approach the challenge of the threats of deepfakes, but people tend to think awareness might help &ndash; if people start to see loads of deepfakes around them on their social media websites, they might become a bit more skeptical of deepfakes they see in the wild. If face swap technology comes to TikTok or Douyin soon, then we&rsquo;ll see how this alters awareness of the technology. If it doesn&rsquo;t arrive in these apps soon, then we can assume it&rsquo;ll show up somewhere else, as a less scrupulous developer rolls out the technology. (A year and a half ago I told a journalist I thought the arrival of deepfake-making meme kids could precede further malicious use of the technology.)&nbsp;&nbsp;&nbsp;Read more: ByteDance &amp; TikTok have secretly built a deepfakes maker (TechCrunch).
####################################################
Play AI Dungeon on your&hellip; Alexa?&hellip;GPT-2-based dungeon crawler gets a voice mode&hellip;Have you ever wanted to yell commands at a smart speaker like &ldquo;travel back in time&rdquo;, &ldquo;melt the cave&rdquo;, an…"

---

### Import AI 179: Explore Arabic text with BERT-based AraNet; get ready for the teenage-made deepfakes; plus DeepMind AI makes doctors more effective

Explore Arabic-language with AraNet:&hellip;Making culture legible with pre-trained BERT models&hellip;University of British Columbia researchers have developed AraNet, software to help people analyze Arabic-language text for identifiers like age, gender, dialect, emotion, irony and sentiment. Tools like AraNet help make cultural outputs (e.g., tweets) legible to large-scale machine learning systems and thereby help broaden cultural representation within the datasets and classifiers used in AI research. What does AraNet contain? AraNet is essentially a set of pre-trained models, along with software for using AraNet via the command line or as a specific python package. The models have typically been fine-tuned from Google&rsquo;s &ldquo;BERT-Base Multilingual Case&rdquo; model which was pre-trained on 104 languages. AraNet includes the following models:
Age &amp; Gender: Arab-Tweet, a dataset of tweets from different users of 17 Arabic countries, annotated with gender and age labels. UBC Twitter Gender dataset, an in-house dataset with gender labels applied to 1,989 users from 21 Arab countries.
Dialect identification: It uses a previously developed dialect-identification model for the &lsquo;MADAR&rsquo; Arabic Fine-Grained Dialect Identification.
Emotion: LAMA-DINA dataset where each tweet is labelled with one of eight primary emotions, with a mixture of human- and machine-generated labels.&nbsp;
Irony: A dataset drawn from the IDAT@FIRE2019 competition, which contains 5,000 tweets related to events taking place in the Middle East between 2011 and 2018, labeled according to whether the tweets are ironic or non-ironic.&nbsp;
Sentiment: 15 datasets relating to sentiment analysis, which are edited and combined together (with labels normalized to positive or negative, and excluding &lsquo;neutral&rsquo; or otherwise-labeled samples).
Why this matters: AI tools let us navigate digitized cultures &ndash; once we have (vaguely reliable) models we can start to search over large bodies of cultural information for abstract things, like the presence of a specific emotion, or the use of irony. I think tools like AraNet are going to eventually give scholars with expert intuition (e.g., experts on, say, Arabic blogging during the Arab Spring) tools to extend their own research, generating new insights via AI. What are we going to learn about ourselves along the way, I wonder? &nbsp; Read more: AraNet: A Deep Learning Toolkit for Arabic Social Media (Arxiv).&nbsp;&nbsp;&nbsp;Get the code here (UBC-NLP GitHub) &ndash; note, when I wrote this section on Saturday the 4th the GitHub repo wasn&rsquo;t yet online; I emailed the authors to let them know.&nbsp;
####################################################Deep learning isn&rsquo;t all about terminators and drones &ndash; Chinese researchers make a butterfly detector!&hellip;Take a break from all the crazy impacts of AI and think about this comparatively pleasant research&hellip;I spend a lot of time in this newsletter writing about surveillance technology, drone/robot movement systems, and other symptoms of the geopolitical changes brought about by AI. So sometimes it&rsquo;s nice to step back and relax with a paper about something quite nice: butterfly identification! Here, researchers with Beijing Jiaotong University publish a simple, short paper on using YOLOv3 for butterfly identification. Make your own butterfly detector: The paper gives us a sense of how (relatively) easy it is to create high-performance object detectors for specific types of imagery.&nbsp;
Gather data: In this case, they label around ~1,000 photos of butterflies using data from the 3rd China Data Mining Competition butterfly recognition contest as well as images generated by searching for specific types of butterflies on the Baidu search engine.&nbsp;
Train and run models: Train multiple YOLO v3 models with different image sizes as input data, then combine results from multiple models to make a prediction.&nbsp;
Obtain a system that gets around 98% accuracy on locating butterflies in photos, with lower accuracies for species and subject identification.&nbsp;
Why this matters: Deep learning technologies let us automate some (basic) human sensory capabilities, like certain vision or audio identification tasks. The 2020s will be the decade of personalized AI, in which we&rsquo;ll see it become increasingly easy for people to gather small datasets and train their own classifiers. I can&rsquo;t wait to see what people come up with!&nbsp;&nbsp;&nbsp;Read more: Butterfly detection and classification based on integrated YOLO algorithm (Arxiv).&nbsp;
####################################################
Prepare yourself for watching your teenage kid make deepfakes:&hellip;First, deepfakes industrialized. Now, they&rsquo;re being consumerized&hellip;Tik Tok &amp; Douyin: Bytedance, the Chinese company behind smash hit app TikTok, is making it easier for people to make synthetic videos of themselves. The company recently added code for a &lsquo;Face Swap&rsquo; feature to the latest versions of its TikTok and Douyin Android apps, according to TechCrunch. This unreleased technology would, according to unpublished application notes, let a user take a detailed series of photos of their face, then they can easily morph their face to match a target video, like pasting themselves into scenes from the Titanic or reality TV.&nbsp;&nbsp;&nbsp;However, the feature may only come to the Chinese-version of the app (Douyin): &ldquo;After checking with the teams I can confirm this is definitely not a function in TikTok, nor do we have any intention of introducing it. I think what you may be looking at is something slated for Douyin &ndash; your email includes screenshots that would be from Douyin, and a privacy policy that mentions Douyin. That said, we don&rsquo;t work on Douyin here at TikTok&rdquo;, a TikTok spokesperson told TechCrunch. &ldquo;They later told TechCrunch that &ldquo;The inactive code fragments are being removed to eliminate any confusion,&rdquo; which implicitly confirms that Face Swap code was found in TikTok.&rdquo;
Snapchat: Separately, Snapchat has acquired AI Factory, a company that had been developing AI tech to let a user take a selfie and paste and animate that selfie into another video, according to TechCrunch &ndash; this technology isn&rsquo;t quite as amenable to making deepfakes out of the box as the potential Tik Tok &amp; Douyin ones, but gives us a sense of the direction Snap is headed in.
Why this matters: For the past half decade, AI technologies for generating synthetic images and video have been improving. So far, many of the abuses of the technology have either occurred abroad (see: mysoginistic disinformation in India, alleged propaganda in Gabon), or in pornography. Politicians have become worried that they&rsquo;ll be the next targets. No one is quite sure how to approach the challenge of the threats of deepfakes, but people tend to think awareness might help &ndash; if people start to see loads of deepfakes around them on their social media websites, they might become a bit more skeptical of deepfakes they see in the wild. If face swap technology comes to TikTok or Douyin soon, then we&rsquo;ll see how this alters awareness of the technology. If it doesn&rsquo;t arrive in these apps soon, then we can assume it&rsquo;ll show up somewhere else, as a less scrupulous developer rolls out the technology. (A year and a half ago I told a journalist I thought the arrival of deepfake-making meme kids could precede further malicious use of the technology.)&nbsp;&nbsp;&nbsp;Read more: ByteDance &amp; TikTok have secretly built a deepfakes maker (TechCrunch).
####################################################
Play AI Dungeon on your&hellip; Alexa?&hellip;GPT-2-based dungeon crawler gets a voice mode&hellip;Have you ever wanted to yell commands at a smart speaker like &ldquo;travel back in time&rdquo;, &ldquo;melt the cave&rdquo;, an…