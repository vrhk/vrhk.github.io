---

layout: post
category: product
title: "Import AI 189: Can your AI beat a 0% baseline?; AlphaFold predicts COVID-19 properties; plus, gigapixel-scale surveillance"
date: 2020-03-17 20:36:44
link: https://vrhk.co/2Wolo6S
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Salesforce gets a language model to generate protein sequences:&hellip;Can a language model become a scientist? Salesforce thinks so&hellip;In recent years, language models have got a lot better. Specifically, AI researchers have figured out how to train large, generative models over strings of data, and have started producing models that can generate reasonable things on the other side &ndash; code, theatrical plays, poems, and so on. Now, scientists have been applying similar techniques to seeing if they can train models to figure out other, complex distributions of data that can be modelled as a string of characters. To that end, researchers with Salesforce and the Department of Bioengineering at Stanford University have developed ProGen, a neural net, that can collectly predict and generate protein sequences. What is ProGen? ProGen is a 1.2 billion parameter language model, trained on a dataset of 280 million protein sequences. ProGen is based on a Transformer model, with a couple of tweaks to help encode protein data. &nbsp; ProGen works somewhat like how a language model completes a sentence, where it generates successive words, adjusting as it goes until it reaches the end of the sequence. &ldquo;ProGen takes a context sequence of amino acids as input and outputs a probability distribution over amino acids,&rdquo; they write. &ldquo;We sample from that distribution and then update the context sequence with the sample amino acid&rdquo;. How well does ProGen work? In tests, the researchers see if ProGen can successfully generate proteins that have a similar structure to real proteins &ndash; it works reasonably well: &ldquo;across differing generation lengths, ProGen generation quality remains steadily near native low-energy levels, indicating a successful generation,&rdquo; Salesforce writes in a blog post about the work. ProGen also displays some of the same helpful traits as language models, in the sense that it can be finetuned to improve performance on novel data, and it exhibits some amount of generalization. Why this matters: Research like this gives us a sense of how scientists might repurpose AI tools developed for various purposes (e.g., language modeling) and apply them to other scientific domains. I think if we see more of this it&rsquo;ll add weight to the idea that AI tools are going to generically help with a range of scientific challenges.  &nbsp; Read more: ProGen: Language Modeling for Protein Generation (bioRxiv).  &nbsp; Read more: ProGen: Using AI to Generate Proteins (Salesforce Einstein AI blog).
####################################################Coming soon: gigapixel-scale surveillance:&hellip;PANDA dataset helps train systems to surveil thousands of people at once&hellip; In the future, massive cameras will capture panoramic views of crowds running marathons, or attending music festivals, or convening in the center of a town, and governments and the private sector will deploy sophisticated surveillance AI systems against this footage. A new research paper from Tsinghua University and Duke University, gives us a a gigapixel photo dataset called PANDA to help people conduct research into large-scale surveillance. What goes into a PANDA: PANDA is made of 21 real-world scenes, where each scene consists of around 2 hours of 30Hz video, with still images extracted from this. The resolution of each PANDA picture is 25,000*14,000 pixels &ndash; that&rsquo;s huge, considering many image datasets have standardized on 512*512 pixels &ndash; about 25 times small, at least. Acronym police, I&rsquo;d like to report a murder: Panda is short for gigaPixel-level humAN-centric viDeo dAtaset. Yup.Two PANDA variants: PANDA, which has 555 images with an average density of ~200 people per image, and PANDA-Crowd (known as PANDA-C) has 45 images and an average density of ~2,700 people per image. PANDA also includes some interesting labels, ranging from classifications of behavior (walking / standing / holding / riding / sitting), to labels on groups of people (e.g., a lone individual might be tagged &lsquo;single&rsquo;, while a couple of friends could be tagged as &lsquo;acquaintance&rsquo; and a mother and son might be tagged &lsquo;family&rsquo;). &nbsp; Video PANDA: PANDA also ships with a video version of the dataset, so researchers can train AI systems to track a given person (or object) in a video soon. Because PANDA has a massive field-of-view, it presents a greater challenge than prior datasets used for this sort of thing. Why this matters: A few years ago, AI systems needed to be plugged into massively complex data pipelines that would automatically crop, tweak, and render images in ways that could be analyzed by AI systems. Now, we&rsquo;re experimenting with systems for doing unconstrained surveillance over really large moving datasets, and testing out approaches that can do image recognition across thousands of faces at once. This stuff is getting more powerful more quickly than people realize, and I think the implications for how states relate to (and seek to control) their citizens are likely to be profound.  &nbsp; Read more: PANDA: A Gigapixel-level Human-centric Video Dataset (arXiv). &nbsp; Get the dataset from the official website (PANDA dataset). ####################################################Want to keep up to date with AI Ethics? Subscribe to this newsletter:The Montreal AI Ethics Institute (MAIEI) has launched a newsletter to help people understand the world of AI Ethics. Like Import AI, the MAIEI newsletter provides analysis of research papers. Some of the research covered in the first issue includes: Papers that try and bridge short-term and long-term AI ethics concerns, analyses of algorithmic injustices, and studies that analyze how people who spread misinformation acquire influence online.  &nbsp; Read more: AI Ethics #1: Hello World! Relational ethics, misinformation, animism and more&hellip; (Montreal AI Ethics Institute substack). ####################################################DeepMind uses AlphaFold system to make (informed) guesses about COVID-19:&hellip;Another episode of &ldquo;function approximation can get you surprisingly far&rdquo;&hellip;Here&rsquo;s one of the AI futures I&rsquo;ve always wanted: a crisis appears and giant computers whirr into action in response, performing inferences and eventually dispensing scraps of computationally-gleaned insight that can help humans tackle the crisis. The nice thing is this is now happening via some work from DeepMind, which has published predictions from its AlphaFold system about the structures of several under-studied proteins linked to the SARS-CoV-2 virus.What it did: DeepMind generated predictions about the structure of things linked to the virus. These structures &ndash; which are predictions, and haven&rsquo;t been validated &ndash; can serve as clues for scientists trying to test out different hypotheses about how the virus functions. DeepMind says &ldquo;these structure predictions have not been experimentally verified, but hope they may contribute to the scientific community&rsquo;s interrogation of how the virus functions, and serve as a hypothesis generation platform for future experimental work in developing therapeutics.&rdquo; The company has also shared its results with collaborators at Francis Crick Institute in the UK, who encouraged it to publish the predictions.Why this matters: The story of computation has been the story of arbitraging electricity and time for increasingly sophisticated actions and insights. It&rsquo;s amazing to me that we&rsquo;re now able to use neural nets to approximate certain functions, which let us spend some money and time to get computers to generate insights that can equip human scientists. Centaur science! &nbsp; Read more: Computational predictions of protein structures associated with COVID-19 (Google DeepMind). ####################################################Take the pain out of medical machin…"

---

### Import AI 189: Can your AI beat a 0% baseline?; AlphaFold predicts COVID-19 properties; plus, gigapixel-scale surveillance

Salesforce gets a language model to generate protein sequences:&hellip;Can a language model become a scientist? Salesforce thinks so&hellip;In recent years, language models have got a lot better. Specifically, AI researchers have figured out how to train large, generative models over strings of data, and have started producing models that can generate reasonable things on the other side &ndash; code, theatrical plays, poems, and so on. Now, scientists have been applying similar techniques to seeing if they can train models to figure out other, complex distributions of data that can be modelled as a string of characters. To that end, researchers with Salesforce and the Department of Bioengineering at Stanford University have developed ProGen, a neural net, that can collectly predict and generate protein sequences. What is ProGen? ProGen is a 1.2 billion parameter language model, trained on a dataset of 280 million protein sequences. ProGen is based on a Transformer model, with a couple of tweaks to help encode protein data. &nbsp; ProGen works somewhat like how a language model completes a sentence, where it generates successive words, adjusting as it goes until it reaches the end of the sequence. &ldquo;ProGen takes a context sequence of amino acids as input and outputs a probability distribution over amino acids,&rdquo; they write. &ldquo;We sample from that distribution and then update the context sequence with the sample amino acid&rdquo;. How well does ProGen work? In tests, the researchers see if ProGen can successfully generate proteins that have a similar structure to real proteins &ndash; it works reasonably well: &ldquo;across differing generation lengths, ProGen generation quality remains steadily near native low-energy levels, indicating a successful generation,&rdquo; Salesforce writes in a blog post about the work. ProGen also displays some of the same helpful traits as language models, in the sense that it can be finetuned to improve performance on novel data, and it exhibits some amount of generalization. Why this matters: Research like this gives us a sense of how scientists might repurpose AI tools developed for various purposes (e.g., language modeling) and apply them to other scientific domains. I think if we see more of this it&rsquo;ll add weight to the idea that AI tools are going to generically help with a range of scientific challenges.  &nbsp; Read more: ProGen: Language Modeling for Protein Generation (bioRxiv).  &nbsp; Read more: ProGen: Using AI to Generate Proteins (Salesforce Einstein AI blog).
####################################################Coming soon: gigapixel-scale surveillance:&hellip;PANDA dataset helps train systems to surveil thousands of people at once&hellip; In the future, massive cameras will capture panoramic views of crowds running marathons, or attending music festivals, or convening in the center of a town, and governments and the private sector will deploy sophisticated surveillance AI systems against this footage. A new research paper from Tsinghua University and Duke University, gives us a a gigapixel photo dataset called PANDA to help people conduct research into large-scale surveillance. What goes into a PANDA: PANDA is made of 21 real-world scenes, where each scene consists of around 2 hours of 30Hz video, with still images extracted from this. The resolution of each PANDA picture is 25,000*14,000 pixels &ndash; that&rsquo;s huge, considering many image datasets have standardized on 512*512 pixels &ndash; about 25 times small, at least. Acronym police, I&rsquo;d like to report a murder: Panda is short for gigaPixel-level humAN-centric viDeo dAtaset. Yup.Two PANDA variants: PANDA, which has 555 images with an average density of ~200 people per image, and PANDA-Crowd (known as PANDA-C) has 45 images and an average density of ~2,700 people per image. PANDA also includes some interesting labels, ranging from classifications of behavior (walking / standing / holding / riding / sitting), to labels on groups of people (e.g., a lone individual might be tagged &lsquo;single&rsquo;, while a couple of friends could be tagged as &lsquo;acquaintance&rsquo; and a mother and son might be tagged &lsquo;family&rsquo;). &nbsp; Video PANDA: PANDA also ships with a video version of the dataset, so researchers can train AI systems to track a given person (or object) in a video soon. Because PANDA has a massive field-of-view, it presents a greater challenge than prior datasets used for this sort of thing. Why this matters: A few years ago, AI systems needed to be plugged into massively complex data pipelines that would automatically crop, tweak, and render images in ways that could be analyzed by AI systems. Now, we&rsquo;re experimenting with systems for doing unconstrained surveillance over really large moving datasets, and testing out approaches that can do image recognition across thousands of faces at once. This stuff is getting more powerful more quickly than people realize, and I think the implications for how states relate to (and seek to control) their citizens are likely to be profound.  &nbsp; Read more: PANDA: A Gigapixel-level Human-centric Video Dataset (arXiv). &nbsp; Get the dataset from the official website (PANDA dataset). ####################################################Want to keep up to date with AI Ethics? Subscribe to this newsletter:The Montreal AI Ethics Institute (MAIEI) has launched a newsletter to help people understand the world of AI Ethics. Like Import AI, the MAIEI newsletter provides analysis of research papers. Some of the research covered in the first issue includes: Papers that try and bridge short-term and long-term AI ethics concerns, analyses of algorithmic injustices, and studies that analyze how people who spread misinformation acquire influence online.  &nbsp; Read more: AI Ethics #1: Hello World! Relational ethics, misinformation, animism and more&hellip; (Montreal AI Ethics Institute substack). ####################################################DeepMind uses AlphaFold system to make (informed) guesses about COVID-19:&hellip;Another episode of &ldquo;function approximation can get you surprisingly far&rdquo;&hellip;Here&rsquo;s one of the AI futures I&rsquo;ve always wanted: a crisis appears and giant computers whirr into action in response, performing inferences and eventually dispensing scraps of computationally-gleaned insight that can help humans tackle the crisis. The nice thing is this is now happening via some work from DeepMind, which has published predictions from its AlphaFold system about the structures of several under-studied proteins linked to the SARS-CoV-2 virus.What it did: DeepMind generated predictions about the structure of things linked to the virus. These structures &ndash; which are predictions, and haven&rsquo;t been validated &ndash; can serve as clues for scientists trying to test out different hypotheses about how the virus functions. DeepMind says &ldquo;these structure predictions have not been experimentally verified, but hope they may contribute to the scientific community&rsquo;s interrogation of how the virus functions, and serve as a hypothesis generation platform for future experimental work in developing therapeutics.&rdquo; The company has also shared its results with collaborators at Francis Crick Institute in the UK, who encouraged it to publish the predictions.Why this matters: The story of computation has been the story of arbitraging electricity and time for increasingly sophisticated actions and insights. It&rsquo;s amazing to me that we&rsquo;re now able to use neural nets to approximate certain functions, which let us spend some money and time to get computers to generate insights that can equip human scientists. Centaur science! &nbsp; Read more: Computational predictions of protein structures associated with COVID-19 (Google DeepMind). ####################################################Take the pain out of medical machin…