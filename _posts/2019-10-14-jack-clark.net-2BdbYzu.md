---

layout: post
category: product
title: "Import AI 168: The self-learning warehouse; a sub-$225 homebrew drone; and training card-playing AIs with RLCard "
date: 2019-10-14 16:31:33
link: https://vrhk.co/2BdbYzu
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Why the warehouse of the future will learn about itself:&hellip;Your next product could be delivered via Deep Manufacturing Dispatching (DMD)&hellip;How can we make manufacturing facilities more efficient? One approach is to try to make them more efficient. One way to make things more efficient is &ndash; sometimes &ndash; to make them more intelligent. That&rsquo;s what researchers at Hitachi America Ltd are trying to do with a new research paper where they improve dispatching systems in (simulated) warehouses via the use of AI. They call their resulting approach &ldquo;Deep Manufacturing Dispatching (DMD)&rdquo;, which I find oddly charming.&nbsp;
How DMD works: The DMD works like this &ndash; the researchers turn the state of the shop floor into a 2D matrix, incorporate various bits of state from the environment, then design reward systems which favor the on-time delivery of items.&nbsp;
Does any of this work? Yes, in simulation: They compare DND with seven other dispatching algorithms, ranging from carefully designed rule-based systems, to ones that use machine learning and reinforcement learning. They perform these comparisons in a variety of circumstances, assessing how well DMD can satisfy different constraints &ndash; here, lateness and tardiness. &ldquo;Overall, for 19 settings, DMD gets best results for 18 settings on total discounted reward and 16 settings on average lateness and tardiness.&rdquo; In tests, DMD beats out other systems by wide margins of success.
Why this matters: As the economy becomes increasingly digitized, we can expect some subset of the physical goods chain to move faster, as some goods are an expression of people&rsquo;s preferences which are themselves determined by social media/advertising/fast-moving digital things. Papers like this suggest that more retailers are going to deal in a larger variety of products, each sold at relatively low volumes; this generally increases the importance of systems for efficiently coordinating in warehouses where this is the case.&nbsp;&nbsp;&nbsp;Read more: Manufacturing Dispatching using Reinforcement and Transfer Learning (Arxiv).&nbsp;
####################################################
What happens when people think private AI systems should be public goods?..All watched over by un-integrated machines of incompetence&hellip;In the past few years, robots have become good and cheap enough to start being deployed in the world &ndash; see the proliferation of quadruped dog-esque bots, new generation robot vacuum cleaners, robo-lawnmowers, and so on. One use case has been security, exemplified by robots produced by a startup called Knightscope. These robots patrol malls, corporate campuses, stores, and other places, providing a highly visible and mobile sign of security.
So what happens when people get in trouble and need security? In Los Angeles in early October,, some people started fighting and there happened to be a Knightscope robot nearby. The robot had &lsquo;POLICE&rsquo; written on it. A woman ran up to the robot and hit its emergency alert button but nothing happened, as the robot&rsquo;s alert button isn&rsquo;t yet connected to the local police department, a spokesperson told NBC News. &ldquo;Amid the scene, the robot continued to glide along its pre-programmed route, humming an intergalactic tune that could have been ripped from any low-budget sci-fi film,&rdquo; NBC wrote. &ldquo;The almost 400-pound robot followed the park&rsquo;s winding concrete from the basketball courts to the children&rsquo;s splash zone, pausing every so often to tell visitors to &ldquo;please keep the park clean.&rdquo;&rdquo;
Why this matters: Integrating robots into society is going to be difficult if people don&rsquo;t trust robots; situations where robots don&rsquo;t match people&rsquo;s expectations are going to cause tension.&nbsp;&nbsp;&nbsp;Read more: A RoboCop, a park and a fight: How expectations about robots are clashing with reality (NBC News).
####################################################
Simple sub-$225 drones for smart students:&hellip;Brown University&rsquo;s &ldquo;PiDrone&rdquo; aims to make it easy for students to build smart drones&hellip;Another day brings another low-cost drone and associated software system, developed by university educators. This time it is PiDrone, a project from Brown University which describes a low-cost quadcopter drone which the researchers created to accompany a robotics course. Right now, the drone is a pretty basic platform, but the researchers expect it will become more advanced in the future &ndash; they plan to tap into the drone&rsquo;s vision system for better object tracking and motion planning,&nbsp; and to run a crowdfunding campaign &ldquo;to enable packaging of the drone parts into self-contained kits to distribute to individuals who desire to learn autonomous robotics using the PiDrone platform&rdquo;.&nbsp;
Autonomy &ndash; no deep learning required: I spend a lot of time in this newsletter writing about the intersection of deep learning and contemporary robot platforms, so it&rsquo;s worth noting that this drone doesn&rsquo;t use any deep learning. Instead, it uses tried and tested systems like an Unscented Kalman Filter (UKF) for state estimation,as well as two methods for localization &ndash; particle filters, and a FastSLAM algorithm. State estimation lets the drone know its state in reference to the rest of the world (eg, its height), and localization lets the drone know its location &ndash; having both of these systems makes it possible to build smart software on top of the drone to carry out actions in the world.
Why this matters: In the past few years, drones have been becoming cheaper to build as a consequence of economics of scale, and drones directly benefiting from improvements in vision and sensing technology driven by the (vast!) market for smartphones. Now, educators are turning drones into modular, extensible platforms that students can pick apart and write software for. I think the outcome of this is going to be a growing cadre of people able to hack, extend, and augment drones with increasingly powerful sensing and action technologies.&nbsp;&nbsp;&nbsp;Read more: Advanced Autonomy on a Low-Cost Educational Drone Platform (Arxiv).&nbsp;
####################################################
Want to see if your AI can beat humans at cards? Use RLCard:&hellip;OpenAI Gym-esque system makes it easy to train agents via reinforcement learning&hellip;Researchers with Texas A&amp;M University and Simon Fraser University have released RLCard, software to make it easy to train AI systems via reinforcement learning to play a variety of card games. RLCard is modeled on other, popular reinforcement learning frameworks like OpenAI Gym. It also ships with some in-built utilities for things like parallel training.
Included games: RLCard ships with the following integrated card games: Blackjack, Leduc Hold&rsquo;em, Limit Texas Hold&rsquo;em, Dou Dizhu, Mahjong, No-limit Texas Hold&rsquo;em, UNO, and Sheng Ji.
Why this matters: In the same way that some parts of AI research in language modeling have moved from single task to multi-task evaluation (see multi-task NLP benchmarks like GLUE, and SuperGLUE), I expect the same thing will soon happen with reinforcement learning, where we&rsquo;ll start training algorithms on multiple levels of the same game in parallel, then on games that are somewhat related to eachother, then across genres entirely. Systems like RLCard will help researchers improve algorithmic performance against card game domains, and could feed other, larger evaluation approaches in the future.&nbsp;&nbsp;&nbsp;Read more: RLcard: A Toolkit for Reinforcement Learning in Card Games (Arxiv).&nbsp;
####################################################
Lockheed Martin and Drone Racing League prepare to pit robots against humans in high-speed races:&hellip;League&rsquo;s new &ldquo;Artificial Intelligence Robotic Racing…"

---

### Import AI 168: The self-learning warehouse; a sub-$225 homebrew drone; and training card-playing AIs with RLCard 

Why the warehouse of the future will learn about itself:&hellip;Your next product could be delivered via Deep Manufacturing Dispatching (DMD)&hellip;How can we make manufacturing facilities more efficient? One approach is to try to make them more efficient. One way to make things more efficient is &ndash; sometimes &ndash; to make them more intelligent. That&rsquo;s what researchers at Hitachi America Ltd are trying to do with a new research paper where they improve dispatching systems in (simulated) warehouses via the use of AI. They call their resulting approach &ldquo;Deep Manufacturing Dispatching (DMD)&rdquo;, which I find oddly charming.&nbsp;
How DMD works: The DMD works like this &ndash; the researchers turn the state of the shop floor into a 2D matrix, incorporate various bits of state from the environment, then design reward systems which favor the on-time delivery of items.&nbsp;
Does any of this work? Yes, in simulation: They compare DND with seven other dispatching algorithms, ranging from carefully designed rule-based systems, to ones that use machine learning and reinforcement learning. They perform these comparisons in a variety of circumstances, assessing how well DMD can satisfy different constraints &ndash; here, lateness and tardiness. &ldquo;Overall, for 19 settings, DMD gets best results for 18 settings on total discounted reward and 16 settings on average lateness and tardiness.&rdquo; In tests, DMD beats out other systems by wide margins of success.
Why this matters: As the economy becomes increasingly digitized, we can expect some subset of the physical goods chain to move faster, as some goods are an expression of people&rsquo;s preferences which are themselves determined by social media/advertising/fast-moving digital things. Papers like this suggest that more retailers are going to deal in a larger variety of products, each sold at relatively low volumes; this generally increases the importance of systems for efficiently coordinating in warehouses where this is the case.&nbsp;&nbsp;&nbsp;Read more: Manufacturing Dispatching using Reinforcement and Transfer Learning (Arxiv).&nbsp;
####################################################
What happens when people think private AI systems should be public goods?..All watched over by un-integrated machines of incompetence&hellip;In the past few years, robots have become good and cheap enough to start being deployed in the world &ndash; see the proliferation of quadruped dog-esque bots, new generation robot vacuum cleaners, robo-lawnmowers, and so on. One use case has been security, exemplified by robots produced by a startup called Knightscope. These robots patrol malls, corporate campuses, stores, and other places, providing a highly visible and mobile sign of security.
So what happens when people get in trouble and need security? In Los Angeles in early October,, some people started fighting and there happened to be a Knightscope robot nearby. The robot had &lsquo;POLICE&rsquo; written on it. A woman ran up to the robot and hit its emergency alert button but nothing happened, as the robot&rsquo;s alert button isn&rsquo;t yet connected to the local police department, a spokesperson told NBC News. &ldquo;Amid the scene, the robot continued to glide along its pre-programmed route, humming an intergalactic tune that could have been ripped from any low-budget sci-fi film,&rdquo; NBC wrote. &ldquo;The almost 400-pound robot followed the park&rsquo;s winding concrete from the basketball courts to the children&rsquo;s splash zone, pausing every so often to tell visitors to &ldquo;please keep the park clean.&rdquo;&rdquo;
Why this matters: Integrating robots into society is going to be difficult if people don&rsquo;t trust robots; situations where robots don&rsquo;t match people&rsquo;s expectations are going to cause tension.&nbsp;&nbsp;&nbsp;Read more: A RoboCop, a park and a fight: How expectations about robots are clashing with reality (NBC News).
####################################################
Simple sub-$225 drones for smart students:&hellip;Brown University&rsquo;s &ldquo;PiDrone&rdquo; aims to make it easy for students to build smart drones&hellip;Another day brings another low-cost drone and associated software system, developed by university educators. This time it is PiDrone, a project from Brown University which describes a low-cost quadcopter drone which the researchers created to accompany a robotics course. Right now, the drone is a pretty basic platform, but the researchers expect it will become more advanced in the future &ndash; they plan to tap into the drone&rsquo;s vision system for better object tracking and motion planning,&nbsp; and to run a crowdfunding campaign &ldquo;to enable packaging of the drone parts into self-contained kits to distribute to individuals who desire to learn autonomous robotics using the PiDrone platform&rdquo;.&nbsp;
Autonomy &ndash; no deep learning required: I spend a lot of time in this newsletter writing about the intersection of deep learning and contemporary robot platforms, so it&rsquo;s worth noting that this drone doesn&rsquo;t use any deep learning. Instead, it uses tried and tested systems like an Unscented Kalman Filter (UKF) for state estimation,as well as two methods for localization &ndash; particle filters, and a FastSLAM algorithm. State estimation lets the drone know its state in reference to the rest of the world (eg, its height), and localization lets the drone know its location &ndash; having both of these systems makes it possible to build smart software on top of the drone to carry out actions in the world.
Why this matters: In the past few years, drones have been becoming cheaper to build as a consequence of economics of scale, and drones directly benefiting from improvements in vision and sensing technology driven by the (vast!) market for smartphones. Now, educators are turning drones into modular, extensible platforms that students can pick apart and write software for. I think the outcome of this is going to be a growing cadre of people able to hack, extend, and augment drones with increasingly powerful sensing and action technologies.&nbsp;&nbsp;&nbsp;Read more: Advanced Autonomy on a Low-Cost Educational Drone Platform (Arxiv).&nbsp;
####################################################
Want to see if your AI can beat humans at cards? Use RLCard:&hellip;OpenAI Gym-esque system makes it easy to train agents via reinforcement learning&hellip;Researchers with Texas A&amp;M University and Simon Fraser University have released RLCard, software to make it easy to train AI systems via reinforcement learning to play a variety of card games. RLCard is modeled on other, popular reinforcement learning frameworks like OpenAI Gym. It also ships with some in-built utilities for things like parallel training.
Included games: RLCard ships with the following integrated card games: Blackjack, Leduc Hold&rsquo;em, Limit Texas Hold&rsquo;em, Dou Dizhu, Mahjong, No-limit Texas Hold&rsquo;em, UNO, and Sheng Ji.
Why this matters: In the same way that some parts of AI research in language modeling have moved from single task to multi-task evaluation (see multi-task NLP benchmarks like GLUE, and SuperGLUE), I expect the same thing will soon happen with reinforcement learning, where we&rsquo;ll start training algorithms on multiple levels of the same game in parallel, then on games that are somewhat related to eachother, then across genres entirely. Systems like RLCard will help researchers improve algorithmic performance against card game domains, and could feed other, larger evaluation approaches in the future.&nbsp;&nbsp;&nbsp;Read more: RLcard: A Toolkit for Reinforcement Learning in Card Games (Arxiv).&nbsp;
####################################################
Lockheed Martin and Drone Racing League prepare to pit robots against humans in high-speed races:&hellip;League&rsquo;s new &ldquo;Artificial Intelligence Robotic Racing…