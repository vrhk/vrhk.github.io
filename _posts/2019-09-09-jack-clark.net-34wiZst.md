---

layout: post
category: product
title: "Import AI 163: Oxford researchers release self-driving car dataset; the rumors are true"
date: 2019-09-09 12:41:27
link: https://vrhk.co/34wiZst
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "How badly can reality mess with object detection algorithms? A lot, it turns out:&hellip;Want to stresstest your streetsign object detection system? Use CURE-TSD-Real&hellip;&ldquo;The new system-breaking tests have arrived!&rdquo; I imagine a researcher at a self-driving car company shouting, upon seeing the release of &lsquo;CURE-TSD-Real&rsquo;, a new dataset developed by researchers at Georgia Tech. CURE-TSD-Real collects footage of streetsigns, then algorithmically augments the footage to generate a variety of different, challenging examples to test systems against.
CURE-TSD-Real ingredients: The dataset contains 2,989 videos distinct containing around ~650,000 annotated signs. The dataset is also diverse &ndash; relative to other datasets &ndash; containing a range of traffic and perception conditions including rain, snow, shadow, haze, illumination, decolorization, blur, noise, codec error, dirty lens, occlusion, and overcast. The videos were collected in Belgium. The dataset is arranged into &lsquo;levels&rsquo;, where higher levels correlate to tests where a larger proportion of the images contain distortions, and so on.
Breaking baselines with CURE-TSD-Real: In tests, the researchers show that the presence of these tricky conditions can reduce performance by anywhere between 20% and 60%, depending on the evaluation criteria being used. Occlusions like shadows resulted in relatively little degradation (around 16%), whereas occlusions like codec errors and exposures could damage performance by as much as 80%.
Why this matters: One of the best ways to understand something is to break it, and datasets like CURE-TSC-Real make it easier than ever for researchers to test their systems against challenging systems, then observe how they do.&nbsp;&nbsp;&nbsp;Get the data from here (official CURE-TSD GitHub).&nbsp;&nbsp;&nbsp;Read more: Traffic Sign Detection under Challenging Conditions: A Deeper Look Into Performance Variations and Spectral Characteristics (Arxiv).
####################################################
What it takes to trick a machine learning classifier:&hellip;MLSEC competition winner explains what they did and how they did it&hellip;If we start deploying large amounts of machine learning into computer security, how might hackers respond? At this year&rsquo;s &lsquo;DEFCON&rsquo; hacking conference, the &lsquo;MLSEC&rsquo; (ImportAI #159) competition challenged hackers to work out how to smuggle 50 distinct malicious executables past machine learning classifiers. Now, the winner of the competition has written a blog post explaining how they won.
What it takes to defeat a machine learning classifier: It&rsquo;s worth reading the post in full, but one of the particularly nice exploits is that they took a look at benign executable files and &ldquo;found a large chunk of strings which appeared to contain Microsoft&rsquo;s End User License Agreement (EULA). This is a nice example of how many machine learning exploits work &ndash; find something in that data that causes the system to consistently predict one thing, and then find a way to emphasize this data.
Why this matters: Competitions like MLSEC generate evidence about the effectiveness of various machine learning exploits and defenses; writeups from competition winners are a neat way to understand the tools people use in this domain, and to develop intuitions about how computer security might work in the future.&nbsp;&nbsp;&nbsp;Read more: Evading Machine Learning Malware Classifiers (Medium).
####################################################
Can medical professionals use AI without needing to code?&hellip;Study suggests our tools are good enough for non-expert use, but our medical datasets are lacking&hellip;AI is getting more capable and is starting to impact society &ndash; that&rsquo;s the message I write here in one form or another each week. But is it useful to have powerful technology if no one can use it? That&rsquo;s a problem I sometimes worry about; though the tech is progressing rapidly, it&rsquo;s still really hard to use for a large number of people, and this makes it harder for us as a society to use the technology to maximum social benefit. Now, new research from researchers affiliated with the National Health Service (NHS) and DeepMind, shows how non-AI-expert medical professionals can use AI tools in their work.
What they did: The research centers on the use of Google&rsquo;s &lsquo;Cloud AutoML&rsquo; service, which is basically a nice UI sitting on top of some fancy neural architecture search technology, theoretically letting people upload a dataset, fiddle with some tuning dials, and let the AI optimize its own architecture for the task. Is it really that easy? It might be: the study focuses on two physicians &ldquo;with no previous coding or machine learning experience&rdquo; who spent around 10 hours studying basic shell script programming, the Google Cloud AutoML online documentation and GUI, and preparing the five input datasets they&rsquo;d use in tests. They also compared the models developed via Google Cloud AutoML with strong AI baselines derived from medical literature. Four out of five models &ldquo;showed comparable discriminative performance and diagnostic properties to state-of-the-art performing deep learning algorithms&rdquo;, they wrote.
Medical data is harder than you think: &ldquo;The quality of the open-access datasets (including insufficient information about patient flow and demographics) and the absence of measurement for precision, such as confidence intervals, constituted the major limitations of this study&rdquo;.
Why this matters: For AI to change society, society needs to be able to utilize AI systems; studies like this show that we&rsquo;re starting to develop sufficiently powerful and easy-to-use systems that non-experts can apply the technology in their own domains. However, the availability of things like high-quality, open datasets could hold back broader adoption of these tools &ndash; it&rsquo;s not useful to have an easy-to-use tool if you lack the ingredients to make exquisite things with it.&nbsp;&nbsp;&nbsp;Read more: Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study (Elsevier).
####################################################
Radar + Self-Driving Cars:&hellip;Addition to Oxford RobotCar Dataset gives academics more data to play with&hellip;Oxford University researchers have added radar data to a self-driving car dataset. The data was gathered using a Navtech CTS350-X scanning radar via 32 traversals of (roughly) the same route around Oxford UK. The data was gathered under different traffic, weather, and lighting conditions in January, 2019. Radar isn&rsquo;t used as much in self-driving car research as data gathered via traditional cameras and/or LIDAR; &ldquo;although this modality has received relatively little attention in this context, we anticipate that this release will help foster discussion of its uses within the community and encourage new and interesting areas of research not possible before,&rdquo; they write.&nbsp;
Why this matters: Data helps to fuel research, and different types of data are especially useful to researchers when they can be studied in conjunction with one another. Multi-modal datasets like the Oxford Robotcar Dataset will become increasingly important to AI research.&nbsp;&nbsp;&nbsp;Read more: The Oxford Radar RobotCar Dataset: A Radar Extension to the Oxford RobotCar Dataset (Arxiv).&nbsp;&nbsp;&nbsp;Get the data from here (official Oxford RobotCar Dataset site).
####################################################
Testing language engines with TABFACT:&hellip;Can your system work out what is entailed and what is refuted by Wikipedia data?&hellip;TABFACT consists of 118,439 annotated statements in reference to 16,621 Wikipedia tables. The statements can be ones that are entailed by the underlying…"

---

### Import AI 163: Oxford researchers release self-driving car dataset; the rumors are true – non-experts can use AI; plus, a meta-learning robot therapist!

How badly can reality mess with object detection algorithms? A lot, it turns out:&hellip;Want to stresstest your streetsign object detection system? Use CURE-TSD-Real&hellip;&ldquo;The new system-breaking tests have arrived!&rdquo; I imagine a researcher at a self-driving car company shouting, upon seeing the release of &lsquo;CURE-TSD-Real&rsquo;, a new dataset developed by researchers at Georgia Tech. CURE-TSD-Real collects footage of streetsigns, then algorithmically augments the footage to generate a variety of different, challenging examples to test systems against.
CURE-TSD-Real ingredients: The dataset contains 2,989 videos distinct containing around ~650,000 annotated signs. The dataset is also diverse &ndash; relative to other datasets &ndash; containing a range of traffic and perception conditions including rain, snow, shadow, haze, illumination, decolorization, blur, noise, codec error, dirty lens, occlusion, and overcast. The videos were collected in Belgium. The dataset is arranged into &lsquo;levels&rsquo;, where higher levels correlate to tests where a larger proportion of the images contain distortions, and so on.
Breaking baselines with CURE-TSD-Real: In tests, the researchers show that the presence of these tricky conditions can reduce performance by anywhere between 20% and 60%, depending on the evaluation criteria being used. Occlusions like shadows resulted in relatively little degradation (around 16%), whereas occlusions like codec errors and exposures could damage performance by as much as 80%.
Why this matters: One of the best ways to understand something is to break it, and datasets like CURE-TSC-Real make it easier than ever for researchers to test their systems against challenging systems, then observe how they do.&nbsp;&nbsp;&nbsp;Get the data from here (official CURE-TSD GitHub).&nbsp;&nbsp;&nbsp;Read more: Traffic Sign Detection under Challenging Conditions: A Deeper Look Into Performance Variations and Spectral Characteristics (Arxiv).
####################################################
What it takes to trick a machine learning classifier:&hellip;MLSEC competition winner explains what they did and how they did it&hellip;If we start deploying large amounts of machine learning into computer security, how might hackers respond? At this year&rsquo;s &lsquo;DEFCON&rsquo; hacking conference, the &lsquo;MLSEC&rsquo; (ImportAI #159) competition challenged hackers to work out how to smuggle 50 distinct malicious executables past machine learning classifiers. Now, the winner of the competition has written a blog post explaining how they won.
What it takes to defeat a machine learning classifier: It&rsquo;s worth reading the post in full, but one of the particularly nice exploits is that they took a look at benign executable files and &ldquo;found a large chunk of strings which appeared to contain Microsoft&rsquo;s End User License Agreement (EULA). This is a nice example of how many machine learning exploits work &ndash; find something in that data that causes the system to consistently predict one thing, and then find a way to emphasize this data.
Why this matters: Competitions like MLSEC generate evidence about the effectiveness of various machine learning exploits and defenses; writeups from competition winners are a neat way to understand the tools people use in this domain, and to develop intuitions about how computer security might work in the future.&nbsp;&nbsp;&nbsp;Read more: Evading Machine Learning Malware Classifiers (Medium).
####################################################
Can medical professionals use AI without needing to code?&hellip;Study suggests our tools are good enough for non-expert use, but our medical datasets are lacking&hellip;AI is getting more capable and is starting to impact society &ndash; that&rsquo;s the message I write here in one form or another each week. But is it useful to have powerful technology if no one can use it? That&rsquo;s a problem I sometimes worry about; though the tech is progressing rapidly, it&rsquo;s still really hard to use for a large number of people, and this makes it harder for us as a society to use the technology to maximum social benefit. Now, new research from researchers affiliated with the National Health Service (NHS) and DeepMind, shows how non-AI-expert medical professionals can use AI tools in their work.
What they did: The research centers on the use of Google&rsquo;s &lsquo;Cloud AutoML&rsquo; service, which is basically a nice UI sitting on top of some fancy neural architecture search technology, theoretically letting people upload a dataset, fiddle with some tuning dials, and let the AI optimize its own architecture for the task. Is it really that easy? It might be: the study focuses on two physicians &ldquo;with no previous coding or machine learning experience&rdquo; who spent around 10 hours studying basic shell script programming, the Google Cloud AutoML online documentation and GUI, and preparing the five input datasets they&rsquo;d use in tests. They also compared the models developed via Google Cloud AutoML with strong AI baselines derived from medical literature. Four out of five models &ldquo;showed comparable discriminative performance and diagnostic properties to state-of-the-art performing deep learning algorithms&rdquo;, they wrote.
Medical data is harder than you think: &ldquo;The quality of the open-access datasets (including insufficient information about patient flow and demographics) and the absence of measurement for precision, such as confidence intervals, constituted the major limitations of this study&rdquo;.
Why this matters: For AI to change society, society needs to be able to utilize AI systems; studies like this show that we&rsquo;re starting to develop sufficiently powerful and easy-to-use systems that non-experts can apply the technology in their own domains. However, the availability of things like high-quality, open datasets could hold back broader adoption of these tools &ndash; it&rsquo;s not useful to have an easy-to-use tool if you lack the ingredients to make exquisite things with it.&nbsp;&nbsp;&nbsp;Read more: Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study (Elsevier).
####################################################
Radar + Self-Driving Cars:&hellip;Addition to Oxford RobotCar Dataset gives academics more data to play with&hellip;Oxford University researchers have added radar data to a self-driving car dataset. The data was gathered using a Navtech CTS350-X scanning radar via 32 traversals of (roughly) the same route around Oxford UK. The data was gathered under different traffic, weather, and lighting conditions in January, 2019. Radar isn&rsquo;t used as much in self-driving car research as data gathered via traditional cameras and/or LIDAR; &ldquo;although this modality has received relatively little attention in this context, we anticipate that this release will help foster discussion of its uses within the community and encourage new and interesting areas of research not possible before,&rdquo; they write.&nbsp;
Why this matters: Data helps to fuel research, and different types of data are especially useful to researchers when they can be studied in conjunction with one another. Multi-modal datasets like the Oxford Robotcar Dataset will become increasingly important to AI research.&nbsp;&nbsp;&nbsp;Read more: The Oxford Radar RobotCar Dataset: A Radar Extension to the Oxford RobotCar Dataset (Arxiv).&nbsp;&nbsp;&nbsp;Get the data from here (official Oxford RobotCar Dataset site).
####################################################
Testing language engines with TABFACT:&hellip;Can your system work out what is entailed and what is refuted by Wikipedia data?&hellip;TABFACT consists of 118,439 annotated statements in reference to 16,621 Wikipedia tables. The statements can be ones that are entailed by the underlying…