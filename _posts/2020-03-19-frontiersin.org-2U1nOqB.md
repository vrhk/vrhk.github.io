---

layout: post
category: threads
title: "Deep Continuous-Discrete Machine Learning (DeCoDeML)"
date: 2020-03-19 05:45:38
link: https://vrhk.co/2U1nOqB
image: 
domain: frontiersin.org
author: "Frontiers"
icon: https://3718aeafc638f96f5bd6-d4a9ca15fc46ba40e71f94dec0aad28c.ssl.cf1.rackcdn.com/favicon_16x16.ico
excerpt: "Since the beginnings of machine learning – and indeed already hinted at in Alan Turing’s groundbreaking 1950 paper “Computing machinery and intelligence” – two opposing approaches have been pursued: on the one hand, approaches that relate learning to knowledge and mostly use “discrete” formalisms of formal logic. On the other hand, approaches which, mostly motivated by biological models, investigate learning in artificial neural networks and predominantly use “continuous” methods from numerical optimization and statistics. The recent successes of deep learning can be attributed to the latter, the “continuous” approach, and are currently opening up new opportunities for computers to “perceive” the world and to act, with far-reaching consequences for industry, science and society. The massive success in recognizing “continuous” patterns is the catalyst for a new enthusiasm for artificial intelligence methods. However, today’s artificial neural networks are hardly suitable for learning and understanding “discrete” logical structures, and this is one of the major hurdles to further progress.Accordingly, one of the biggest open problems is to clarify the connection between these two learning approaches (logical-discrete, neural-continuous). In particular, the role and benefits of prior knowledge need to be reassessed and clarified. The role of formal logic in ensuring sound reasoning must be related to perception through deep networks. Further, the question of how to use prior ..."

---

### Deep Continuous-Discrete Machine Learning (DeCoDeML)

Since the beginnings of machine learning – and indeed already hinted at in Alan Turing’s groundbreaking 1950 paper “Computing machinery and intelligence” – two opposing approaches have been pursued: on the one hand, approaches that relate learning to knowledge and mostly use “discrete” formalisms of formal logic. On the other hand, approaches which, mostly motivated by biological models, investigate learning in artificial neural networks and predominantly use “continuous” methods from numerical optimization and statistics. The recent successes of deep learning can be attributed to the latter, the “continuous” approach, and are currently opening up new opportunities for computers to “perceive” the world and to act, with far-reaching consequences for industry, science and society. The massive success in recognizing “continuous” patterns is the catalyst for a new enthusiasm for artificial intelligence methods. However, today’s artificial neural networks are hardly suitable for learning and understanding “discrete” logical structures, and this is one of the major hurdles to further progress.Accordingly, one of the biggest open problems is to clarify the connection between these two learning approaches (logical-discrete, neural-continuous). In particular, the role and benefits of prior knowledge need to be reassessed and clarified. The role of formal logic in ensuring sound reasoning must be related to perception through deep networks. Further, the question of how to use prior ...