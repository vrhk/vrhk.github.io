---

layout: post
category: research
title: "When Humans Aren’t Optimal: Robots that Collaborate with Risk-Aware Humans"
date: 2020-03-19 08:31:04
link: https://stanford.io/2xR1Spu
image: http://ai.stanford.edu/blog//assets/img/posts/2020-03-17-modeling-risky-humans/image1.png
domain: ai.stanford.edu
author: "SAIL Blog"
icon: http://ai.stanford.edu/blog/assets/img/favicon-32x32.png
excerpt: "A key component of human-robot collaboration is the ability for robots to predict human behavior. Robots do this by building models of human decision making. One way to model humans is to pretend that they are also robots, and assume users will always choose the optimal action that leads to the best outcomes. It’s also possible to account for human limitations, and relax this assumption so that the human is noisily rational (their actions will usually lead to the ideal outcome, but are also somewhat random)."

---

### When Humans Aren’t Optimal: Robots that Collaborate with Risk-Aware Humans

A key component of human-robot collaboration is the ability for robots to predict human behavior. Robots do this by building models of human decision making. One way to model humans is to pretend that they are also robots, and assume users will always choose the optimal action that leads to the best outcomes. It’s also possible to account for human limitations, and relax this assumption so that the human is noisily rational (their actions will usually lead to the ideal outcome, but are also somewhat random).