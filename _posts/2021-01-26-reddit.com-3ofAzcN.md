---

layout: post
category: threads
title: "[D] Weird observation during knowledge distillation"
date: 2021-01-26 13:37:37
link: https://vrhk.co/3ofAzcN
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Recently, we have (my team and me) tried knowledge distillation method: 1. First, we have a human labelled dataset, we trained a large model with..."

---

### [D] Weird observation during knowledge distillation

Recently, we have (my team and me) tried knowledge distillation method: 1. First, we have a human labelled dataset, we trained a large model with...