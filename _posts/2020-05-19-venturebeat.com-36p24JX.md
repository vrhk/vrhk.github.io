---

layout: post
category: press
title: "Microsoft’s ZeRO-2 with DeepSpeed trains neural networks with up to 170 billion parameters"
date: 2020-05-19 15:16:40
link: https://vrhk.co/36p24JX
image: https://venturebeat.com/wp-content/uploads/2019/01/EMMRetreat-5755-Kevin-Scott-March-2018.jpg?w=1200&strip=all
domain: venturebeat.com
author: "VentureBeat"
icon: https://venturebeat.com/wp-content/themes/vb-news/img/favicon.ico
excerpt: "At its all-digital Build conference, Microsoft announced ZeRO-2, which allows for the distributed training of models with up to 170 billion parameters."

---

### Microsoft’s ZeRO-2 with DeepSpeed trains neural networks with up to 170 billion parameters

At its all-digital Build conference, Microsoft announced ZeRO-2, which allows for the distributed training of models with up to 170 billion parameters.