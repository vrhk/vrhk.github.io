---

layout: post
category: threads
title: "[D] [R] How is Fast Transformers with Clustered Attention different from Reformer?"
date: 2020-12-18 10:38:32
link: https://vrhk.co/2WtNXyx
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "[Reformer](<https://arxiv.org/pdf/2001.04451.pdf>) splits queries into buckets using locality-sensitive hashing, while [Fast Transformers with..."

---

### [D] [R] How is Fast Transformers with Clustered Attention different from Reformer?

[Reformer](<https://arxiv.org/pdf/2001.04451.pdf>) splits queries into buckets using locality-sensitive hashing, while [Fast Transformers with...