---

layout: post
category: threads
title: "[D] - How Transformers work in deep learning and NLP: an intuitive introduction"
date: 2020-12-26 12:17:26
link: https://vrhk.co/38HA2uK
image: https://external-preview.redd.it/ms-FSONAX6l_MIq29VmidHIUCLFrqg6rN6Ln_4WAHq8.jpg?width=960&height=502.617801047&auto=webp&crop=960:502.617801047,smart&s=7b8ab2a3984d3f9fa732dacbaefe4a44f7d6ca12
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "The famous paper “**Attention is all you need**” in 2017 changed the way we were thinking about attention. With enough data, matrix..."

---

### [D] - How Transformers work in deep learning and NLP: an intuitive introduction

The famous paper “**Attention is all you need**” in 2017 changed the way we were thinking about attention. With enough data, matrix...