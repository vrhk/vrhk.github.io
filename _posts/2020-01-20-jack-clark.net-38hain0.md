---

layout: post
category: product
title: "Import AI 181: Welcome to the era of Chiplomacy!; how computer vision AI techniques can improve robotics research ; plus Baidu’s adversarial AI software"
date: 2020-01-20 17:36:35
link: https://vrhk.co/38hain0
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Training better and cheaper vision models by arbitraging compute for data:&hellip;Synthinel-1 shows how companies can spend $$$ on compute to create valuable data&hellip;Instead of gathering data in reality, can I spend money on computers to gather data in simulation? That&rsquo;s a question AI researchers have been asking themselves for a while, as they try to figure out cheaper, faster ways to create bigger datasets. New research from Duke University explores this idea by using a synthetically-created dataset named Synthinel-1 to train systems to be better at semantic segmentation. The Synthinel-1 dataset: Synthinel-1 consists of 2,108 synthetic images generated in nine distinct building styles within a simulated city. These images are paired with &ldquo;ground truth&rdquo; annotations that segment each of the buildings. Synthinel also has a subset dataset called Synth-1, which contains 1,640 images spread across six styles.  &nbsp; How to collect data from a virtual city: The researchers used &ldquo;CityEngine&rdquo;, software for rapidly generating large virtual worlds, and then flew a virtual aerial camera through these synthetic worlds, capturing photographs. Does any of this actually help? The key question here is whether the data generated in simulation can help solve problems in the real world. To test this, the researchers train two baseline segmentation systems (U-net, and DeepLabV3) against two distinct datasets: DigitalGlobe and Inria. What they find is if they train on synthetic data, they drastically improve the results of transfer, where you train on datasets and test on different datasets (e.g., train on Inria+Synth data, test on DigitalGlobe).  &nbsp; In further testing, the synthetic dataset doesn&rsquo;t seem to bias towards any particular type of city in performance terms &ndash; the authors hypothesize from this &ldquo;that the benefits of Synth-1 are most similar to those of domain randomization, in which models are improved by presenting them with synthetic data exhibiting diverse and possibly unrealistic visual features&rdquo;. Why this matters: Simulators are going to become the new frontier for (some) data generation &ndash; I expect many AI applications will end up being based on a small amount of &ldquo;real world&rdquo; data and a much larger amount of computationally-generated augmented data. I think computer games are going to become increasingly relevant places to use to generate data as well.  &nbsp; Read more: The Synthinel-1 dataset: a collection of high resolution synthetic overhead imagery for building segmentation (Arxiv).&nbsp;
####################################################
This week&rsquo;s Import A-Idea: CHIPLOMACY&hellip;A new weekly experiment, where I try and write about an idea rather than a specific research paper&hellip;
Chiplomacy (first mentioned: Import AI 175) is what happens when countries compete with eachother for compute resources and other technological assets via diplomatic means (of varying above and below board natures).Recent examples of chiplomacy:&ndash; The RISC-V foundation moving from Delaware to Switzerland to make it easier for it to collaborate with chip architecture people from multiple countries. &ndash; The US government pressuring the Dutch government to prevent ASML exporting extreme ultraviolet lithography (EUV) chip equipment to China. &ndash; The newly negotiated US-China trade deal applies 25% import tariffs to (some) Chinese semiconductors
What is chiplomacy similar to? As Mark Twain said, history doesn&rsquo;t repeat, but it does rhyme, and the current tensions over chips feel similar to prior tensions over oil. In Daniel Yergin&rsquo;s epic history of oil, The Prize, he vividly describes how the primacy of oil inflected politics throughout the 20th century, causing countries to use companies as extra-governmental assets to seize resources across the world, and for the oil companies themselves to grow so powerful that they were able to wirehead governments and direct politics for their own ends &ndash; even after antitrust cases against companies like Standard Oil at the start of the century. What will chiplomacy do?: How chiplomacy unfolds will directly influence the level of technological balkanization we experience in the world. Today, China and the West have different software systems, cloud infrastructures, and networks (via partitioning, e.g, the great firewall, the Internet2 community, etc), but they share some common things: chips, and the machinery used to make chips. Recent trade policy moves by the US have encouraged China to invest further in developing its own semiconductor architectures (see: the RISC-V move, as a symptom of this), but have not &ndash; yet &ndash; led to it pumping resources into inventing the technologies needed to fabricate chips. If that happens, then in about twenty years we&rsquo;ll likely see divergences in technique, materials, and approaches used for advanced chip manufacturing (e.g., as chips go 3D via transistor stacking, we could see two different schools emerge that relate to different fabrication approaches).&nbsp;
Why this matters: How might chiplomacy evolve in the 21st century and what strategic alterations could it bring about? How might nations compete with eachother to secure adequate technological &lsquo;resources&rsquo;, and what above and below-board strategies might they use? I&rsquo;d distill my current thinking as: If you thought the 20th century resource wars were bad, just wait until the 21st century tech-resource wars start heating up!
####################################################Can computer vision breakthroughs improve the way we conduct robotics research?&hellip;Common datasets and shared test environments = good. Can robotics have more of these?&hellip;In the past decade, machine learning breakthroughs in computer vision &ndash; specifically, the use of deep learning approaches, starting with ImageNet in 2012 &ndash; revolutionized some of the AI research field. Since then, deep learning approaches have spread into other parts of AI research. Now, roboticists with the Australian Centre for Robotic Vision at Queensland University of Technology, are asking what the robotics community can learn from this field?What made computer vision research so productive? A cocktail of standard datasets, plus competitions, plus rapid dissemination of results through systems like arXiv, dramatically sped up computer vision research relative to robotics research, they write. &nbsp; Money helps: These breakthroughs also had an economic component, which drove further adoption: breakthroughs in image recognition could &ldquo;be monetized for face detection in phone cameras, online photo album searching and tagging, biometrics, social media and advertising,&rdquo; and more, they write. Reality bites &ndash; why robotics is hard: There&rsquo;s a big difference between real world robot research and other parts of AI, they write, and that&rsquo;s reality. &ldquo;The performance of a sensor-based robot is stochastic,&rdquo; they write. &ldquo;Each run of the robot is unrepeatable&rdquo; due to variations in images, sensors, and so on, they write.  &nbsp; Simulation superiority: This means robot researchers need to thoroughly benchmark their robot systems in common simulators, they write. This would allow for: &ndash; The comparison of different algorithms on the same robot, environment &amp; task&ndash; Estimating the distribution in algorithm performance due to sensor noise, initial condition, etc&ndash; Investigating the robustness of algorithm performance due to environmental factors&ndash; Regression testing of code after alterations or retraining  &nbsp; A grand vision for shared tests: If researchers want to evaluate their algorithms on the same physical robots, then they need to find a way to test on common hardware in common environments. To that end, the researchers have written robot operating system (ROS)-comp…"

---

### Import AI 181: Welcome to the era of Chiplomacy!; how computer vision AI techniques can improve robotics research ; plus Baidu’s adversarial AI software

Training better and cheaper vision models by arbitraging compute for data:&hellip;Synthinel-1 shows how companies can spend $$$ on compute to create valuable data&hellip;Instead of gathering data in reality, can I spend money on computers to gather data in simulation? That&rsquo;s a question AI researchers have been asking themselves for a while, as they try to figure out cheaper, faster ways to create bigger datasets. New research from Duke University explores this idea by using a synthetically-created dataset named Synthinel-1 to train systems to be better at semantic segmentation. The Synthinel-1 dataset: Synthinel-1 consists of 2,108 synthetic images generated in nine distinct building styles within a simulated city. These images are paired with &ldquo;ground truth&rdquo; annotations that segment each of the buildings. Synthinel also has a subset dataset called Synth-1, which contains 1,640 images spread across six styles.  &nbsp; How to collect data from a virtual city: The researchers used &ldquo;CityEngine&rdquo;, software for rapidly generating large virtual worlds, and then flew a virtual aerial camera through these synthetic worlds, capturing photographs. Does any of this actually help? The key question here is whether the data generated in simulation can help solve problems in the real world. To test this, the researchers train two baseline segmentation systems (U-net, and DeepLabV3) against two distinct datasets: DigitalGlobe and Inria. What they find is if they train on synthetic data, they drastically improve the results of transfer, where you train on datasets and test on different datasets (e.g., train on Inria+Synth data, test on DigitalGlobe).  &nbsp; In further testing, the synthetic dataset doesn&rsquo;t seem to bias towards any particular type of city in performance terms &ndash; the authors hypothesize from this &ldquo;that the benefits of Synth-1 are most similar to those of domain randomization, in which models are improved by presenting them with synthetic data exhibiting diverse and possibly unrealistic visual features&rdquo;. Why this matters: Simulators are going to become the new frontier for (some) data generation &ndash; I expect many AI applications will end up being based on a small amount of &ldquo;real world&rdquo; data and a much larger amount of computationally-generated augmented data. I think computer games are going to become increasingly relevant places to use to generate data as well.  &nbsp; Read more: The Synthinel-1 dataset: a collection of high resolution synthetic overhead imagery for building segmentation (Arxiv).&nbsp;
####################################################
This week&rsquo;s Import A-Idea: CHIPLOMACY&hellip;A new weekly experiment, where I try and write about an idea rather than a specific research paper&hellip;
Chiplomacy (first mentioned: Import AI 175) is what happens when countries compete with eachother for compute resources and other technological assets via diplomatic means (of varying above and below board natures).Recent examples of chiplomacy:&ndash; The RISC-V foundation moving from Delaware to Switzerland to make it easier for it to collaborate with chip architecture people from multiple countries. &ndash; The US government pressuring the Dutch government to prevent ASML exporting extreme ultraviolet lithography (EUV) chip equipment to China. &ndash; The newly negotiated US-China trade deal applies 25% import tariffs to (some) Chinese semiconductors
What is chiplomacy similar to? As Mark Twain said, history doesn&rsquo;t repeat, but it does rhyme, and the current tensions over chips feel similar to prior tensions over oil. In Daniel Yergin&rsquo;s epic history of oil, The Prize, he vividly describes how the primacy of oil inflected politics throughout the 20th century, causing countries to use companies as extra-governmental assets to seize resources across the world, and for the oil companies themselves to grow so powerful that they were able to wirehead governments and direct politics for their own ends &ndash; even after antitrust cases against companies like Standard Oil at the start of the century. What will chiplomacy do?: How chiplomacy unfolds will directly influence the level of technological balkanization we experience in the world. Today, China and the West have different software systems, cloud infrastructures, and networks (via partitioning, e.g, the great firewall, the Internet2 community, etc), but they share some common things: chips, and the machinery used to make chips. Recent trade policy moves by the US have encouraged China to invest further in developing its own semiconductor architectures (see: the RISC-V move, as a symptom of this), but have not &ndash; yet &ndash; led to it pumping resources into inventing the technologies needed to fabricate chips. If that happens, then in about twenty years we&rsquo;ll likely see divergences in technique, materials, and approaches used for advanced chip manufacturing (e.g., as chips go 3D via transistor stacking, we could see two different schools emerge that relate to different fabrication approaches).&nbsp;
Why this matters: How might chiplomacy evolve in the 21st century and what strategic alterations could it bring about? How might nations compete with eachother to secure adequate technological &lsquo;resources&rsquo;, and what above and below-board strategies might they use? I&rsquo;d distill my current thinking as: If you thought the 20th century resource wars were bad, just wait until the 21st century tech-resource wars start heating up!
####################################################Can computer vision breakthroughs improve the way we conduct robotics research?&hellip;Common datasets and shared test environments = good. Can robotics have more of these?&hellip;In the past decade, machine learning breakthroughs in computer vision &ndash; specifically, the use of deep learning approaches, starting with ImageNet in 2012 &ndash; revolutionized some of the AI research field. Since then, deep learning approaches have spread into other parts of AI research. Now, roboticists with the Australian Centre for Robotic Vision at Queensland University of Technology, are asking what the robotics community can learn from this field?What made computer vision research so productive? A cocktail of standard datasets, plus competitions, plus rapid dissemination of results through systems like arXiv, dramatically sped up computer vision research relative to robotics research, they write. &nbsp; Money helps: These breakthroughs also had an economic component, which drove further adoption: breakthroughs in image recognition could &ldquo;be monetized for face detection in phone cameras, online photo album searching and tagging, biometrics, social media and advertising,&rdquo; and more, they write. Reality bites &ndash; why robotics is hard: There&rsquo;s a big difference between real world robot research and other parts of AI, they write, and that&rsquo;s reality. &ldquo;The performance of a sensor-based robot is stochastic,&rdquo; they write. &ldquo;Each run of the robot is unrepeatable&rdquo; due to variations in images, sensors, and so on, they write.  &nbsp; Simulation superiority: This means robot researchers need to thoroughly benchmark their robot systems in common simulators, they write. This would allow for: &ndash; The comparison of different algorithms on the same robot, environment &amp; task&ndash; Estimating the distribution in algorithm performance due to sensor noise, initial condition, etc&ndash; Investigating the robustness of algorithm performance due to environmental factors&ndash; Regression testing of code after alterations or retraining  &nbsp; A grand vision for shared tests: If researchers want to evaluate their algorithms on the same physical robots, then they need to find a way to test on common hardware in common environments. To that end, the researchers have written robot operating system (ROS)-comp…