---

layout: post
category: product
title: "Shrinking massive neural networks used to model language"
date: 2020-12-01 06:21:28
link: https://vrhk.co/37oeZfR
image: https://news.mit.edu/sites/default/files/images/202011/MIT-BERT-Lottery-01-Press.jpg
domain: news.mit.edu
author: "MIT News | Massachusetts Institute of Technology"
icon: https://news.mit.edu/themes/mit/assets/img/favicon/apple-icon-57x57.png
excerpt: "Deep learning neural networks can be massive, demanding major computing power. In a test of the “lottery ticket hypothesis,” MIT researchers have found leaner, more efficient subnetworks hidden within BERT models. The discovery could make natural language processing more accessible."

---

### Shrinking massive neural networks used to model language

Deep learning neural networks can be massive, demanding major computing power. In a test of the “lottery ticket hypothesis,” MIT researchers have found leaner, more efficient subnetworks hidden within BERT models. The discovery could make natural language processing more accessible.