---

layout: post
category: threads
title: "[D] Is it possible to have a vanilla VAE with an attention/transformer decoder"
date: 2021-01-06 13:37:30
link: https://vrhk.co/3rWLhbj
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "I'm not sure if it makes sense to combine the two architectures but I wanted to ask around if there are basic examples of such a hybrid. I'm..."

---

### [D] Is it possible to have a vanilla VAE with an attention/transformer decoder

I'm not sure if it makes sense to combine the two architectures but I wanted to ask around if there are basic examples of such a hybrid. I'm...