---

layout: post
category: product
title: "Import AI 194: DIY AI drones; Audi releases its self-driving dataset; plus, Eurovision-style AI pop."
date: 2020-04-20 16:36:36
link: https://vrhk.co/351oyA1
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Want to see if AI can write a pop song? Cast your vote in this contest:&hellip;VPRO competition challenges teams to write a half-decent song using AI tools&hellip;Dutch broadcaster VPRO wants to see if songs created via AI tools can be compelling, enjoyable pieces of music. Contestants need to use AI to help them compose a song of no more than three minutes long and need to document their creative process. Entries will be judged by a panel of AI Experts, as well as an international audience who can cast votes on the competition website (yes, that includes you, the readers of Import AI). What are they building in there? One French group has used GPT-2, Char-RNN, and Magenta Studio for Ableton to write their song, and an Australian act has used audio samples of Australian animals including koalas, kookaburras and Tasmanian devils as samples for their music (along with a generative system trained on Eurovision pop contest songs).  &nbsp; When do we get a winner? Winners will be announced on May 12, 2020.  &nbsp; Listen to the songs: You can listen to the songs and find out more about the teams here. Read more here: FAQ about the AI Song Contest (vpro website).####################################################Audi releases a semantic segmentation self-driving car dataset:&hellip;Audi sees Waymo&rsquo;s data release, raises with vehicle bus data&hellip;Audi has released A2D2, a self-driving car dataset. This is part of a recent trend where large companies have started releasing expensive datasets, collected by proprietary means. What is A2D2 and what can you do with it? The dataset consists of simultaneously recorded images and 3D point clouds, along with 3D bounding boxes, semantic segmentation, instance segmentation, and data from the vehicle&rsquo;s automotive bus. This means it&rsquo;s a good dataset for imitation learning research, as well as various visual processing problems. The inclusion of the vehicle&rsquo;s automotive bus data is interesting, as it means you can also use this dataset for reinforcement learning research, where you can learn from both the visual scenes and also the action instructions from the bus. How much data? A2D2 consists of around 400,000 images in total. Includes data recorded on highways, country roads, and cities in the south of Germany. The data was recorded under cloudy, rainy, and sunny weather conditions. Some of the data is labelled: 41,277 images are accompanied with semantic and instance segmentation labels for 38 categories, and 12,497 images also annotated with 3D bounding boxes within the field of view of the front-center camera.How does it compare? The A2D2 dataset is relatively large compared to other self-driving datasets, but is likely smaller than Waymo&rsquo;s Waymo Open Dataset (Import AI 161), which has 1.2 million 2D bounding boxes and 12 million 3D bounding boxes in its dataset across hundreds of thousands of annotated frames. However, Audi&rsquo;s dataset includes a richer set of types of data, including the vehicle&rsquo;s bus. GDPR &amp; Privacy: The researchers blur faces and vehicle number plates in all the images so they can follow GDPR legislation, they say. Who gets to build autonomous cars? One motivation for the dataset is to &ldquo;contribute to startups and other commercial entities by freely releasing data which is expensive to generate&rdquo;, the researchers write. This highlights an awkward truth of today&rsquo;s autonomous driving developments &ndash; gathering real-world data is a punishingly expensive exercise, and because for a long time companies kept data private, there aren&rsquo;t many real-world benchmarks. Dataset releases like A2D2 will hopefully make it easier for more people to conduct research into autonomous cars.  &nbsp; Read more: A2D2: Audi Autonomous Driving Dataset (arXiv). &nbsp; Download the 2.3TB dataset here (official A2D2 website).####################################################The DIY AI drone future gets closer:&hellip;Software prototype shows how to load homebrew models onto consumer drones&hellip;Researchers with the University of Udine in Italy and the Mongolian University of Science and Technology have created a software system that lets them load various AI capabilities onto a drone, then remotely pilot it. The system is worth viewing as a prototype for how we might see AI capabilities get integrated into more sophisticated, future systems, and it hints at a future full of cheap consumer drones being used for various surveillance tasks. The software: The main work here is in developing software that pairs a user-friendly desktop interface (showing a drone video feed, a map, and a control panel), with backend systes that interface with a DJI drone and execute AI capabilities on it. For this work, they implement a system that combines a YOLOv3 object detection model with a Discriminative Correlation Filter (DCFNet) model to track objects. In tests, the system is able to track an object of interest at 29.94fps, and detect multiple objects at processing speeds of around 20fps.&nbsp;
Where this research is going: Interfaces are hard &ndash; but they always get built given enough interest. I think in the future we&rsquo;ll see open source software packages emerge that let us easily load homebrew AI models onto off-the-shelf consumer drones. I think the implications of this kind of capability are hard to fathom, and I&rsquo;d guess we&rsquo;re less than three years away from us seeing scaled-up versions of the research discussed here.  &nbsp; Read more: An Efficient UAV-based Artificial Intelligence Framework for Real-Time Visual Tasks (arXiv). ####################################################Can AI help us automate satellite surveillance? (Hint: Yes, it can):&hellip;Where we&rsquo;re going, clouds don&rsquo;t matter&hellip;A group of defense-adjacent of involved organizations have released SpaceNet6, a high-resolution synthetic aperture radar dataset. &ldquo;No other open datasets exist that feature near-concurrent collection of SAR and optical at this scale with sub-meter resolution,&rdquo; they write. The authors of the dataset and associated research paper come from In-Q-Tel, Capella Space, Maxar Technologies, German Aerospace Center, and the Intel AI Lab. They&rsquo;re also launching a challenge for researchers to train deep learning systems to infer building dimensions from SAR data. The dataset and associated paper What&rsquo;s in the data? The SpaceNet6 Multi-Sensor All Weather Mapping (MSAW) dataset consists of SAR and optical data of the port of Rotterdam, the Netherlands, and contains 48,000 annotated building footprints across 120 square kilometers of sensory data. &ldquo;The dataset covers heterogeneous geographies, including high-density urban environments, rural farming areas, suburbs, industrial areas and ports resulting in various building size, density, context and appearance&rdquo;.Who cares about SAR? SAR is an interesting data format &ndash; it&rsquo;s radar, so it is made up of reflections from the earth, which means SAR data has different visual traits to optical data (e.g, one phenomenon called layover distorts things like skyscrapers &lsquo;where the object is so tall that the radar signal reaches the top of an object before it reaches the bottom of it&rsquo;, which causes alignment problems.&nbsp; This &ldquo;presents unique challenges for both computer vision algorithms and human comprehension,&rdquo; the researchers write. But SAR also has massive benefits &ndash; it intuitively maps out 3D structures, can see through clouds, and as we develop better SAR systems we&rsquo;ll be able to extract more and more information from the world. The challenge is building automated systems that can decode it and harmonize it with optical data &ndash; which is some of what SpaceNet6 helps with. Interesting progress: &ldquo;Although SAR has existed since the 1950s [22] and studies with neural nets date back at least to the 1990s [3], th…"

---

### Import AI 194: DIY AI drones; Audi releases its self-driving dataset; plus, Eurovision-style AI pop.

Want to see if AI can write a pop song? Cast your vote in this contest:&hellip;VPRO competition challenges teams to write a half-decent song using AI tools&hellip;Dutch broadcaster VPRO wants to see if songs created via AI tools can be compelling, enjoyable pieces of music. Contestants need to use AI to help them compose a song of no more than three minutes long and need to document their creative process. Entries will be judged by a panel of AI Experts, as well as an international audience who can cast votes on the competition website (yes, that includes you, the readers of Import AI). What are they building in there? One French group has used GPT-2, Char-RNN, and Magenta Studio for Ableton to write their song, and an Australian act has used audio samples of Australian animals including koalas, kookaburras and Tasmanian devils as samples for their music (along with a generative system trained on Eurovision pop contest songs).  &nbsp; When do we get a winner? Winners will be announced on May 12, 2020.  &nbsp; Listen to the songs: You can listen to the songs and find out more about the teams here. Read more here: FAQ about the AI Song Contest (vpro website).####################################################Audi releases a semantic segmentation self-driving car dataset:&hellip;Audi sees Waymo&rsquo;s data release, raises with vehicle bus data&hellip;Audi has released A2D2, a self-driving car dataset. This is part of a recent trend where large companies have started releasing expensive datasets, collected by proprietary means. What is A2D2 and what can you do with it? The dataset consists of simultaneously recorded images and 3D point clouds, along with 3D bounding boxes, semantic segmentation, instance segmentation, and data from the vehicle&rsquo;s automotive bus. This means it&rsquo;s a good dataset for imitation learning research, as well as various visual processing problems. The inclusion of the vehicle&rsquo;s automotive bus data is interesting, as it means you can also use this dataset for reinforcement learning research, where you can learn from both the visual scenes and also the action instructions from the bus. How much data? A2D2 consists of around 400,000 images in total. Includes data recorded on highways, country roads, and cities in the south of Germany. The data was recorded under cloudy, rainy, and sunny weather conditions. Some of the data is labelled: 41,277 images are accompanied with semantic and instance segmentation labels for 38 categories, and 12,497 images also annotated with 3D bounding boxes within the field of view of the front-center camera.How does it compare? The A2D2 dataset is relatively large compared to other self-driving datasets, but is likely smaller than Waymo&rsquo;s Waymo Open Dataset (Import AI 161), which has 1.2 million 2D bounding boxes and 12 million 3D bounding boxes in its dataset across hundreds of thousands of annotated frames. However, Audi&rsquo;s dataset includes a richer set of types of data, including the vehicle&rsquo;s bus. GDPR &amp; Privacy: The researchers blur faces and vehicle number plates in all the images so they can follow GDPR legislation, they say. Who gets to build autonomous cars? One motivation for the dataset is to &ldquo;contribute to startups and other commercial entities by freely releasing data which is expensive to generate&rdquo;, the researchers write. This highlights an awkward truth of today&rsquo;s autonomous driving developments &ndash; gathering real-world data is a punishingly expensive exercise, and because for a long time companies kept data private, there aren&rsquo;t many real-world benchmarks. Dataset releases like A2D2 will hopefully make it easier for more people to conduct research into autonomous cars.  &nbsp; Read more: A2D2: Audi Autonomous Driving Dataset (arXiv). &nbsp; Download the 2.3TB dataset here (official A2D2 website).####################################################The DIY AI drone future gets closer:&hellip;Software prototype shows how to load homebrew models onto consumer drones&hellip;Researchers with the University of Udine in Italy and the Mongolian University of Science and Technology have created a software system that lets them load various AI capabilities onto a drone, then remotely pilot it. The system is worth viewing as a prototype for how we might see AI capabilities get integrated into more sophisticated, future systems, and it hints at a future full of cheap consumer drones being used for various surveillance tasks. The software: The main work here is in developing software that pairs a user-friendly desktop interface (showing a drone video feed, a map, and a control panel), with backend systes that interface with a DJI drone and execute AI capabilities on it. For this work, they implement a system that combines a YOLOv3 object detection model with a Discriminative Correlation Filter (DCFNet) model to track objects. In tests, the system is able to track an object of interest at 29.94fps, and detect multiple objects at processing speeds of around 20fps.&nbsp;
Where this research is going: Interfaces are hard &ndash; but they always get built given enough interest. I think in the future we&rsquo;ll see open source software packages emerge that let us easily load homebrew AI models onto off-the-shelf consumer drones. I think the implications of this kind of capability are hard to fathom, and I&rsquo;d guess we&rsquo;re less than three years away from us seeing scaled-up versions of the research discussed here.  &nbsp; Read more: An Efficient UAV-based Artificial Intelligence Framework for Real-Time Visual Tasks (arXiv). ####################################################Can AI help us automate satellite surveillance? (Hint: Yes, it can):&hellip;Where we&rsquo;re going, clouds don&rsquo;t matter&hellip;A group of defense-adjacent of involved organizations have released SpaceNet6, a high-resolution synthetic aperture radar dataset. &ldquo;No other open datasets exist that feature near-concurrent collection of SAR and optical at this scale with sub-meter resolution,&rdquo; they write. The authors of the dataset and associated research paper come from In-Q-Tel, Capella Space, Maxar Technologies, German Aerospace Center, and the Intel AI Lab. They&rsquo;re also launching a challenge for researchers to train deep learning systems to infer building dimensions from SAR data. The dataset and associated paper What&rsquo;s in the data? The SpaceNet6 Multi-Sensor All Weather Mapping (MSAW) dataset consists of SAR and optical data of the port of Rotterdam, the Netherlands, and contains 48,000 annotated building footprints across 120 square kilometers of sensory data. &ldquo;The dataset covers heterogeneous geographies, including high-density urban environments, rural farming areas, suburbs, industrial areas and ports resulting in various building size, density, context and appearance&rdquo;.Who cares about SAR? SAR is an interesting data format &ndash; it&rsquo;s radar, so it is made up of reflections from the earth, which means SAR data has different visual traits to optical data (e.g, one phenomenon called layover distorts things like skyscrapers &lsquo;where the object is so tall that the radar signal reaches the top of an object before it reaches the bottom of it&rsquo;, which causes alignment problems.&nbsp; This &ldquo;presents unique challenges for both computer vision algorithms and human comprehension,&rdquo; the researchers write. But SAR also has massive benefits &ndash; it intuitively maps out 3D structures, can see through clouds, and as we develop better SAR systems we&rsquo;ll be able to extract more and more information from the world. The challenge is building automated systems that can decode it and harmonize it with optical data &ndash; which is some of what SpaceNet6 helps with. Interesting progress: &ldquo;Although SAR has existed since the 1950s [22] and studies with neural nets date back at least to the 1990s [3], th…