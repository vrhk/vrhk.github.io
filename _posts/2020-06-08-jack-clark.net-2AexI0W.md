---

layout: post
category: product
title: "Import AI 200: Pedestrian tracking; synthetic satellite data; and upscaling games with DeepFakes"
date: 2020-06-08 17:26:32
link: https://vrhk.co/2AexI0W
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "Can we use synthetic data to spy from space? RarePlanes suggests &lsquo;yes&rsquo;:&hellip;Real data + simulated data means we can arbitrage compute for data&hellip;Researchers with In Q Tel, a CIA-backed investment firm, and AI Reverie, an In Q Tel-backed startup, want to use synthetic data to improve satellite surveillance. To do this, they&rsquo;ve developed a dataset called Rareplanes that pairs real satellite data with synthetically generated stuff, for the purpose of identifying aircraft from satellite imagery.&ldquo;Overhead datasets remain one of the best avenues for developing new computer vision methods that can adapt to limited sensor resolution, variable look angles, and locate tightly grouped, cluttered objects,&rdquo; they write. &ldquo;Such methods can extend beyond the overhead space and be helpful in other domains such as face-id, autonomous driving, and surveillance&rdquo;What goes into RarePlanes?&ndash; Real data: 253 Maxar WorldView-3 satellite images with 14,700 hand annotated aircraft, spread across 112 real locations. &ndash; Synthetic data: 50 images with 630,000 annotations, spread across 15 synthetic locations.Fine-grained plane labels: The dataset labels thousands of planes with detailed attributes, such as wing position, number of engines, and sub-types of plane (e.g, whether a type of military plane, or a civil plane). Simulating&hellip;Atlanta? The synthetic portion of the dataset contains data simulated to be from cities across Europe, Asia, North America, and Russia. Why this matters &ndash; arbitraging compute for data: In tests, they show that if you use a small amount of real data and a large amount of synthetic data, you can train systems that approach the accuracy of those trained entirely on real data. This is promising: it suggests we&rsquo;ll be able to arbitrage spending money on compute to generate data, with spending money on generating real data (which I imagine can be quite expensive for satellite imagery).  &nbsp; Dataset: The dataset can allegedly be downloaded from this link, but the webpage currently says &ldquo;this content is password protected&rdquo;.  &nbsp; Read more: RarePlanes: Synthetic Data Takes Flight (arXiv).  &nbsp; Keep an eye on the AI Reverie github, in case they post synthetic data there (GitHub).####################################################JOB ALERT! Care about publication norms in AI research? Perhaps this PAI job is for you:&hellip;Help &ldquo;explore the challenges faced by the AI ecosystem in adopting responsible publication practices&rdquo;&hellip;How can the AI research community figure out responsible ways to publish research in potentially risky areas? That&rsquo;s a question that a project at the Partnership on AI is grappling with, and the organization is hiring a &lsquo;publication norms research fellow&rsquo; to help think through some of the (tricky!) issues here. The job is open to US citizens and may support remote work, I&rsquo;m told.  &nbsp; Apply here: Publication Norms Research Fellow (PAI TriNet job board).  &nbsp; Read more about PAI&rsquo;s work on publication norms here (official PAI website).####################################################Soon, security cameras will track you across cities even if you change your clothing:&hellip;Pedestrian re-identification is getting more sophisticated&hellip;The future of surveillance is a technique called re-identification that is currently being supercharged by modern AI capabilities. Re-identification is the task of matching an object across different camera views at different locations and times &ndash; in other words, if I give you a picture of a car at an intersection, can you automatically re-identify this car in other pictures from other parts of the town? Now, researchers with Fudan University, the University of Oxford, and the University of Surrey, have published research on Long-Term Cloth-Changing Person Re-identification &ndash; a technique for identifying someone even if they change their appearance by changing their clothes. How it works &ndash; by paying attention to bodies: Their technique works by trying to ignore the clothing of the person and instead analyzing their body pose, then using that to match them in images where they&rsquo;re wearing different clothes. Specifically, they &ldquo;extract identity-discriminative shape information whilst eliminating clothing information with the help of an off-the-shelf body pose estimation model&rdquo;The dataset: The &ldquo;Long-Term Cloth Changing&rdquo; (LTCC) dataset was collected over two months and contains 17,138 images of 152 identities with 478 different outfits captured from 12 camera views. The dataset includes major changes in illumination, viewing angle, and person pose&rsquo;s.How well does it do? In tests, their system displays good performance relative to a variety of baselines, and the authors carry out some ablation studies. Accuracy is still fairly poor, getting around 70$ top-1 accuracy on tests where it sees the person wearing the target clothes during training (though from a different angle), and more like 25% to 30% in harder cases where it has to generalize to the subject in new clothes.  &nbsp; So: nothing to be worried about right now. But I&rsquo;d be surprised if we couldn&rsquo;t get dramatically better scores simply by enlarging the dataset in terms of individuals and clothing variety, as well as camera angle variation. In the long run, techniques like this are going to change the costs of various surveillance techniques, with significant societal implications. Read more: Long-Term Cloth-Changing Person Re-Identification (arXiv).Get the dataset when it is available from the official project website (LTCC site).
####################################################DeepFakes for good: upgrading old games:Here&rsquo;s a fun YouTube video where someone upscales the characters in videogame Uncharted 2 by porting in their faces from Uncharted 4. They suggest they use &lsquo;deepfake tech&rsquo;, which I think we can take to mean any of the off-the-shelf image &amp; video synthesis systems that are floating around these days. Projects like this are an example of what happens after an AI technology becomes widely available and usable &ndash; the emergence of little hacky mini projects. What fun! &nbsp; Watch the video here: Uncharted 2 Faces Enhanced with Deepfake tech (YouTube).####################################################Skydio expands its smart drone business towards U.S government customers:&hellip;Obstacle-avoiding, object-tracking sport-selfie drone starts to explore Army, DEA, and Police applications&hellip;Skydio, a startup that makes a drone that can track and follow people, has started doing more work with local police and the U.S. government (including the U.S. Army and Air Force), according to Forbes. Skydio released a drone in 2018 that could follow people while they were doing exercise outdoors, giving hobbyists and athletes a smart selfie drone. Now, the company is starting to do more work with the government, and has also had conversations &ldquo;related to supply chain / national security&rdquo;.Why this matters: Some things that appear as toys end up being used eventually for more serious or grave purposes. Forbes&rsquo; story gives us a sense of how the VC-led boom in drone companies in recent years might also yield more use of ever-smarter drones by government actors &ndash; a nice example of omni-use AI technology in action. I expect this will generate a lot of societally beneficial uses of the technology, but in the short term I worry about use of these kinds of systems in domestic surveillance, where they may serve to heighten existing asymmetries of power.  &nbsp; Read more: Funded By Kevin Durant, Founded By Ex-Google Engineers: Meet The Drone Startup Scoring Millions In Government Surveillance Contracts (Forbes).####################################################How smart are drone autopilots get…"

---

### Import AI 200: Pedestrian tracking; synthetic satellite data; and upscaling games with DeepFakes

Can we use synthetic data to spy from space? RarePlanes suggests &lsquo;yes&rsquo;:&hellip;Real data + simulated data means we can arbitrage compute for data&hellip;Researchers with In Q Tel, a CIA-backed investment firm, and AI Reverie, an In Q Tel-backed startup, want to use synthetic data to improve satellite surveillance. To do this, they&rsquo;ve developed a dataset called Rareplanes that pairs real satellite data with synthetically generated stuff, for the purpose of identifying aircraft from satellite imagery.&ldquo;Overhead datasets remain one of the best avenues for developing new computer vision methods that can adapt to limited sensor resolution, variable look angles, and locate tightly grouped, cluttered objects,&rdquo; they write. &ldquo;Such methods can extend beyond the overhead space and be helpful in other domains such as face-id, autonomous driving, and surveillance&rdquo;What goes into RarePlanes?&ndash; Real data: 253 Maxar WorldView-3 satellite images with 14,700 hand annotated aircraft, spread across 112 real locations. &ndash; Synthetic data: 50 images with 630,000 annotations, spread across 15 synthetic locations.Fine-grained plane labels: The dataset labels thousands of planes with detailed attributes, such as wing position, number of engines, and sub-types of plane (e.g, whether a type of military plane, or a civil plane). Simulating&hellip;Atlanta? The synthetic portion of the dataset contains data simulated to be from cities across Europe, Asia, North America, and Russia. Why this matters &ndash; arbitraging compute for data: In tests, they show that if you use a small amount of real data and a large amount of synthetic data, you can train systems that approach the accuracy of those trained entirely on real data. This is promising: it suggests we&rsquo;ll be able to arbitrage spending money on compute to generate data, with spending money on generating real data (which I imagine can be quite expensive for satellite imagery).  &nbsp; Dataset: The dataset can allegedly be downloaded from this link, but the webpage currently says &ldquo;this content is password protected&rdquo;.  &nbsp; Read more: RarePlanes: Synthetic Data Takes Flight (arXiv).  &nbsp; Keep an eye on the AI Reverie github, in case they post synthetic data there (GitHub).####################################################JOB ALERT! Care about publication norms in AI research? Perhaps this PAI job is for you:&hellip;Help &ldquo;explore the challenges faced by the AI ecosystem in adopting responsible publication practices&rdquo;&hellip;How can the AI research community figure out responsible ways to publish research in potentially risky areas? That&rsquo;s a question that a project at the Partnership on AI is grappling with, and the organization is hiring a &lsquo;publication norms research fellow&rsquo; to help think through some of the (tricky!) issues here. The job is open to US citizens and may support remote work, I&rsquo;m told.  &nbsp; Apply here: Publication Norms Research Fellow (PAI TriNet job board).  &nbsp; Read more about PAI&rsquo;s work on publication norms here (official PAI website).####################################################Soon, security cameras will track you across cities even if you change your clothing:&hellip;Pedestrian re-identification is getting more sophisticated&hellip;The future of surveillance is a technique called re-identification that is currently being supercharged by modern AI capabilities. Re-identification is the task of matching an object across different camera views at different locations and times &ndash; in other words, if I give you a picture of a car at an intersection, can you automatically re-identify this car in other pictures from other parts of the town? Now, researchers with Fudan University, the University of Oxford, and the University of Surrey, have published research on Long-Term Cloth-Changing Person Re-identification &ndash; a technique for identifying someone even if they change their appearance by changing their clothes. How it works &ndash; by paying attention to bodies: Their technique works by trying to ignore the clothing of the person and instead analyzing their body pose, then using that to match them in images where they&rsquo;re wearing different clothes. Specifically, they &ldquo;extract identity-discriminative shape information whilst eliminating clothing information with the help of an off-the-shelf body pose estimation model&rdquo;The dataset: The &ldquo;Long-Term Cloth Changing&rdquo; (LTCC) dataset was collected over two months and contains 17,138 images of 152 identities with 478 different outfits captured from 12 camera views. The dataset includes major changes in illumination, viewing angle, and person pose&rsquo;s.How well does it do? In tests, their system displays good performance relative to a variety of baselines, and the authors carry out some ablation studies. Accuracy is still fairly poor, getting around 70$ top-1 accuracy on tests where it sees the person wearing the target clothes during training (though from a different angle), and more like 25% to 30% in harder cases where it has to generalize to the subject in new clothes.  &nbsp; So: nothing to be worried about right now. But I&rsquo;d be surprised if we couldn&rsquo;t get dramatically better scores simply by enlarging the dataset in terms of individuals and clothing variety, as well as camera angle variation. In the long run, techniques like this are going to change the costs of various surveillance techniques, with significant societal implications. Read more: Long-Term Cloth-Changing Person Re-Identification (arXiv).Get the dataset when it is available from the official project website (LTCC site).
####################################################DeepFakes for good: upgrading old games:Here&rsquo;s a fun YouTube video where someone upscales the characters in videogame Uncharted 2 by porting in their faces from Uncharted 4. They suggest they use &lsquo;deepfake tech&rsquo;, which I think we can take to mean any of the off-the-shelf image &amp; video synthesis systems that are floating around these days. Projects like this are an example of what happens after an AI technology becomes widely available and usable &ndash; the emergence of little hacky mini projects. What fun! &nbsp; Watch the video here: Uncharted 2 Faces Enhanced with Deepfake tech (YouTube).####################################################Skydio expands its smart drone business towards U.S government customers:&hellip;Obstacle-avoiding, object-tracking sport-selfie drone starts to explore Army, DEA, and Police applications&hellip;Skydio, a startup that makes a drone that can track and follow people, has started doing more work with local police and the U.S. government (including the U.S. Army and Air Force), according to Forbes. Skydio released a drone in 2018 that could follow people while they were doing exercise outdoors, giving hobbyists and athletes a smart selfie drone. Now, the company is starting to do more work with the government, and has also had conversations &ldquo;related to supply chain / national security&rdquo;.Why this matters: Some things that appear as toys end up being used eventually for more serious or grave purposes. Forbes&rsquo; story gives us a sense of how the VC-led boom in drone companies in recent years might also yield more use of ever-smarter drones by government actors &ndash; a nice example of omni-use AI technology in action. I expect this will generate a lot of societally beneficial uses of the technology, but in the short term I worry about use of these kinds of systems in domestic surveillance, where they may serve to heighten existing asymmetries of power.  &nbsp; Read more: Funded By Kevin Durant, Founded By Ex-Google Engineers: Meet The Drone Startup Scoring Millions In Government Surveillance Contracts (Forbes).####################################################How smart are drone autopilots get…