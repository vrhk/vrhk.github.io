---

layout: post
category: product
title: "Import AI 196: Baidu wins city surveillance challenge; COVID surveillance drones; and a dataset for building TLDR engines"
date: 2020-05-04 18:06:36
link: https://vrhk.co/3b21aDC
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "The AI City Challenge shows us what 21st century Information Empires look like:&hellip;Baidu wins three out of four city-surveillance challenges&hellip;City-level surveillance is getting really good. That&rsquo;s the takeaway from a paper going over the results of the 4th AI City Challenge, a workshop held at the CVPR conference this year. More than 300 teams entered the challenge and it strikes me as interesting that one company &ndash; Baidu &ndash; won three out of the four competition challenge tracks. What was the AI City Challenge testing? The AI City Challenge is designed to test out AI capabilities in four areas relating to city-scale video analysis problems. The challenge had four tracks, which covered:&ndash; Multi-class, multi-movement vehicle counting (Winner: Baidu).&ndash; Vehicle re-identification with real and synthetic training data (Winner: Baidu in collaboration with University of Technology, Sydney).&ndash; City-scale multi-target multi-camera vehicle tracking (CMU).&ndash; Traffic anomaly detection (Baidu, in collaboration with Sun Yat-sen University).What does this mean? In the 21st century, we&rsquo;ll view nations in terms of their information capacity, whereas in the 20th century we viewed them in terms of their resource capacity. A state&rsquo;s information capacity will basically be its ability to analyze itself and make rapid changes, and states which use tons of AI will be better at this. Think of this lens as nation-scale OODA loop analysis. Something which I think most people in the West are failing to notice is that the tight collaboration between tech companies and governments among Asian nations (China is obviously a big player here, as these Baidu results indicate, but so are countries like Singapore, Taiwan, etc) means that some countries are already showing us what information empires look like. Expect to see Baidu roll out more and more of these AI analysis capabilities in areas that the Chinese government operates (including abroad via One Belt One Road agreements). I think in a decade we&rsquo;ll look back at this period with interest at the obvious rise of companies and nations in this area, and we&rsquo;ll puzzle over why certain governments took relatively little notice.  &nbsp; Read more: The 4th AI City Challenge (arXiv). ####################################################
YOLOv4 gives everyone better open source object detection:&hellip;Plus, why we can&rsquo;t stop the march of progress here, and what that means&hellip;The fourth version of YOLOv4 is here, which means people can now access an even more efficient, higher-accuracy object detection system. YOLOv4 was developed by Russian researcher Alexey Bochkovskiy, as well as two researchers with the Institute of Information Science in Taiwan. YOLO is around 10% more accurate than YOLOv3, and about 12% better in terms of the frames-per-second it can run at. In other words: object recognition just got cheaper, easier, and better. Specific tricks versus general techniques: The YOLOv4 paper is worth a read because it gives us a sense of just how many domain-specific improvements have been packed into the system. This isn&rsquo;t one of those research papers where researchers dramatically simplify things &ndash; instead, this is a research paper about a widely-used real world system, which means most of the paper is about the specific tweaks the creators apply to further increase performance &ndash; data augmentation, hyperparameter selection, normalization tweaks, and so on.Can we choose _not_ to build things? YOLO has an interesting lineage &ndash; its original creator Joseph Redmon wrote upon the release of YOLOv3 in mid-2018 (Import AI: 88) that they expected the system to be used widely by advertising companies and the military; an unusually blunt assessment by a researcher of what their work was contributing to. This year, they said: &ldquo;I stopped doing CV research because I saw the impact my work was having. I loved the work but the military applications and privacy concerns eventually became impossible to ignore&ldquo;. When someone asked Redmon for their thoughts on Yolov4 they said &ldquo;doesn&rsquo;t matter what I think!&ldquo;. The existence of YOLOv4 highlights the inherent inevitability of certain kinds of technical progress, and raises interesting questions about how much impact individual researchers can have on the overall trajectory of a field.  &nbsp; Read the paper: YOLOv4: Optimal Speed and Accuracy of Object Detection (arXiv). &nbsp; Get the code for YOLOv4 here (GitHub).####################################################AllenAI try to build a scientific summarization engine &ndash; and the research has quite far to go:&hellip;Try out the summarization demo and see how well the system works in practice&hellip;Researchers with the Allen Institute for Artificial Intelligence and the University of Washington have built TLDR, a new dataset and challenge for exploring how well contemporary AI techniques can summarize scientific research papers. Summarization is a challenging task and for this work the researchers try to do extreme summarization &ndash; the goal is to build systems that can produce very &lsquo;TLDR&rsquo;-style short summarizations (between 15 to 30 tokens in length) of scientific papers. Spoiler alert: this is a hard task and a prototype system developed by Allen AI doesn&rsquo;t do very well on it&hellip; yet. What they&rsquo;ve released: As part of this research, they&rsquo;ve released SciTLDR, a dataset of almost ~4,000 TLDRs written about AI research papers hosted on the &lsquo;OpenReview&rsquo; publishing platform. SciTLDR includes at least two high-quality TLDRs for each paper.How well does it work? I ran a paper from arXiv through the online SciTLDR demo. Specifically, I fed in the abstract, introduction, and conclusion of this paper: Addressing Artificial Intelligence Bias in Retinal Disease Diagnostics. Here&rsquo;s what I got back after plugging in the abstract, introduction, and conclusion:&nbsp; &ldquo;Artificial Intelligence Bias for diabetic retinopathy diagnostics using deep generative models .&rdquo; This is not useful!  &nbsp; But maybe I got unlucky here. So let&rsquo;s try a couple more, using same method of abstract, introduction, and conclusion: &ndash; Input paper: A Review of Winograd Schema Challenge Datasets and Approaches.&ndash; Output: &ldquo;The Winograd Schema Challenge: A Survey and Benchmark Dataset Review&rdquo;. This isn&rsquo;t particularly useful. &ndash; Input paper: AIBench: An Industry Standard AI Benchmark Suite from Internet Services.&ndash; Output: &ldquo;AIBench: A balanced AI benchmarking methodology for meeting the subtly different requirements of different stages in developing a new system/architecture and&rdquo;. This is probably the best of the bunch &ndash; it gives me a better sense of the paper&rsquo;s contents and what it contains.Why this matters: While this research is at a preliminary and barely useable stage, it won&rsquo;t stay that way for long &ndash; within a couple of years, I expect we&rsquo;ll have decent summarization engines in a variety of different scientific domains, which will make it easier for us to understand the changing contours of science. More broadly, I think summarization is a challenging cognitive task, so progress here will lead to more general progress in AI writ large.  &nbsp; Read more: TLDR: Extreme Summarization of Scientific Documents (arXiv).  &nbsp; Get the SciTLDR dataset here (AllenAI, GitHub) &nbsp; Play around with a demo of the paper here (SciTLDR).####################################################Mapillary releases 1.6 million Street View-style photos:&hellip;(Almost) open source Google Street View&hellip;Mapping company Mapillary has released more than 1.6 million images of streets from 30 major cities across six continents. Researchers can request free access to the Mapillary Street-level Sequences Dataset, but if you wa…"

---

### Import AI 196: Baidu wins city surveillance challenge; COVID surveillance drones; and a dataset for building TLDR engines

The AI City Challenge shows us what 21st century Information Empires look like:&hellip;Baidu wins three out of four city-surveillance challenges&hellip;City-level surveillance is getting really good. That&rsquo;s the takeaway from a paper going over the results of the 4th AI City Challenge, a workshop held at the CVPR conference this year. More than 300 teams entered the challenge and it strikes me as interesting that one company &ndash; Baidu &ndash; won three out of the four competition challenge tracks. What was the AI City Challenge testing? The AI City Challenge is designed to test out AI capabilities in four areas relating to city-scale video analysis problems. The challenge had four tracks, which covered:&ndash; Multi-class, multi-movement vehicle counting (Winner: Baidu).&ndash; Vehicle re-identification with real and synthetic training data (Winner: Baidu in collaboration with University of Technology, Sydney).&ndash; City-scale multi-target multi-camera vehicle tracking (CMU).&ndash; Traffic anomaly detection (Baidu, in collaboration with Sun Yat-sen University).What does this mean? In the 21st century, we&rsquo;ll view nations in terms of their information capacity, whereas in the 20th century we viewed them in terms of their resource capacity. A state&rsquo;s information capacity will basically be its ability to analyze itself and make rapid changes, and states which use tons of AI will be better at this. Think of this lens as nation-scale OODA loop analysis. Something which I think most people in the West are failing to notice is that the tight collaboration between tech companies and governments among Asian nations (China is obviously a big player here, as these Baidu results indicate, but so are countries like Singapore, Taiwan, etc) means that some countries are already showing us what information empires look like. Expect to see Baidu roll out more and more of these AI analysis capabilities in areas that the Chinese government operates (including abroad via One Belt One Road agreements). I think in a decade we&rsquo;ll look back at this period with interest at the obvious rise of companies and nations in this area, and we&rsquo;ll puzzle over why certain governments took relatively little notice.  &nbsp; Read more: The 4th AI City Challenge (arXiv). ####################################################
YOLOv4 gives everyone better open source object detection:&hellip;Plus, why we can&rsquo;t stop the march of progress here, and what that means&hellip;The fourth version of YOLOv4 is here, which means people can now access an even more efficient, higher-accuracy object detection system. YOLOv4 was developed by Russian researcher Alexey Bochkovskiy, as well as two researchers with the Institute of Information Science in Taiwan. YOLO is around 10% more accurate than YOLOv3, and about 12% better in terms of the frames-per-second it can run at. In other words: object recognition just got cheaper, easier, and better. Specific tricks versus general techniques: The YOLOv4 paper is worth a read because it gives us a sense of just how many domain-specific improvements have been packed into the system. This isn&rsquo;t one of those research papers where researchers dramatically simplify things &ndash; instead, this is a research paper about a widely-used real world system, which means most of the paper is about the specific tweaks the creators apply to further increase performance &ndash; data augmentation, hyperparameter selection, normalization tweaks, and so on.Can we choose _not_ to build things? YOLO has an interesting lineage &ndash; its original creator Joseph Redmon wrote upon the release of YOLOv3 in mid-2018 (Import AI: 88) that they expected the system to be used widely by advertising companies and the military; an unusually blunt assessment by a researcher of what their work was contributing to. This year, they said: &ldquo;I stopped doing CV research because I saw the impact my work was having. I loved the work but the military applications and privacy concerns eventually became impossible to ignore&ldquo;. When someone asked Redmon for their thoughts on Yolov4 they said &ldquo;doesn&rsquo;t matter what I think!&ldquo;. The existence of YOLOv4 highlights the inherent inevitability of certain kinds of technical progress, and raises interesting questions about how much impact individual researchers can have on the overall trajectory of a field.  &nbsp; Read the paper: YOLOv4: Optimal Speed and Accuracy of Object Detection (arXiv). &nbsp; Get the code for YOLOv4 here (GitHub).####################################################AllenAI try to build a scientific summarization engine &ndash; and the research has quite far to go:&hellip;Try out the summarization demo and see how well the system works in practice&hellip;Researchers with the Allen Institute for Artificial Intelligence and the University of Washington have built TLDR, a new dataset and challenge for exploring how well contemporary AI techniques can summarize scientific research papers. Summarization is a challenging task and for this work the researchers try to do extreme summarization &ndash; the goal is to build systems that can produce very &lsquo;TLDR&rsquo;-style short summarizations (between 15 to 30 tokens in length) of scientific papers. Spoiler alert: this is a hard task and a prototype system developed by Allen AI doesn&rsquo;t do very well on it&hellip; yet. What they&rsquo;ve released: As part of this research, they&rsquo;ve released SciTLDR, a dataset of almost ~4,000 TLDRs written about AI research papers hosted on the &lsquo;OpenReview&rsquo; publishing platform. SciTLDR includes at least two high-quality TLDRs for each paper.How well does it work? I ran a paper from arXiv through the online SciTLDR demo. Specifically, I fed in the abstract, introduction, and conclusion of this paper: Addressing Artificial Intelligence Bias in Retinal Disease Diagnostics. Here&rsquo;s what I got back after plugging in the abstract, introduction, and conclusion:&nbsp; &ldquo;Artificial Intelligence Bias for diabetic retinopathy diagnostics using deep generative models .&rdquo; This is not useful!  &nbsp; But maybe I got unlucky here. So let&rsquo;s try a couple more, using same method of abstract, introduction, and conclusion: &ndash; Input paper: A Review of Winograd Schema Challenge Datasets and Approaches.&ndash; Output: &ldquo;The Winograd Schema Challenge: A Survey and Benchmark Dataset Review&rdquo;. This isn&rsquo;t particularly useful. &ndash; Input paper: AIBench: An Industry Standard AI Benchmark Suite from Internet Services.&ndash; Output: &ldquo;AIBench: A balanced AI benchmarking methodology for meeting the subtly different requirements of different stages in developing a new system/architecture and&rdquo;. This is probably the best of the bunch &ndash; it gives me a better sense of the paper&rsquo;s contents and what it contains.Why this matters: While this research is at a preliminary and barely useable stage, it won&rsquo;t stay that way for long &ndash; within a couple of years, I expect we&rsquo;ll have decent summarization engines in a variety of different scientific domains, which will make it easier for us to understand the changing contours of science. More broadly, I think summarization is a challenging cognitive task, so progress here will lead to more general progress in AI writ large.  &nbsp; Read more: TLDR: Extreme Summarization of Scientific Documents (arXiv).  &nbsp; Get the SciTLDR dataset here (AllenAI, GitHub) &nbsp; Play around with a demo of the paper here (SciTLDR).####################################################Mapillary releases 1.6 million Street View-style photos:&hellip;(Almost) open source Google Street View&hellip;Mapping company Mapillary has released more than 1.6 million images of streets from 30 major cities across six continents. Researchers can request free access to the Mapillary Street-level Sequences Dataset, but if you wa…