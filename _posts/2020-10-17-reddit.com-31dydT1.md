---

layout: post
category: threads
title: "[P] Poisoned Datasets: following some recent papers (Kurita et al 2020, Gu et al 2019), I demonstrate how datasets can be manipulated to place 'back door' vulnerabilities in ML models, and show how hard it can be to recognise when a dataset has been messed with..."
date: 2020-10-17 18:07:29
link: https://vrhk.co/31dydT1
image: https://external-preview.redd.it/VGU9NyEnIabZ_5t5KCwdgTKQG5ZUphF-RdkYMZSYT88.jpg?width=640&height=335.078534031&auto=webp&crop=640:335.078534031,smart&s=6de31819e9e546a3b6d66d539055fec0f4223b36
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "Posted in r/MachineLearning by u/mountainhousedog • 0 points and 3 comments"

---

### [P] Poisoned Datasets: following some recent papers (Kurita et al 2020, Gu et al 2019), I demonstrate how datasets can be manipulated to place 'back door' vulnerabilities in ML models, and show how hard it can be to recognise when a dataset has been messed with...

Posted in r/MachineLearning by u/mountainhousedog • 0 points and 3 comments