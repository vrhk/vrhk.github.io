---

layout: post
category: threads
title: "[D] Random Network Distillation - why doesn't the predictor network learn a bad representation in order to always be surprised?"
date: 2020-08-17 14:17:29
link: https://vrhk.co/31XUl3z
image: https://www.redditstatic.com/new-icon.png
domain: reddit.com
author: "reddit"
icon: http://www.redditstatic.com/desktop2x/img/favicon/apple-icon-57x57.png
excerpt: "In Exploration by Random Network Distillation paper ([<https://arxiv.org/abs/1810.12894>](<https://arxiv.org/abs/1810.12894>)), the authors introduce..."

---

### [D] Random Network Distillation - why doesn't the predictor network learn a bad representation in order to always be surprised?

In Exploration by Random Network Distillation paper ([<https://arxiv.org/abs/1810.12894>](<https://arxiv.org/abs/1810.12894>)), the authors introduce...