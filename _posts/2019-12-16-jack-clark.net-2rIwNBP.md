---

layout: post
category: product
title: "Import AI 177: Droneforests, via the FAA; Google expands BERT to 70+ languages; +DeepMind releases its memory suite."
date: 2019-12-16 18:36:19
link: https://vrhk.co/2rIwNBP
image: 
domain: jack-clark.net
author: "Jack Clark"
icon: https://s2.wp.com/i/webclip.png
excerpt: "DeepMind&rsquo;s Memory Task Suite makes it easier to build agents that remember:&hellip;To live is to remember and to remember is to live within a memory&hellip; Memory is mysterious, important, and frustratingly hard to build into AI systems. For the past few years, researchers have been experimenting with ways of adding memory to machine learning-based systems, and they&rsquo;ve messed around with components like separate differentiable storage sub-systems, external structured knowledge bases, and sometimes cocktails of curricula to structure the data and/or environments the agent gets fed during training, so it develops memory capabilities. More recently, people have been using attention mechanisms via widely-applied things like transformers to supplement for memory, by instead having systems that can be primed with lengthy inputs (e.g., entering 1000 characters of text into a GPT-2 model), and the system then ends up using attentional mechanisms to perform things that require some memory capabilities.
How do we expect to build memory systems in the future? Who knows. But AI research company DeepMind thinks the key is to develop sufficiently hard testing suites that help it understand the drawbacks of existing systems, and let it develop new ones against tasks that definitely requie sophisticated memory. To that end, it has released the DeepMind Memory Task Suite, a collection of 13 diverse machine-learning tasks that require memory to solve. Eight of the tasks are based in the Unity game engine, and the remaining ones are based on PsychLab, a testing sub-environment of DeepMind Lab.  &nbsp; Get the code for the tasks here: DeepMind Memory Task Suite (DeepMind GitHub).  &nbsp; Read the background research: Generalization of Reinforcement Learners with Working and Episodic Memory (Arxiv). ####################################################Google has photographed 10 million miles of planet Earth:Google&rsquo;s &ldquo;Street View&rdquo; vehicles have now photographed more than 10 million miles of imagery worldwide, and Google&rsquo;s satellites have covered around 36 million square miles of satellite imagery. 50% of the world&rsquo;s roads: The world has about 20 million miles of roads, according to the CIA&rsquo;s World Factbook. Let&rsquo;s assume this estimate lowballs things a bit and hasn&rsquo;t been updated in a while, and lets also add in a big chunk of dirt paths and other non-traditional roads, since we know (some) Google Street View vehicles go there&hellip; call it an extra 10 million? Therefore, Google has (potentially) photographed a third of the roads in the world, ish.Why this matters: Along with plugging into Google&rsquo;s various mapping services, the Street View imagery is also a profoundly valuable source of data for the training of supervized and unsupervised machine learning systems. Given recent progress in unsupervised machine learning approaches to image recognition, we can expect the Street View data to become an increasingly valuable blob of Google-gathered data, and I&rsquo;m especially curious to see what happens when people start training large-scale generative models against such data, and the inevitable creations of imaginary cities and imaginary roads that&rsquo;ll follow. &nbsp; &nbsp;Read more: Google Maps has now photographed 10 million miles in Street View (CNET). ####################################################FAA makes it easier to create DRONEFORESTS:The FAA has given tree-planting startup DroneSeed the permission to operate drones beyond visual line of sight (BVLOS) in forested and post-forest fire areas. &ldquo;The last numbers released in 2018 show more than twelve hundred BVLOS exemption applications have been submitted to the FAA by commercial drone operators and 99% have failed to be approved,&rdquo; DroneSeed wrote in a press release. The company &ldquo;currently operates with up to five aircraft simultaneously, each capable of delivering up to 57 lbs. Per flight of payload. Payloads dropped are &ldquo;pucks&rdquo; containing seeds, fertilizers and other amendments designed to boost seed survival.&rdquo;Why this matters: DroneSeed is a startup that I hope we see many more of, as it is using modern technology (drones and a little bit of clever software) to work on a problem of social importance (forest maintenance and growth).  &nbsp; Read more: FAA Approves Rare Permit to Replant After Wildfires (PR Newswire).####################################################Google expands BERT-based search to 70+ languages:In October, Google announced it had integrated a BERT-based models into its search engine to improve how it responds to user queries (Import AI: 170). That was a big deal at the time as it demonstrated how rapidly AI techniques can go from research into production (in the case of BERT, the timetable was a ~year ish, which is astonishingly fast). Now, Google is rolling out BERT-infused search to 70 languages, including Afrikaans, Icelandic, Vietnamese, and more. Why this matters: Some AI models are being used in a &lsquo;train once, run anywhere&rsquo; mode, where companies like Google will do large-scale pre-training on vast datasets, then use these pre-trained models to improve a multitude of services and/or finetune against specific services. This also stresses the significant impact we&rsquo;re starting to see NLP advances have in the real world; if the mid-2010s were about the emergence and maturation of computer vision, then the early 2020s will likely be about the maturation of language-oriented AI systems. (Mid-2020s&hellip; I&rsquo;d hazard a guess at robots, if hardware reliability improves enough).  &nbsp; Read more: Google announces expansion of BERT to 70+ languages (Google &lsquo;SearchLiaison&rsquo; twitter account).&nbsp;
####################################################Drones learn search-and-rescue in simulation:&hellip;Weather and terrain perturbation + AirSim + tweaked DDQN = Researchers with Durham University, Aalborg University, Newcastle University and Edinburgh University are trying to build AI systems for helping search and rescue drones navigate to predefined targets in cluttered or distracting environments. Preliminary research from them shows it&rsquo;s possible to train drones to perform well in simulated* environments, and that these drones can generalize to unseen environments and weather patterns. The most interesting part of this research is that the drones can learn in real-time, so they can be trained in simulation on huge amounts of data, then update themselves in reality on small samples of information.  &nbsp; &ldquo;This is the first approach to autonomous flight and exploration under the forest canopy that harnesses the advantages of Deep Reinforcement Learning (DRL) to continuously learn new features during the flight, allowing adaptability to unseen domains and varying weather conditions that culminate in low visibility,&rdquo; they write. They train the system in Microsoft&rsquo;s &lsquo;AirSim&rsquo; drone simulator (Import AI: 30), which has always been used to train drones to spot hazardous materials (Import AI: 111).Maps and reasoning: The UAV tries to figure out where it is and what it is doing by using two maps to help it navigate: a small 10X10 meter one, which it uses to learn how to navigate around its local environment, and a large map of arbitrary size which the small one is a subset of. This is a handy trick, as it means &ldquo;regardless of the size of the search area, the navigational complexity handled by the model will remain the same&rdquo;, they write. Two algorithms, one with slight tweaks: In tests, the researchers show that Deep Recurrent Q-Learning for Partially Observable MDPs (DRQN, first published in 2015) has the best overall performance, while their algorithm, Extended Dueling Double Deep-Q Networks (EDDQN) has marginally better performance in domains with lots of variation in weather. Specifically, EDDQN fiddles with t…"

---

### Import AI 177: Droneforests, via the FAA; Google expands BERT to 70+ languages; +DeepMind releases its memory suite.

DeepMind&rsquo;s Memory Task Suite makes it easier to build agents that remember:&hellip;To live is to remember and to remember is to live within a memory&hellip; Memory is mysterious, important, and frustratingly hard to build into AI systems. For the past few years, researchers have been experimenting with ways of adding memory to machine learning-based systems, and they&rsquo;ve messed around with components like separate differentiable storage sub-systems, external structured knowledge bases, and sometimes cocktails of curricula to structure the data and/or environments the agent gets fed during training, so it develops memory capabilities. More recently, people have been using attention mechanisms via widely-applied things like transformers to supplement for memory, by instead having systems that can be primed with lengthy inputs (e.g., entering 1000 characters of text into a GPT-2 model), and the system then ends up using attentional mechanisms to perform things that require some memory capabilities.
How do we expect to build memory systems in the future? Who knows. But AI research company DeepMind thinks the key is to develop sufficiently hard testing suites that help it understand the drawbacks of existing systems, and let it develop new ones against tasks that definitely requie sophisticated memory. To that end, it has released the DeepMind Memory Task Suite, a collection of 13 diverse machine-learning tasks that require memory to solve. Eight of the tasks are based in the Unity game engine, and the remaining ones are based on PsychLab, a testing sub-environment of DeepMind Lab.  &nbsp; Get the code for the tasks here: DeepMind Memory Task Suite (DeepMind GitHub).  &nbsp; Read the background research: Generalization of Reinforcement Learners with Working and Episodic Memory (Arxiv). ####################################################Google has photographed 10 million miles of planet Earth:Google&rsquo;s &ldquo;Street View&rdquo; vehicles have now photographed more than 10 million miles of imagery worldwide, and Google&rsquo;s satellites have covered around 36 million square miles of satellite imagery. 50% of the world&rsquo;s roads: The world has about 20 million miles of roads, according to the CIA&rsquo;s World Factbook. Let&rsquo;s assume this estimate lowballs things a bit and hasn&rsquo;t been updated in a while, and lets also add in a big chunk of dirt paths and other non-traditional roads, since we know (some) Google Street View vehicles go there&hellip; call it an extra 10 million? Therefore, Google has (potentially) photographed a third of the roads in the world, ish.Why this matters: Along with plugging into Google&rsquo;s various mapping services, the Street View imagery is also a profoundly valuable source of data for the training of supervized and unsupervised machine learning systems. Given recent progress in unsupervised machine learning approaches to image recognition, we can expect the Street View data to become an increasingly valuable blob of Google-gathered data, and I&rsquo;m especially curious to see what happens when people start training large-scale generative models against such data, and the inevitable creations of imaginary cities and imaginary roads that&rsquo;ll follow. &nbsp; &nbsp;Read more: Google Maps has now photographed 10 million miles in Street View (CNET). ####################################################FAA makes it easier to create DRONEFORESTS:The FAA has given tree-planting startup DroneSeed the permission to operate drones beyond visual line of sight (BVLOS) in forested and post-forest fire areas. &ldquo;The last numbers released in 2018 show more than twelve hundred BVLOS exemption applications have been submitted to the FAA by commercial drone operators and 99% have failed to be approved,&rdquo; DroneSeed wrote in a press release. The company &ldquo;currently operates with up to five aircraft simultaneously, each capable of delivering up to 57 lbs. Per flight of payload. Payloads dropped are &ldquo;pucks&rdquo; containing seeds, fertilizers and other amendments designed to boost seed survival.&rdquo;Why this matters: DroneSeed is a startup that I hope we see many more of, as it is using modern technology (drones and a little bit of clever software) to work on a problem of social importance (forest maintenance and growth).  &nbsp; Read more: FAA Approves Rare Permit to Replant After Wildfires (PR Newswire).####################################################Google expands BERT-based search to 70+ languages:In October, Google announced it had integrated a BERT-based models into its search engine to improve how it responds to user queries (Import AI: 170). That was a big deal at the time as it demonstrated how rapidly AI techniques can go from research into production (in the case of BERT, the timetable was a ~year ish, which is astonishingly fast). Now, Google is rolling out BERT-infused search to 70 languages, including Afrikaans, Icelandic, Vietnamese, and more. Why this matters: Some AI models are being used in a &lsquo;train once, run anywhere&rsquo; mode, where companies like Google will do large-scale pre-training on vast datasets, then use these pre-trained models to improve a multitude of services and/or finetune against specific services. This also stresses the significant impact we&rsquo;re starting to see NLP advances have in the real world; if the mid-2010s were about the emergence and maturation of computer vision, then the early 2020s will likely be about the maturation of language-oriented AI systems. (Mid-2020s&hellip; I&rsquo;d hazard a guess at robots, if hardware reliability improves enough).  &nbsp; Read more: Google announces expansion of BERT to 70+ languages (Google &lsquo;SearchLiaison&rsquo; twitter account).&nbsp;
####################################################Drones learn search-and-rescue in simulation:&hellip;Weather and terrain perturbation + AirSim + tweaked DDQN = Researchers with Durham University, Aalborg University, Newcastle University and Edinburgh University are trying to build AI systems for helping search and rescue drones navigate to predefined targets in cluttered or distracting environments. Preliminary research from them shows it&rsquo;s possible to train drones to perform well in simulated* environments, and that these drones can generalize to unseen environments and weather patterns. The most interesting part of this research is that the drones can learn in real-time, so they can be trained in simulation on huge amounts of data, then update themselves in reality on small samples of information.  &nbsp; &ldquo;This is the first approach to autonomous flight and exploration under the forest canopy that harnesses the advantages of Deep Reinforcement Learning (DRL) to continuously learn new features during the flight, allowing adaptability to unseen domains and varying weather conditions that culminate in low visibility,&rdquo; they write. They train the system in Microsoft&rsquo;s &lsquo;AirSim&rsquo; drone simulator (Import AI: 30), which has always been used to train drones to spot hazardous materials (Import AI: 111).Maps and reasoning: The UAV tries to figure out where it is and what it is doing by using two maps to help it navigate: a small 10X10 meter one, which it uses to learn how to navigate around its local environment, and a large map of arbitrary size which the small one is a subset of. This is a handy trick, as it means &ldquo;regardless of the size of the search area, the navigational complexity handled by the model will remain the same&rdquo;, they write. Two algorithms, one with slight tweaks: In tests, the researchers show that Deep Recurrent Q-Learning for Partially Observable MDPs (DRQN, first published in 2015) has the best overall performance, while their algorithm, Extended Dueling Double Deep-Q Networks (EDDQN) has marginally better performance in domains with lots of variation in weather. Specifically, EDDQN fiddles with t…